{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpVqQpXPsI0D"
      },
      "source": [
        "# Setup Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1BZto4asQHv",
        "outputId": "b05714d9-fc7a-485f-c04f-616c5505a9e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/tagucci/pythonrouge.git\n",
            "  Cloning https://github.com/tagucci/pythonrouge.git to /tmp/pip-req-build-2faz8b5l\n",
            "  Running command git clone -q https://github.com/tagucci/pythonrouge.git /tmp/pip-req-build-2faz8b5l\n",
            "Building wheels for collected packages: pythonrouge\n",
            "  Building wheel for pythonrouge (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pythonrouge: filename=pythonrouge-0.2-py3-none-any.whl size=285408 sha256=653f58c27c9efcaed30341c98394f31814544765f431785e57063f47c79de5f0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9jp98gtd/wheels/f2/28/1a/47e2c73d5e7d1d49296a991e19d774c97e4c2e98dbf027a515\n",
            "Successfully built pythonrouge\n",
            "Installing collected packages: pythonrouge\n",
            "Successfully installed pythonrouge-0.2\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libalgorithm-c3-perl libb-hooks-endofscope-perl libb-hooks-op-check-perl\n",
            "  libclass-c3-perl libclass-c3-xs-perl libclass-method-modifiers-perl\n",
            "  libclass-xsaccessor-perl libcpan-changes-perl libcpan-distnameinfo-perl\n",
            "  libcpan-meta-check-perl libdata-optlist-perl libdata-perl-perl\n",
            "  libdata-section-perl libdevel-callchecker-perl\n",
            "  libdevel-globaldestruction-perl libdynaloader-functions-perl\n",
            "  libencode-locale-perl libexporter-tiny-perl libfile-pushd-perl\n",
            "  libfile-slurp-perl libgetopt-long-descriptive-perl libhtml-parser-perl\n",
            "  libhtml-tagset-perl libhttp-date-perl libhttp-message-perl\n",
            "  libimport-into-perl libio-html-perl libio-stringy-perl\n",
            "  liblist-moreutils-perl liblocal-lib-perl liblwp-mediatypes-perl\n",
            "  libmodule-build-perl libmodule-cpanfile-perl libmodule-implementation-perl\n",
            "  libmodule-runtime-perl libmodule-signature-perl libmoo-perl\n",
            "  libmoox-handlesvia-perl libmro-compat-perl libnamespace-autoclean-perl\n",
            "  libnamespace-clean-perl libpackage-stash-perl libpackage-stash-xs-perl\n",
            "  libparams-classify-perl libparams-util-perl libparams-validate-perl\n",
            "  libparse-pmfile-perl libpath-tiny-perl libpod-markdown-perl\n",
            "  libpod-readme-perl libreadonly-perl libref-util-perl libref-util-xs-perl\n",
            "  librole-tiny-perl libsoftware-license-perl libstrictures-perl\n",
            "  libstring-shellquote-perl libsub-exporter-perl\n",
            "  libsub-exporter-progressive-perl libsub-identify-perl libsub-install-perl\n",
            "  libsub-name-perl libsub-quote-perl libtext-template-perl libtimedate-perl\n",
            "  libtry-tiny-perl libtype-tiny-perl libtype-tiny-xs-perl libunicode-utf8-perl\n",
            "  liburi-perl libvariable-magic-perl\n",
            "Suggested packages:\n",
            "  libdata-dump-perl libscalar-number-perl libbareword-filehandles-perl\n",
            "  libindirect-perl libmultidimensional-perl libdevel-stacktrace-perl\n",
            "  libdevel-lexalias-perl libwww-perl\n",
            "The following NEW packages will be installed:\n",
            "  cpanminus libalgorithm-c3-perl libb-hooks-endofscope-perl\n",
            "  libb-hooks-op-check-perl libclass-c3-perl libclass-c3-xs-perl\n",
            "  libclass-method-modifiers-perl libclass-xsaccessor-perl libcpan-changes-perl\n",
            "  libcpan-distnameinfo-perl libcpan-meta-check-perl libdata-optlist-perl\n",
            "  libdata-perl-perl libdata-section-perl libdevel-callchecker-perl\n",
            "  libdevel-globaldestruction-perl libdynaloader-functions-perl\n",
            "  libencode-locale-perl libexporter-tiny-perl libfile-pushd-perl\n",
            "  libfile-slurp-perl libgetopt-long-descriptive-perl libhtml-parser-perl\n",
            "  libhtml-tagset-perl libhttp-date-perl libhttp-message-perl\n",
            "  libimport-into-perl libio-html-perl libio-stringy-perl\n",
            "  liblist-moreutils-perl liblocal-lib-perl liblwp-mediatypes-perl\n",
            "  libmodule-build-perl libmodule-cpanfile-perl libmodule-implementation-perl\n",
            "  libmodule-runtime-perl libmodule-signature-perl libmoo-perl\n",
            "  libmoox-handlesvia-perl libmro-compat-perl libnamespace-autoclean-perl\n",
            "  libnamespace-clean-perl libpackage-stash-perl libpackage-stash-xs-perl\n",
            "  libparams-classify-perl libparams-util-perl libparams-validate-perl\n",
            "  libparse-pmfile-perl libpath-tiny-perl libpod-markdown-perl\n",
            "  libpod-readme-perl libreadonly-perl libref-util-perl libref-util-xs-perl\n",
            "  librole-tiny-perl libsoftware-license-perl libstrictures-perl\n",
            "  libstring-shellquote-perl libsub-exporter-perl\n",
            "  libsub-exporter-progressive-perl libsub-identify-perl libsub-install-perl\n",
            "  libsub-name-perl libsub-quote-perl libtext-template-perl libtimedate-perl\n",
            "  libtry-tiny-perl libtype-tiny-perl libtype-tiny-xs-perl libunicode-utf8-perl\n",
            "  liburi-perl libvariable-magic-perl\n",
            "0 upgraded, 72 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 2,249 kB of archives.\n",
            "After this operation, 6,883 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libcpan-distnameinfo-perl all 0.12-1 [8,662 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libcpan-meta-check-perl all 0.014-1 [7,594 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libfile-pushd-perl all 1.014-1 [11.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmodule-build-perl all 0.422400-1 [201 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 liblocal-lib-perl all 2.000024-1 [46.1 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmodule-cpanfile-perl all 1.1002-1 [23.8 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libparse-pmfile-perl all 0.41-1 [14.2 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libstring-shellquote-perl all 1.04-1 [12.0 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/universe amd64 cpanminus all 1.7043-1 [58.0 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libalgorithm-c3-perl all 0.10-1 [11.3 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libb-hooks-op-check-perl amd64 0.22-1 [10.1 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdynaloader-functions-perl all 0.003-1 [11.9 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdevel-callchecker-perl amd64 0.007-2build1 [14.1 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libparams-classify-perl amd64 0.015-1 [21.2 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmodule-runtime-perl all 0.016-1 [16.2 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtry-tiny-perl all 0.30-1 [20.5 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmodule-implementation-perl all 0.09-1 [12.2 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsub-exporter-progressive-perl all 0.001013-1 [6,784 B]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 libvariable-magic-perl amd64 0.62-1 [34.5 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 libb-hooks-endofscope-perl all 0.21-1 [14.7 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libclass-c3-perl all 0.33-1 [19.0 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libclass-c3-xs-perl amd64 0.14-1build3 [15.8 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 libclass-method-modifiers-perl all 2.12-1 [15.7 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 libclass-xsaccessor-perl amd64 1.19-2build8 [32.8 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libcpan-changes-perl all 0.400002-1 [32.0 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 libparams-util-perl amd64 1.07-3build3 [19.6 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsub-install-perl all 0.928-1 [10.5 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdata-optlist-perl all 0.110-1 [9,956 B]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic/main amd64 libexporter-tiny-perl all 1.000000-2 [34.6 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblist-moreutils-perl amd64 0.416-1build3 [55.5 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic/main amd64 librole-tiny-perl all 2.000006-1 [15.9 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu bionic/main amd64 libstrictures-perl all 2.000003-1 [16.1 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libdata-perl-perl all 0.002009-2 [39.1 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmro-compat-perl all 0.13-1 [11.2 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsub-exporter-perl all 0.987-1 [44.9 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libdata-section-perl all 0.200007-1 [11.8 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdevel-globaldestruction-perl all 0.14-1 [6,752 B]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu bionic/main amd64 libencode-locale-perl all 1.05-1 [12.3 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libfile-slurp-perl all 9999.19-6 [38.5 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-stringy-perl all 2.111-2 [60.6 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu bionic/main amd64 libparams-validate-perl amd64 1.29-1 [52.3 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgetopt-long-descriptive-perl all 0.102-1 [24.4 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-tagset-perl all 3.20-3 [12.1 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu bionic/main amd64 liburi-perl all 1.73-1 [77.2 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-parser-perl amd64 3.72-3build1 [85.9 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtimedate-perl all 2.3000-2 [37.5 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-date-perl all 6.02-1 [10.4 kB]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-html-perl all 1.001-1 [14.9 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblwp-mediatypes-perl all 6.02-1 [21.7 kB]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-message-perl all 6.14-1 [72.1 kB]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu bionic/main amd64 libimport-into-perl all 1.002005-1 [11.0 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmodule-signature-perl all 0.81-1 [22.9 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsub-quote-perl all 2.005000-1 [17.0 kB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmoo-perl all 2.003004-1 [45.5 kB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmoox-handlesvia-perl all 0.001008-3 [17.6 kB]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpackage-stash-perl all 0.37-1 [18.3 kB]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsub-identify-perl amd64 0.14-1 [10.5 kB]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsub-name-perl amd64 0.21-1build1 [11.6 kB]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu bionic/main amd64 libnamespace-clean-perl all 0.27-1 [13.6 kB]\n",
            "Get:60 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libnamespace-autoclean-perl all 0.28-1 [12.5 kB]\n",
            "Get:61 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpackage-stash-xs-perl amd64 0.28-3build2 [16.4 kB]\n",
            "Get:62 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpath-tiny-perl all 0.104-1 [55.3 kB]\n",
            "Get:63 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libpod-markdown-perl all 3.005000-1 [27.9 kB]\n",
            "Get:64 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libtype-tiny-perl all 1.002001-1 [226 kB]\n",
            "Get:65 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libpod-readme-perl all 1.1.2-2 [32.9 kB]\n",
            "Get:66 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libreadonly-perl all 2.050-1 [19.8 kB]\n",
            "Get:67 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libref-util-perl all 0.203-1 [14.8 kB]\n",
            "Get:68 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libref-util-xs-perl amd64 0.116-1 [11.5 kB]\n",
            "Get:69 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libtext-template-perl all 1.47-1 [46.9 kB]\n",
            "Get:70 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsoftware-license-perl all 0.103012-1 [108 kB]\n",
            "Get:71 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libtype-tiny-xs-perl amd64 0.012-2 [22.8 kB]\n",
            "Get:72 http://archive.ubuntu.com/ubuntu bionic/main amd64 libunicode-utf8-perl amd64 0.60-1build4 [17.9 kB]\n",
            "Fetched 2,249 kB in 0s (10.9 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package libcpan-distnameinfo-perl.\n",
            "(Reading database ... 155629 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libcpan-distnameinfo-perl_0.12-1_all.deb ...\n",
            "Unpacking libcpan-distnameinfo-perl (0.12-1) ...\n",
            "Selecting previously unselected package libcpan-meta-check-perl.\n",
            "Preparing to unpack .../01-libcpan-meta-check-perl_0.014-1_all.deb ...\n",
            "Unpacking libcpan-meta-check-perl (0.014-1) ...\n",
            "Selecting previously unselected package libfile-pushd-perl.\n",
            "Preparing to unpack .../02-libfile-pushd-perl_1.014-1_all.deb ...\n",
            "Unpacking libfile-pushd-perl (1.014-1) ...\n",
            "Selecting previously unselected package libmodule-build-perl.\n",
            "Preparing to unpack .../03-libmodule-build-perl_0.422400-1_all.deb ...\n",
            "Adding 'diversion of /usr/bin/config_data to /usr/bin/config_data.diverted by libmodule-build-perl'\n",
            "Adding 'diversion of /usr/share/man/man1/config_data.1.gz to /usr/share/man/man1/config_data.diverted.1.gz by libmodule-build-perl'\n",
            "Unpacking libmodule-build-perl (0.422400-1) ...\n",
            "Selecting previously unselected package liblocal-lib-perl.\n",
            "Preparing to unpack .../04-liblocal-lib-perl_2.000024-1_all.deb ...\n",
            "Unpacking liblocal-lib-perl (2.000024-1) ...\n",
            "Selecting previously unselected package libmodule-cpanfile-perl.\n",
            "Preparing to unpack .../05-libmodule-cpanfile-perl_1.1002-1_all.deb ...\n",
            "Unpacking libmodule-cpanfile-perl (1.1002-1) ...\n",
            "Selecting previously unselected package libparse-pmfile-perl.\n",
            "Preparing to unpack .../06-libparse-pmfile-perl_0.41-1_all.deb ...\n",
            "Unpacking libparse-pmfile-perl (0.41-1) ...\n",
            "Selecting previously unselected package libstring-shellquote-perl.\n",
            "Preparing to unpack .../07-libstring-shellquote-perl_1.04-1_all.deb ...\n",
            "Unpacking libstring-shellquote-perl (1.04-1) ...\n",
            "Selecting previously unselected package cpanminus.\n",
            "Preparing to unpack .../08-cpanminus_1.7043-1_all.deb ...\n",
            "Unpacking cpanminus (1.7043-1) ...\n",
            "Selecting previously unselected package libalgorithm-c3-perl.\n",
            "Preparing to unpack .../09-libalgorithm-c3-perl_0.10-1_all.deb ...\n",
            "Unpacking libalgorithm-c3-perl (0.10-1) ...\n",
            "Selecting previously unselected package libb-hooks-op-check-perl.\n",
            "Preparing to unpack .../10-libb-hooks-op-check-perl_0.22-1_amd64.deb ...\n",
            "Unpacking libb-hooks-op-check-perl (0.22-1) ...\n",
            "Selecting previously unselected package libdynaloader-functions-perl.\n",
            "Preparing to unpack .../11-libdynaloader-functions-perl_0.003-1_all.deb ...\n",
            "Unpacking libdynaloader-functions-perl (0.003-1) ...\n",
            "Selecting previously unselected package libdevel-callchecker-perl.\n",
            "Preparing to unpack .../12-libdevel-callchecker-perl_0.007-2build1_amd64.deb ...\n",
            "Unpacking libdevel-callchecker-perl (0.007-2build1) ...\n",
            "Selecting previously unselected package libparams-classify-perl.\n",
            "Preparing to unpack .../13-libparams-classify-perl_0.015-1_amd64.deb ...\n",
            "Unpacking libparams-classify-perl (0.015-1) ...\n",
            "Selecting previously unselected package libmodule-runtime-perl.\n",
            "Preparing to unpack .../14-libmodule-runtime-perl_0.016-1_all.deb ...\n",
            "Unpacking libmodule-runtime-perl (0.016-1) ...\n",
            "Selecting previously unselected package libtry-tiny-perl.\n",
            "Preparing to unpack .../15-libtry-tiny-perl_0.30-1_all.deb ...\n",
            "Unpacking libtry-tiny-perl (0.30-1) ...\n",
            "Selecting previously unselected package libmodule-implementation-perl.\n",
            "Preparing to unpack .../16-libmodule-implementation-perl_0.09-1_all.deb ...\n",
            "Unpacking libmodule-implementation-perl (0.09-1) ...\n",
            "Selecting previously unselected package libsub-exporter-progressive-perl.\n",
            "Preparing to unpack .../17-libsub-exporter-progressive-perl_0.001013-1_all.deb ...\n",
            "Unpacking libsub-exporter-progressive-perl (0.001013-1) ...\n",
            "Selecting previously unselected package libvariable-magic-perl.\n",
            "Preparing to unpack .../18-libvariable-magic-perl_0.62-1_amd64.deb ...\n",
            "Unpacking libvariable-magic-perl (0.62-1) ...\n",
            "Selecting previously unselected package libb-hooks-endofscope-perl.\n",
            "Preparing to unpack .../19-libb-hooks-endofscope-perl_0.21-1_all.deb ...\n",
            "Unpacking libb-hooks-endofscope-perl (0.21-1) ...\n",
            "Selecting previously unselected package libclass-c3-perl.\n",
            "Preparing to unpack .../20-libclass-c3-perl_0.33-1_all.deb ...\n",
            "Unpacking libclass-c3-perl (0.33-1) ...\n",
            "Selecting previously unselected package libclass-c3-xs-perl.\n",
            "Preparing to unpack .../21-libclass-c3-xs-perl_0.14-1build3_amd64.deb ...\n",
            "Unpacking libclass-c3-xs-perl (0.14-1build3) ...\n",
            "Selecting previously unselected package libclass-method-modifiers-perl.\n",
            "Preparing to unpack .../22-libclass-method-modifiers-perl_2.12-1_all.deb ...\n",
            "Unpacking libclass-method-modifiers-perl (2.12-1) ...\n",
            "Selecting previously unselected package libclass-xsaccessor-perl.\n",
            "Preparing to unpack .../23-libclass-xsaccessor-perl_1.19-2build8_amd64.deb ...\n",
            "Unpacking libclass-xsaccessor-perl (1.19-2build8) ...\n",
            "Selecting previously unselected package libcpan-changes-perl.\n",
            "Preparing to unpack .../24-libcpan-changes-perl_0.400002-1_all.deb ...\n",
            "Unpacking libcpan-changes-perl (0.400002-1) ...\n",
            "Selecting previously unselected package libparams-util-perl.\n",
            "Preparing to unpack .../25-libparams-util-perl_1.07-3build3_amd64.deb ...\n",
            "Unpacking libparams-util-perl (1.07-3build3) ...\n",
            "Selecting previously unselected package libsub-install-perl.\n",
            "Preparing to unpack .../26-libsub-install-perl_0.928-1_all.deb ...\n",
            "Unpacking libsub-install-perl (0.928-1) ...\n",
            "Selecting previously unselected package libdata-optlist-perl.\n",
            "Preparing to unpack .../27-libdata-optlist-perl_0.110-1_all.deb ...\n",
            "Unpacking libdata-optlist-perl (0.110-1) ...\n",
            "Selecting previously unselected package libexporter-tiny-perl.\n",
            "Preparing to unpack .../28-libexporter-tiny-perl_1.000000-2_all.deb ...\n",
            "Unpacking libexporter-tiny-perl (1.000000-2) ...\n",
            "Selecting previously unselected package liblist-moreutils-perl.\n",
            "Preparing to unpack .../29-liblist-moreutils-perl_0.416-1build3_amd64.deb ...\n",
            "Unpacking liblist-moreutils-perl (0.416-1build3) ...\n",
            "Selecting previously unselected package librole-tiny-perl.\n",
            "Preparing to unpack .../30-librole-tiny-perl_2.000006-1_all.deb ...\n",
            "Unpacking librole-tiny-perl (2.000006-1) ...\n",
            "Selecting previously unselected package libstrictures-perl.\n",
            "Preparing to unpack .../31-libstrictures-perl_2.000003-1_all.deb ...\n",
            "Unpacking libstrictures-perl (2.000003-1) ...\n",
            "Selecting previously unselected package libdata-perl-perl.\n",
            "Preparing to unpack .../32-libdata-perl-perl_0.002009-2_all.deb ...\n",
            "Unpacking libdata-perl-perl (0.002009-2) ...\n",
            "Selecting previously unselected package libmro-compat-perl.\n",
            "Preparing to unpack .../33-libmro-compat-perl_0.13-1_all.deb ...\n",
            "Unpacking libmro-compat-perl (0.13-1) ...\n",
            "Selecting previously unselected package libsub-exporter-perl.\n",
            "Preparing to unpack .../34-libsub-exporter-perl_0.987-1_all.deb ...\n",
            "Unpacking libsub-exporter-perl (0.987-1) ...\n",
            "Selecting previously unselected package libdata-section-perl.\n",
            "Preparing to unpack .../35-libdata-section-perl_0.200007-1_all.deb ...\n",
            "Unpacking libdata-section-perl (0.200007-1) ...\n",
            "Selecting previously unselected package libdevel-globaldestruction-perl.\n",
            "Preparing to unpack .../36-libdevel-globaldestruction-perl_0.14-1_all.deb ...\n",
            "Unpacking libdevel-globaldestruction-perl (0.14-1) ...\n",
            "Selecting previously unselected package libencode-locale-perl.\n",
            "Preparing to unpack .../37-libencode-locale-perl_1.05-1_all.deb ...\n",
            "Unpacking libencode-locale-perl (1.05-1) ...\n",
            "Selecting previously unselected package libfile-slurp-perl.\n",
            "Preparing to unpack .../38-libfile-slurp-perl_9999.19-6_all.deb ...\n",
            "Unpacking libfile-slurp-perl (9999.19-6) ...\n",
            "Selecting previously unselected package libio-stringy-perl.\n",
            "Preparing to unpack .../39-libio-stringy-perl_2.111-2_all.deb ...\n",
            "Unpacking libio-stringy-perl (2.111-2) ...\n",
            "Selecting previously unselected package libparams-validate-perl.\n",
            "Preparing to unpack .../40-libparams-validate-perl_1.29-1_amd64.deb ...\n",
            "Unpacking libparams-validate-perl (1.29-1) ...\n",
            "Selecting previously unselected package libgetopt-long-descriptive-perl.\n",
            "Preparing to unpack .../41-libgetopt-long-descriptive-perl_0.102-1_all.deb ...\n",
            "Unpacking libgetopt-long-descriptive-perl (0.102-1) ...\n",
            "Selecting previously unselected package libhtml-tagset-perl.\n",
            "Preparing to unpack .../42-libhtml-tagset-perl_3.20-3_all.deb ...\n",
            "Unpacking libhtml-tagset-perl (3.20-3) ...\n",
            "Selecting previously unselected package liburi-perl.\n",
            "Preparing to unpack .../43-liburi-perl_1.73-1_all.deb ...\n",
            "Unpacking liburi-perl (1.73-1) ...\n",
            "Selecting previously unselected package libhtml-parser-perl.\n",
            "Preparing to unpack .../44-libhtml-parser-perl_3.72-3build1_amd64.deb ...\n",
            "Unpacking libhtml-parser-perl (3.72-3build1) ...\n",
            "Selecting previously unselected package libtimedate-perl.\n",
            "Preparing to unpack .../45-libtimedate-perl_2.3000-2_all.deb ...\n",
            "Unpacking libtimedate-perl (2.3000-2) ...\n",
            "Selecting previously unselected package libhttp-date-perl.\n",
            "Preparing to unpack .../46-libhttp-date-perl_6.02-1_all.deb ...\n",
            "Unpacking libhttp-date-perl (6.02-1) ...\n",
            "Selecting previously unselected package libio-html-perl.\n",
            "Preparing to unpack .../47-libio-html-perl_1.001-1_all.deb ...\n",
            "Unpacking libio-html-perl (1.001-1) ...\n",
            "Selecting previously unselected package liblwp-mediatypes-perl.\n",
            "Preparing to unpack .../48-liblwp-mediatypes-perl_6.02-1_all.deb ...\n",
            "Unpacking liblwp-mediatypes-perl (6.02-1) ...\n",
            "Selecting previously unselected package libhttp-message-perl.\n",
            "Preparing to unpack .../49-libhttp-message-perl_6.14-1_all.deb ...\n",
            "Unpacking libhttp-message-perl (6.14-1) ...\n",
            "Selecting previously unselected package libimport-into-perl.\n",
            "Preparing to unpack .../50-libimport-into-perl_1.002005-1_all.deb ...\n",
            "Unpacking libimport-into-perl (1.002005-1) ...\n",
            "Selecting previously unselected package libmodule-signature-perl.\n",
            "Preparing to unpack .../51-libmodule-signature-perl_0.81-1_all.deb ...\n",
            "Unpacking libmodule-signature-perl (0.81-1) ...\n",
            "Selecting previously unselected package libsub-quote-perl.\n",
            "Preparing to unpack .../52-libsub-quote-perl_2.005000-1_all.deb ...\n",
            "Unpacking libsub-quote-perl (2.005000-1) ...\n",
            "Selecting previously unselected package libmoo-perl.\n",
            "Preparing to unpack .../53-libmoo-perl_2.003004-1_all.deb ...\n",
            "Unpacking libmoo-perl (2.003004-1) ...\n",
            "Selecting previously unselected package libmoox-handlesvia-perl.\n",
            "Preparing to unpack .../54-libmoox-handlesvia-perl_0.001008-3_all.deb ...\n",
            "Unpacking libmoox-handlesvia-perl (0.001008-3) ...\n",
            "Selecting previously unselected package libpackage-stash-perl.\n",
            "Preparing to unpack .../55-libpackage-stash-perl_0.37-1_all.deb ...\n",
            "Unpacking libpackage-stash-perl (0.37-1) ...\n",
            "Selecting previously unselected package libsub-identify-perl.\n",
            "Preparing to unpack .../56-libsub-identify-perl_0.14-1_amd64.deb ...\n",
            "Unpacking libsub-identify-perl (0.14-1) ...\n",
            "Selecting previously unselected package libsub-name-perl.\n",
            "Preparing to unpack .../57-libsub-name-perl_0.21-1build1_amd64.deb ...\n",
            "Unpacking libsub-name-perl (0.21-1build1) ...\n",
            "Selecting previously unselected package libnamespace-clean-perl.\n",
            "Preparing to unpack .../58-libnamespace-clean-perl_0.27-1_all.deb ...\n",
            "Unpacking libnamespace-clean-perl (0.27-1) ...\n",
            "Selecting previously unselected package libnamespace-autoclean-perl.\n",
            "Preparing to unpack .../59-libnamespace-autoclean-perl_0.28-1_all.deb ...\n",
            "Unpacking libnamespace-autoclean-perl (0.28-1) ...\n",
            "Selecting previously unselected package libpackage-stash-xs-perl.\n",
            "Preparing to unpack .../60-libpackage-stash-xs-perl_0.28-3build2_amd64.deb ...\n",
            "Unpacking libpackage-stash-xs-perl (0.28-3build2) ...\n",
            "Selecting previously unselected package libpath-tiny-perl.\n",
            "Preparing to unpack .../61-libpath-tiny-perl_0.104-1_all.deb ...\n",
            "Unpacking libpath-tiny-perl (0.104-1) ...\n",
            "Selecting previously unselected package libpod-markdown-perl.\n",
            "Preparing to unpack .../62-libpod-markdown-perl_3.005000-1_all.deb ...\n",
            "Unpacking libpod-markdown-perl (3.005000-1) ...\n",
            "Selecting previously unselected package libtype-tiny-perl.\n",
            "Preparing to unpack .../63-libtype-tiny-perl_1.002001-1_all.deb ...\n",
            "Unpacking libtype-tiny-perl (1.002001-1) ...\n",
            "Selecting previously unselected package libpod-readme-perl.\n",
            "Preparing to unpack .../64-libpod-readme-perl_1.1.2-2_all.deb ...\n",
            "Unpacking libpod-readme-perl (1.1.2-2) ...\n",
            "Selecting previously unselected package libreadonly-perl.\n",
            "Preparing to unpack .../65-libreadonly-perl_2.050-1_all.deb ...\n",
            "Unpacking libreadonly-perl (2.050-1) ...\n",
            "Selecting previously unselected package libref-util-perl.\n",
            "Preparing to unpack .../66-libref-util-perl_0.203-1_all.deb ...\n",
            "Unpacking libref-util-perl (0.203-1) ...\n",
            "Selecting previously unselected package libref-util-xs-perl.\n",
            "Preparing to unpack .../67-libref-util-xs-perl_0.116-1_amd64.deb ...\n",
            "Unpacking libref-util-xs-perl (0.116-1) ...\n",
            "Selecting previously unselected package libtext-template-perl.\n",
            "Preparing to unpack .../68-libtext-template-perl_1.47-1_all.deb ...\n",
            "Unpacking libtext-template-perl (1.47-1) ...\n",
            "Selecting previously unselected package libsoftware-license-perl.\n",
            "Preparing to unpack .../69-libsoftware-license-perl_0.103012-1_all.deb ...\n",
            "Unpacking libsoftware-license-perl (0.103012-1) ...\n",
            "Selecting previously unselected package libtype-tiny-xs-perl.\n",
            "Preparing to unpack .../70-libtype-tiny-xs-perl_0.012-2_amd64.deb ...\n",
            "Unpacking libtype-tiny-xs-perl (0.012-2) ...\n",
            "Selecting previously unselected package libunicode-utf8-perl.\n",
            "Preparing to unpack .../71-libunicode-utf8-perl_0.60-1build4_amd64.deb ...\n",
            "Unpacking libunicode-utf8-perl (0.60-1build4) ...\n",
            "Setting up libhtml-tagset-perl (3.20-3) ...\n",
            "Setting up libpath-tiny-perl (0.104-1) ...\n",
            "Setting up libclass-c3-xs-perl (0.14-1build3) ...\n",
            "Setting up libsub-install-perl (0.928-1) ...\n",
            "Setting up libio-stringy-perl (2.111-2) ...\n",
            "Setting up libcpan-distnameinfo-perl (0.12-1) ...\n",
            "Setting up libsub-exporter-progressive-perl (0.001013-1) ...\n",
            "Setting up libtry-tiny-perl (0.30-1) ...\n",
            "Setting up libfile-slurp-perl (9999.19-6) ...\n",
            "Setting up libclass-method-modifiers-perl (2.12-1) ...\n",
            "Setting up libencode-locale-perl (1.05-1) ...\n",
            "Setting up libvariable-magic-perl (0.62-1) ...\n",
            "Setting up libtimedate-perl (2.3000-2) ...\n",
            "Setting up librole-tiny-perl (2.000006-1) ...\n",
            "Setting up libstring-shellquote-perl (1.04-1) ...\n",
            "Setting up libb-hooks-op-check-perl (0.22-1) ...\n",
            "Setting up libio-html-perl (1.001-1) ...\n",
            "Setting up libexporter-tiny-perl (1.000000-2) ...\n",
            "Setting up libmodule-cpanfile-perl (1.1002-1) ...\n",
            "Setting up libtype-tiny-xs-perl (0.012-2) ...\n",
            "Setting up libsub-identify-perl (0.14-1) ...\n",
            "Setting up libref-util-perl (0.203-1) ...\n",
            "Setting up libdynaloader-functions-perl (0.003-1) ...\n",
            "Setting up libparse-pmfile-perl (0.41-1) ...\n",
            "Setting up libfile-pushd-perl (1.014-1) ...\n",
            "Setting up libcpan-meta-check-perl (0.014-1) ...\n",
            "Setting up libpackage-stash-xs-perl (0.28-3build2) ...\n",
            "Setting up libstrictures-perl (2.000003-1) ...\n",
            "Setting up libmodule-signature-perl (0.81-1) ...\n",
            "Setting up libreadonly-perl (2.050-1) ...\n",
            "Setting up liblwp-mediatypes-perl (6.02-1) ...\n",
            "Setting up libref-util-xs-perl (0.116-1) ...\n",
            "Setting up liburi-perl (1.73-1) ...\n",
            "Setting up libhtml-parser-perl (3.72-3build1) ...\n",
            "Setting up libdevel-globaldestruction-perl (0.14-1) ...\n",
            "Setting up libpod-markdown-perl (3.005000-1) ...\n",
            "Setting up libclass-xsaccessor-perl (1.19-2build8) ...\n",
            "Setting up libcpan-changes-perl (0.400002-1) ...\n",
            "Setting up libunicode-utf8-perl (0.60-1build4) ...\n",
            "Setting up libmodule-build-perl (0.422400-1) ...\n",
            "Setting up libparams-util-perl (1.07-3build3) ...\n",
            "Setting up libsub-name-perl (0.21-1build1) ...\n",
            "Setting up libsub-quote-perl (2.005000-1) ...\n",
            "Setting up libtext-template-perl (1.47-1) ...\n",
            "Setting up libalgorithm-c3-perl (0.10-1) ...\n",
            "Setting up libclass-c3-perl (0.33-1) ...\n",
            "Setting up liblocal-lib-perl (2.000024-1) ...\n",
            "Setting up liblist-moreutils-perl (0.416-1build3) ...\n",
            "Setting up libdata-optlist-perl (0.110-1) ...\n",
            "Setting up libhttp-date-perl (6.02-1) ...\n",
            "Setting up libtype-tiny-perl (1.002001-1) ...\n",
            "Setting up libdevel-callchecker-perl (0.007-2build1) ...\n",
            "Setting up cpanminus (1.7043-1) ...\n",
            "Setting up libmro-compat-perl (0.13-1) ...\n",
            "Setting up libsub-exporter-perl (0.987-1) ...\n",
            "Setting up libhttp-message-perl (6.14-1) ...\n",
            "Setting up libparams-classify-perl (0.015-1) ...\n",
            "Setting up libdata-section-perl (0.200007-1) ...\n",
            "Setting up libmodule-runtime-perl (0.016-1) ...\n",
            "Setting up libsoftware-license-perl (0.103012-1) ...\n",
            "Setting up libdata-perl-perl (0.002009-2) ...\n",
            "Setting up libimport-into-perl (1.002005-1) ...\n",
            "Setting up libmodule-implementation-perl (0.09-1) ...\n",
            "Setting up libparams-validate-perl (1.29-1) ...\n",
            "Setting up libmoo-perl (2.003004-1) ...\n",
            "Setting up libb-hooks-endofscope-perl (0.21-1) ...\n",
            "Setting up libpackage-stash-perl (0.37-1) ...\n",
            "Setting up libgetopt-long-descriptive-perl (0.102-1) ...\n",
            "Setting up libmoox-handlesvia-perl (0.001008-3) ...\n",
            "Setting up libnamespace-clean-perl (0.27-1) ...\n",
            "Setting up libnamespace-autoclean-perl (0.28-1) ...\n",
            "Setting up libpod-readme-perl (1.1.2-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "--> Working on XML::Parser\n",
            "Fetching http://www.cpan.org/authors/id/T/TO/TODDR/XML-Parser-2.46.tar.gz ... OK\n",
            "Configuring XML-Parser-2.46 ... OK\n",
            "==> Found dependencies: LWP::UserAgent\n",
            "--> Working on LWP::UserAgent\n",
            "Fetching http://www.cpan.org/authors/id/O/OA/OALDERS/libwww-perl-6.66.tar.gz ... OK\n",
            "Configuring libwww-perl-6.66 ... OK\n",
            "==> Found dependencies: Test::Fatal, Test::RequiresInternet, HTTP::Negotiate, HTTP::Daemon, WWW::RobotRules, Net::HTTP, HTTP::Cookies, Test::Needs, File::Listing\n",
            "--> Working on Test::Fatal\n",
            "Fetching http://www.cpan.org/authors/id/R/RJ/RJBS/Test-Fatal-0.016.tar.gz ... OK\n",
            "Configuring Test-Fatal-0.016 ... OK\n",
            "Building and testing Test-Fatal-0.016 ... OK\n",
            "Successfully installed Test-Fatal-0.016\n",
            "--> Working on Test::RequiresInternet\n",
            "Fetching http://www.cpan.org/authors/id/M/MA/MALLEN/Test-RequiresInternet-0.05.tar.gz ... OK\n",
            "Configuring Test-RequiresInternet-0.05 ... OK\n",
            "Building and testing Test-RequiresInternet-0.05 ... OK\n",
            "Successfully installed Test-RequiresInternet-0.05\n",
            "--> Working on HTTP::Negotiate\n",
            "Fetching http://www.cpan.org/authors/id/G/GA/GAAS/HTTP-Negotiate-6.01.tar.gz ... OK\n",
            "Configuring HTTP-Negotiate-6.01 ... OK\n",
            "Building and testing HTTP-Negotiate-6.01 ... OK\n",
            "Successfully installed HTTP-Negotiate-6.01\n",
            "--> Working on HTTP::Daemon\n",
            "Fetching http://www.cpan.org/authors/id/O/OA/OALDERS/HTTP-Daemon-6.14.tar.gz ... OK\n",
            "==> Found dependencies: Module::Build::Tiny\n",
            "--> Working on Module::Build::Tiny\n",
            "Fetching http://www.cpan.org/authors/id/L/LE/LEONT/Module-Build-Tiny-0.039.tar.gz ... OK\n",
            "==> Found dependencies: ExtUtils::InstallPaths, ExtUtils::Config, ExtUtils::Helpers\n",
            "--> Working on ExtUtils::InstallPaths\n",
            "Fetching http://www.cpan.org/authors/id/L/LE/LEONT/ExtUtils-InstallPaths-0.012.tar.gz ... OK\n",
            "Configuring ExtUtils-InstallPaths-0.012 ... OK\n",
            "==> Found dependencies: ExtUtils::Config\n",
            "--> Working on ExtUtils::Config\n",
            "Fetching http://www.cpan.org/authors/id/L/LE/LEONT/ExtUtils-Config-0.008.tar.gz ... OK\n",
            "Configuring ExtUtils-Config-0.008 ... OK\n",
            "Building and testing ExtUtils-Config-0.008 ... OK\n",
            "Successfully installed ExtUtils-Config-0.008\n",
            "Building and testing ExtUtils-InstallPaths-0.012 ... OK\n",
            "Successfully installed ExtUtils-InstallPaths-0.012\n",
            "--> Working on ExtUtils::Helpers\n",
            "Fetching http://www.cpan.org/authors/id/L/LE/LEONT/ExtUtils-Helpers-0.026.tar.gz ... OK\n",
            "Configuring ExtUtils-Helpers-0.026 ... OK\n",
            "Building and testing ExtUtils-Helpers-0.026 ... OK\n",
            "Successfully installed ExtUtils-Helpers-0.026\n",
            "Configuring Module-Build-Tiny-0.039 ... OK\n",
            "Building and testing Module-Build-Tiny-0.039 ... OK\n",
            "Successfully installed Module-Build-Tiny-0.039\n",
            "Configuring HTTP-Daemon-6.14 ... OK\n",
            "==> Found dependencies: Test::Needs\n",
            "--> Working on Test::Needs\n",
            "Fetching http://www.cpan.org/authors/id/H/HA/HAARG/Test-Needs-0.002009.tar.gz ... OK\n",
            "Configuring Test-Needs-0.002009 ... OK\n",
            "Building and testing Test-Needs-0.002009 ... OK\n",
            "Successfully installed Test-Needs-0.002009\n",
            "Building and testing HTTP-Daemon-6.14 ... OK\n",
            "Successfully installed HTTP-Daemon-6.14\n",
            "--> Working on WWW::RobotRules\n",
            "Fetching http://www.cpan.org/authors/id/G/GA/GAAS/WWW-RobotRules-6.02.tar.gz ... OK\n",
            "Configuring WWW-RobotRules-6.02 ... OK\n",
            "Building and testing WWW-RobotRules-6.02 ... OK\n",
            "Successfully installed WWW-RobotRules-6.02\n",
            "--> Working on Net::HTTP\n",
            "Fetching http://www.cpan.org/authors/id/O/OA/OALDERS/Net-HTTP-6.22.tar.gz ... OK\n",
            "Configuring Net-HTTP-6.22 ... OK\n",
            "Building and testing Net-HTTP-6.22 ... OK\n",
            "Successfully installed Net-HTTP-6.22\n",
            "--> Working on HTTP::Cookies\n",
            "Fetching http://www.cpan.org/authors/id/O/OA/OALDERS/HTTP-Cookies-6.10.tar.gz ... OK\n",
            "Configuring HTTP-Cookies-6.10 ... OK\n",
            "Building and testing HTTP-Cookies-6.10 ... OK\n",
            "Successfully installed HTTP-Cookies-6.10\n",
            "--> Working on File::Listing\n",
            "Fetching http://www.cpan.org/authors/id/P/PL/PLICEASE/File-Listing-6.15.tar.gz ... OK\n",
            "Configuring File-Listing-6.15 ... OK\n",
            "Building and testing File-Listing-6.15 ... OK\n",
            "Successfully installed File-Listing-6.15\n",
            "Building and testing libwww-perl-6.66 ... OK\n",
            "Successfully installed libwww-perl-6.66\n",
            "Building and testing XML-Parser-2.46 ... OK\n",
            "Successfully installed XML-Parser-2.46\n",
            "15 distributions installed\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/tagucci/pythonrouge.git\n",
        "!apt-get install -y cpanminus\n",
        "!cpanm --force XML::Parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOJZKbSRsENa",
        "outputId": "89599bb8-df9b-489c-cc02-0fa2e3119fc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "nltk.download('punkt')\n",
        "import string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZFeEQ61sgbk"
      },
      "source": [
        "# Preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpvDbO72sjr_"
      },
      "outputs": [],
      "source": [
        "def unlistDatasetParagraphs(df, column: str):\n",
        "  data = []\n",
        "  for list1 in df[column]:\n",
        "    new_paragraphs = ''\n",
        "    for list2 in list1:\n",
        "      for list3 in list2:\n",
        "        for str1 in list3:\n",
        "          new_paragraphs += \" \" + str1\n",
        "    data.append(new_paragraphs)\n",
        "\n",
        "  df[column] = data\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCQtbRS7slSV"
      },
      "outputs": [],
      "source": [
        "def unlistDatasetSummary(df, column: str):\n",
        "  data = []\n",
        "  for list1 in df[column]:\n",
        "    new_paragraphs = ''\n",
        "    for list2 in list1:\n",
        "      for str1 in list2:\n",
        "        new_paragraphs += \" \" + str1\n",
        "    data.append(new_paragraphs)\n",
        "\n",
        "  df[column] = data\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zgR1hFbsnF0"
      },
      "outputs": [],
      "source": [
        "def caseFolding (df, column:str):\n",
        "  data = []\n",
        "  for kalimat in df[column]:\n",
        "    data.append(kalimat.lower())\n",
        "  \n",
        "  df[column] = data\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKuN-xQUspWw"
      },
      "outputs": [],
      "source": [
        "def removingPunctuation(df, column:str):\n",
        "\n",
        "  data = []\n",
        "  for kalimat in df[column]:\n",
        "    new_kalimat = kalimat.translate(str.maketrans('', '', string.punctuation))\n",
        "    data.append(new_kalimat)\n",
        "\n",
        "  df[column] = data\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1I_jZ6vTsqFX"
      },
      "outputs": [],
      "source": [
        "def wordTokenization(df, column:str):\n",
        "  data = []\n",
        "  for kalimat in df[column]:\n",
        "    nltk_tokens = nltk.word_tokenize(kalimat)\n",
        "    data.append(nltk_tokens)\n",
        "\n",
        "  df[column] = data\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAercxmmss4E"
      },
      "outputs": [],
      "source": [
        "def addStartEnd(df, column: str):\n",
        "  data = []\n",
        "  for summary in df[column]:\n",
        "    summary.append('</s>')\n",
        "    summary.insert(0, '<s>')\n",
        "    data.append(summary)\n",
        "\n",
        "  df[column] = data\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCQtJM2-suza"
      },
      "outputs": [],
      "source": [
        "def shortText(df):\n",
        "\n",
        "  cleaned_paragraphs = np.array(df['clean_paragraphs'])\n",
        "  cleaned_summary= np.array(df['clean_summary'])\n",
        "\n",
        "  short_paragraphs = []\n",
        "  short_summary = []\n",
        "\n",
        "  for i in range(len(cleaned_paragraphs)):\n",
        "    if len(cleaned_summary[i]) <= max_summary_len and len(cleaned_paragraphs[i]) <= max_paragraphs_len: \n",
        "      short_paragraphs.append(cleaned_paragraphs[i])\n",
        "      short_summary.append(cleaned_summary[i])\n",
        "        \n",
        "  post_df = pd.DataFrame({'paragraphs': short_paragraphs,'summary': short_summary})\n",
        "  return post_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uytYRmAsvaM"
      },
      "outputs": [],
      "source": [
        "def showMax(df):\n",
        "  text_count = []\n",
        "  summary_count = []\n",
        "\n",
        "  for sent in df['clean_paragraphs']:\n",
        "      text_count.append(len(sent))\n",
        "      \n",
        "  for sent in df['clean_summary']:\n",
        "      summary_count.append(len(sent))\n",
        "\n",
        "  graph_df = pd.DataFrame() \n",
        "\n",
        "  graph_df['text'] = text_count\n",
        "  graph_df['summary'] = summary_count\n",
        "\n",
        "  graph_df.hist(bins = 5)\n",
        "  plt.show()\n",
        "\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fG0sOLk-sxQn"
      },
      "outputs": [],
      "source": [
        "train1 = pd.read_json(path_or_buf=r'/content/drive/MyDrive/Dataset TA/train.01.jsonl', lines=True)\n",
        "train2 = pd.read_json(path_or_buf=r'/content/drive/MyDrive/Dataset TA/train.02.jsonl', lines=True)\n",
        "train3 = pd.read_json(path_or_buf=r'/content/drive/MyDrive/Dataset TA/train.03.jsonl', lines=True)\n",
        "train4 = pd.read_json(path_or_buf=r'/content/drive/MyDrive/Dataset TA/train.04.jsonl', lines=True)\n",
        "train5 = pd.read_json(path_or_buf=r'/content/drive/MyDrive/Dataset TA/train.05.jsonl', lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVS2SuZKtG4K",
        "outputId": "13628c50-6079-49d7-9c24-e0c741341116"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          category                                        gold_labels  \\\n",
              "0      tajuk utama  [[False, True], [True, True], [False, False, F...   \n",
              "1        teknologi  [[False, False, False, False], [False, True, T...   \n",
              "2          hiburan  [[True], [True], [False, False], [False], [Fal...   \n",
              "3      tajuk utama  [[True, True], [False, False, False], [True], ...   \n",
              "4      tajuk utama  [[False, True], [True, True, True], [False], [...   \n",
              "...            ...                                                ...   \n",
              "71348  tajuk utama  [[True], [True, True], [True, False], [False, ...   \n",
              "71349  tajuk utama  [[True, True], [False, False], [False, False],...   \n",
              "71350  tajuk utama    [[True, True], [True, False], [False], [False]]   \n",
              "71351     olahraga  [[True], [True, True], [False], [False], [Fals...   \n",
              "71352      hiburan  [[True], [False], [False, True], [True], [Fals...   \n",
              "\n",
              "                                                      id  \\\n",
              "0      1501893029-lula-kamal-dokter-ryan-thamrin-saki...   \n",
              "1      1509072914-dua-smartphone-zenfone-baru-tawarka...   \n",
              "2      1510613677-songsong-visit-2020-bengkulu-perkua...   \n",
              "3      1502706803-icw-ada-kejanggalan-atas-tewasnya-s...   \n",
              "4      1503039338-pembagian-sepeda-usai-upacara-penur...   \n",
              "...                                                  ...   \n",
              "71348  1494387000-bongkar-pungli-rutan-bungkuk-polisi...   \n",
              "71349  1503822625-implementasi-het-beras-kementan-pun...   \n",
              "71350       1491261317-menhub-panggil-manajemen-lion-air   \n",
              "71351  1502994600-conor-mcgregor-lebih-siap-daripada-...   \n",
              "71352  1503286200-pendaki-gunung-tambora-diperkirakan...   \n",
              "\n",
              "                                              paragraphs          source  \\\n",
              "0      [[[Jakarta, ,, CNN, Indonesia, -, -, Dokter, R...   cnn indonesia   \n",
              "1      [[[Selfie, ialah, salah, satu, tema, terpanas,...  dailysocial.id   \n",
              "2      [[[Jakarta, ,, CNN, Indonesia, -, -, Dinas, Pa...   cnn indonesia   \n",
              "3      [[[Merdeka.com, -, Indonesia, Corruption, Watc...         merdeka   \n",
              "4      [[[Merdeka.com, -, Presiden, Joko, Widodo, (, ...         merdeka   \n",
              "...                                                  ...             ...   \n",
              "71348  [[[Merdeka.com, -, Direktorat, Reserse, Krimin...         merdeka   \n",
              "71349  [[[Merdeka.com, -, Kementerian, Perdagangan, t...         merdeka   \n",
              "71350  [[[Rimanews, -, Menteri, Perhubungan, Budi, Ka...        rimanews   \n",
              "71351  [[[JUARA.net, -, Duel, antara, Floyd, Mayweath...       juara.net   \n",
              "71352  [[[Mataram, (, ANTARA, News, ), -, Kepala, Bal...      antaranews   \n",
              "\n",
              "                                              source_url  \\\n",
              "0      https://www.cnnindonesia.com/hiburan/201708041...   \n",
              "1      https://dailysocial.id/post/dua-smartphone-zen...   \n",
              "2      https://www.cnnindonesia.com/gaya-hidup/201711...   \n",
              "3      https://www.merdeka.com/peristiwa/icw-merasa-a...   \n",
              "4      https://www.merdeka.com/peristiwa/usai-upacara...   \n",
              "...                                                  ...   \n",
              "71348  https://www.merdeka.com/peristiwa/bongkar-pung...   \n",
              "71349  https://www.merdeka.com/uang/implementasi-het-...   \n",
              "71350  http://rimanews.com/nasional/peristiwa/read/20...   \n",
              "71351  http://juara.bolasport.com/read/ragam/ragam/18...   \n",
              "71352  http://www.antaranews.com/berita/647551/pendak...   \n",
              "\n",
              "                                                 summary  \n",
              "0      [[Dokter, Lula, Kamal, yang, merupakan, selebr...  \n",
              "1      [[Asus, memperkenalkan, , ZenFone, generasi, ...  \n",
              "2      [[Dinas, Pariwisata, Provinsi, Bengkulu, kemba...  \n",
              "3      [[Indonesia, Corruption, Watch, (, ICW, ), mem...  \n",
              "4      [[Jokowi, memimpin, upacara, penurunan, bender...  \n",
              "...                                                  ...  \n",
              "71348  [[Direktorat, Reserse, Kriminal, Khususnya, Po...  \n",
              "71349  [[Kementerian, Perdagangan, telah, menetapkan,...  \n",
              "71350  [[Menteri, Perhubungan, Budi, Karya, Sumadi, a...  \n",
              "71351  [[Sejumlah, persipan, jelang, duel, antara, Fl...  \n",
              "71352  [[Kepala, Balai, Taman, Nasional, Tambora, Bud...  \n",
              "\n",
              "[71353 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-def3088f-3a9f-4ab2-a33f-48553b970b69\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>gold_labels</th>\n",
              "      <th>id</th>\n",
              "      <th>paragraphs</th>\n",
              "      <th>source</th>\n",
              "      <th>source_url</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tajuk utama</td>\n",
              "      <td>[[False, True], [True, True], [False, False, F...</td>\n",
              "      <td>1501893029-lula-kamal-dokter-ryan-thamrin-saki...</td>\n",
              "      <td>[[[Jakarta, ,, CNN, Indonesia, -, -, Dokter, R...</td>\n",
              "      <td>cnn indonesia</td>\n",
              "      <td>https://www.cnnindonesia.com/hiburan/201708041...</td>\n",
              "      <td>[[Dokter, Lula, Kamal, yang, merupakan, selebr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>teknologi</td>\n",
              "      <td>[[False, False, False, False], [False, True, T...</td>\n",
              "      <td>1509072914-dua-smartphone-zenfone-baru-tawarka...</td>\n",
              "      <td>[[[Selfie, ialah, salah, satu, tema, terpanas,...</td>\n",
              "      <td>dailysocial.id</td>\n",
              "      <td>https://dailysocial.id/post/dua-smartphone-zen...</td>\n",
              "      <td>[[Asus, memperkenalkan, , ZenFone, generasi, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hiburan</td>\n",
              "      <td>[[True], [True], [False, False], [False], [Fal...</td>\n",
              "      <td>1510613677-songsong-visit-2020-bengkulu-perkua...</td>\n",
              "      <td>[[[Jakarta, ,, CNN, Indonesia, -, -, Dinas, Pa...</td>\n",
              "      <td>cnn indonesia</td>\n",
              "      <td>https://www.cnnindonesia.com/gaya-hidup/201711...</td>\n",
              "      <td>[[Dinas, Pariwisata, Provinsi, Bengkulu, kemba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tajuk utama</td>\n",
              "      <td>[[True, True], [False, False, False], [True], ...</td>\n",
              "      <td>1502706803-icw-ada-kejanggalan-atas-tewasnya-s...</td>\n",
              "      <td>[[[Merdeka.com, -, Indonesia, Corruption, Watc...</td>\n",
              "      <td>merdeka</td>\n",
              "      <td>https://www.merdeka.com/peristiwa/icw-merasa-a...</td>\n",
              "      <td>[[Indonesia, Corruption, Watch, (, ICW, ), mem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tajuk utama</td>\n",
              "      <td>[[False, True], [True, True, True], [False], [...</td>\n",
              "      <td>1503039338-pembagian-sepeda-usai-upacara-penur...</td>\n",
              "      <td>[[[Merdeka.com, -, Presiden, Joko, Widodo, (, ...</td>\n",
              "      <td>merdeka</td>\n",
              "      <td>https://www.merdeka.com/peristiwa/usai-upacara...</td>\n",
              "      <td>[[Jokowi, memimpin, upacara, penurunan, bender...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71348</th>\n",
              "      <td>tajuk utama</td>\n",
              "      <td>[[True], [True, True], [True, False], [False, ...</td>\n",
              "      <td>1494387000-bongkar-pungli-rutan-bungkuk-polisi...</td>\n",
              "      <td>[[[Merdeka.com, -, Direktorat, Reserse, Krimin...</td>\n",
              "      <td>merdeka</td>\n",
              "      <td>https://www.merdeka.com/peristiwa/bongkar-pung...</td>\n",
              "      <td>[[Direktorat, Reserse, Kriminal, Khususnya, Po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71349</th>\n",
              "      <td>tajuk utama</td>\n",
              "      <td>[[True, True], [False, False], [False, False],...</td>\n",
              "      <td>1503822625-implementasi-het-beras-kementan-pun...</td>\n",
              "      <td>[[[Merdeka.com, -, Kementerian, Perdagangan, t...</td>\n",
              "      <td>merdeka</td>\n",
              "      <td>https://www.merdeka.com/uang/implementasi-het-...</td>\n",
              "      <td>[[Kementerian, Perdagangan, telah, menetapkan,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71350</th>\n",
              "      <td>tajuk utama</td>\n",
              "      <td>[[True, True], [True, False], [False], [False]]</td>\n",
              "      <td>1491261317-menhub-panggil-manajemen-lion-air</td>\n",
              "      <td>[[[Rimanews, -, Menteri, Perhubungan, Budi, Ka...</td>\n",
              "      <td>rimanews</td>\n",
              "      <td>http://rimanews.com/nasional/peristiwa/read/20...</td>\n",
              "      <td>[[Menteri, Perhubungan, Budi, Karya, Sumadi, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71351</th>\n",
              "      <td>olahraga</td>\n",
              "      <td>[[True], [True, True], [False], [False], [Fals...</td>\n",
              "      <td>1502994600-conor-mcgregor-lebih-siap-daripada-...</td>\n",
              "      <td>[[[JUARA.net, -, Duel, antara, Floyd, Mayweath...</td>\n",
              "      <td>juara.net</td>\n",
              "      <td>http://juara.bolasport.com/read/ragam/ragam/18...</td>\n",
              "      <td>[[Sejumlah, persipan, jelang, duel, antara, Fl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71352</th>\n",
              "      <td>hiburan</td>\n",
              "      <td>[[True], [False], [False, True], [True], [Fals...</td>\n",
              "      <td>1503286200-pendaki-gunung-tambora-diperkirakan...</td>\n",
              "      <td>[[[Mataram, (, ANTARA, News, ), -, Kepala, Bal...</td>\n",
              "      <td>antaranews</td>\n",
              "      <td>http://www.antaranews.com/berita/647551/pendak...</td>\n",
              "      <td>[[Kepala, Balai, Taman, Nasional, Tambora, Bud...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>71353 rows  7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-def3088f-3a9f-4ab2-a33f-48553b970b69')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-def3088f-3a9f-4ab2-a33f-48553b970b69 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-def3088f-3a9f-4ab2-a33f-48553b970b69');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "full_train = pd.concat([train1, train2, train3, train4, train5], ignore_index=True)\n",
        "full_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlkpNoEqtacm"
      },
      "outputs": [],
      "source": [
        "test1 = pd.read_json(path_or_buf=r'/content/drive/MyDrive/Dataset TA/test.01.jsonl', lines=True)\n",
        "test2 = pd.read_json(path_or_buf=r'/content/drive/MyDrive/Dataset TA/test.02.jsonl', lines=True)\n",
        "test3 = pd.read_json(path_or_buf=r'/content/drive/MyDrive/Dataset TA/test.03.jsonl', lines=True)\n",
        "test4 = pd.read_json(path_or_buf=r'/content/drive/MyDrive/Dataset TA/test.04.jsonl', lines=True)\n",
        "test5 = pd.read_json(path_or_buf=r'/content/drive/MyDrive/Dataset TA/test.05.jsonl', lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eI3cxAJOt0OJ",
        "outputId": "0fc3e9a9-250d-423a-b21d-a6eb02f92acb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          category                                        gold_labels  \\\n",
              "0          hiburan  [[False], [True], [False], [True, False], [Fal...   \n",
              "1      tajuk utama  [[True, True], [True, True, True], [False, Fal...   \n",
              "2          showbiz  [[True], [True], [False], [True], [False], [Fa...   \n",
              "3      tajuk utama  [[True, True], [False], [False, False], [False...   \n",
              "4        teknologi  [[False, False, True], [True, True], [False, F...   \n",
              "...            ...                                                ...   \n",
              "18769  tajuk utama  [[True, False], [False, False], [True], [True]...   \n",
              "18770     olahraga  [[True, True], [False, False], [True, True], [...   \n",
              "18771    teknologi  [[False, True, True, False, False], [False], [...   \n",
              "18772  tajuk utama  [[True, True], [True, True], [True], [False], ...   \n",
              "18773    teknologi  [[False, False], [True], [False], [False], [Tr...   \n",
              "\n",
              "                                                      id  \\\n",
              "0      1494135000-wanita-terberat-di-dunia-jalani-fis...   \n",
              "1      1501222980-kemhan-ingin-beli-drone-dari-china-...   \n",
              "2         1475739008-film-mean-girls-akan-dibuat-musikal   \n",
              "3      1505785500-eggi-sudjana-sumpah-demi-allah-saya...   \n",
              "4        1497394800-kartu-muslim-optimalkan-teknologi-ar   \n",
              "...                                                  ...   \n",
              "18769  1519195500-persiapan-pilpres-zulkifli-hasan-te...   \n",
              "18770  1518206400-andik-vermansah-diklaim-resmi-gabun...   \n",
              "18771  1501214400-kaskus-kini-fokus-ke-pengembangan-p...   \n",
              "18772  1500930900-kebakaran-hutan-dan-lahan-kabut-asa...   \n",
              "18773  1511229600-facebook-luncurkan-aplikasi-baru-un...   \n",
              "\n",
              "                                              paragraphs          source  \\\n",
              "0      [[[Jakarta, ,, CNN, Indonesia, -, -, Dilansir,...   cnn indonesia   \n",
              "1      [[[Menteri, Pertahanan, Ryamizard, Ryacudu, me...        kumparan   \n",
              "2      [[[Jakarta, ,, CNN, Indonesia, -, -, Meski, su...   cnn indonesia   \n",
              "3      [[[Usai, melaksanakan, ibadah, haji, ,, Eggi, ...        kumparan   \n",
              "4      [[[Banyak, cara, untuk, memberikan, pengajaran...  dailysocial.id   \n",
              "...                                                  ...             ...   \n",
              "18769  [[[Suara.com, -, Ketua, Umum, DPP, Partai, Ama...           suara   \n",
              "18770  [[[Jakarta, ,, CNN, Indonesia, -, -, Winger, T...   cnn indonesia   \n",
              "18771  [[[Sebagai, seorang, pengguna, Kaskus, yang, p...  dailysocial.id   \n",
              "18772  [[[Jakarta, ,, CNN, Indonesia, -, -, Kabut, as...   cnn indonesia   \n",
              "18773  [[[Misi, Facebook, mengkudeta, Snapchat, terbi...  dailysocial.id   \n",
              "\n",
              "                                              source_url  \\\n",
              "0      http://www.cnnindonesia.com/gaya-hidup/2017050...   \n",
              "1      https://kumparan.com/teuku-muhammad-valdy-arie...   \n",
              "2      http://www.cnnindonesia.com/hiburan/2016100514...   \n",
              "3      https://kumparan.com/rini-friastuti/eggi-sudja...   \n",
              "4      https://dailysocial.id/post/kartu-muslim-optim...   \n",
              "...                                                  ...   \n",
              "18769  https://www.suara.com/news/2018/02/20/183814/p...   \n",
              "18770  https://www.cnnindonesia.com/olahraga/20180209...   \n",
              "18771  https://dailysocial.id/post/inovasi-kaskus-kin...   \n",
              "18772  https://www.cnnindonesia.com/nasional/20170724...   \n",
              "18773  https://dailysocial.id/post/facebook-luncurkan...   \n",
              "\n",
              "                                                 summary  \n",
              "0      [[Eman, Ahmed, Abd, El, Aty, memiliki, berat, ...  \n",
              "1      [[Menteri, Pertahanan, Ryamizard, Ryacudu, men...  \n",
              "2      [[Rumah, produksi, film, yang, dibintangi, Lin...  \n",
              "3      [[Eggi, Sudjana, akhirnya, mendatangi, kantor,...  \n",
              "4      [[Game, permainan, Kartu, Muslim, .], [Menggun...  \n",
              "...                                                  ...  \n",
              "18769  [[Ketua, Umum, DPP, Partai, Amanat, Nasional, ...  \n",
              "18770  [[Winger, Timnas, Indonesia, ,, Andik, Vermans...  \n",
              "18771  [[Kaskus, saat, ini, sudah, jauh, berbeda, kar...  \n",
              "18772  [[Kabut, asap, menyelimuti, Kota, Meulaboh, ,,...  \n",
              "18773  [[Facebook, Creator, dirancang, untuk, membant...  \n",
              "\n",
              "[18774 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-021f00df-7d6c-4194-82ad-0dd713751732\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>gold_labels</th>\n",
              "      <th>id</th>\n",
              "      <th>paragraphs</th>\n",
              "      <th>source</th>\n",
              "      <th>source_url</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hiburan</td>\n",
              "      <td>[[False], [True], [False], [True, False], [Fal...</td>\n",
              "      <td>1494135000-wanita-terberat-di-dunia-jalani-fis...</td>\n",
              "      <td>[[[Jakarta, ,, CNN, Indonesia, -, -, Dilansir,...</td>\n",
              "      <td>cnn indonesia</td>\n",
              "      <td>http://www.cnnindonesia.com/gaya-hidup/2017050...</td>\n",
              "      <td>[[Eman, Ahmed, Abd, El, Aty, memiliki, berat, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tajuk utama</td>\n",
              "      <td>[[True, True], [True, True, True], [False, Fal...</td>\n",
              "      <td>1501222980-kemhan-ingin-beli-drone-dari-china-...</td>\n",
              "      <td>[[[Menteri, Pertahanan, Ryamizard, Ryacudu, me...</td>\n",
              "      <td>kumparan</td>\n",
              "      <td>https://kumparan.com/teuku-muhammad-valdy-arie...</td>\n",
              "      <td>[[Menteri, Pertahanan, Ryamizard, Ryacudu, men...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>showbiz</td>\n",
              "      <td>[[True], [True], [False], [True], [False], [Fa...</td>\n",
              "      <td>1475739008-film-mean-girls-akan-dibuat-musikal</td>\n",
              "      <td>[[[Jakarta, ,, CNN, Indonesia, -, -, Meski, su...</td>\n",
              "      <td>cnn indonesia</td>\n",
              "      <td>http://www.cnnindonesia.com/hiburan/2016100514...</td>\n",
              "      <td>[[Rumah, produksi, film, yang, dibintangi, Lin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tajuk utama</td>\n",
              "      <td>[[True, True], [False], [False, False], [False...</td>\n",
              "      <td>1505785500-eggi-sudjana-sumpah-demi-allah-saya...</td>\n",
              "      <td>[[[Usai, melaksanakan, ibadah, haji, ,, Eggi, ...</td>\n",
              "      <td>kumparan</td>\n",
              "      <td>https://kumparan.com/rini-friastuti/eggi-sudja...</td>\n",
              "      <td>[[Eggi, Sudjana, akhirnya, mendatangi, kantor,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>teknologi</td>\n",
              "      <td>[[False, False, True], [True, True], [False, F...</td>\n",
              "      <td>1497394800-kartu-muslim-optimalkan-teknologi-ar</td>\n",
              "      <td>[[[Banyak, cara, untuk, memberikan, pengajaran...</td>\n",
              "      <td>dailysocial.id</td>\n",
              "      <td>https://dailysocial.id/post/kartu-muslim-optim...</td>\n",
              "      <td>[[Game, permainan, Kartu, Muslim, .], [Menggun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18769</th>\n",
              "      <td>tajuk utama</td>\n",
              "      <td>[[True, False], [False, False], [True], [True]...</td>\n",
              "      <td>1519195500-persiapan-pilpres-zulkifli-hasan-te...</td>\n",
              "      <td>[[[Suara.com, -, Ketua, Umum, DPP, Partai, Ama...</td>\n",
              "      <td>suara</td>\n",
              "      <td>https://www.suara.com/news/2018/02/20/183814/p...</td>\n",
              "      <td>[[Ketua, Umum, DPP, Partai, Amanat, Nasional, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18770</th>\n",
              "      <td>olahraga</td>\n",
              "      <td>[[True, True], [False, False], [True, True], [...</td>\n",
              "      <td>1518206400-andik-vermansah-diklaim-resmi-gabun...</td>\n",
              "      <td>[[[Jakarta, ,, CNN, Indonesia, -, -, Winger, T...</td>\n",
              "      <td>cnn indonesia</td>\n",
              "      <td>https://www.cnnindonesia.com/olahraga/20180209...</td>\n",
              "      <td>[[Winger, Timnas, Indonesia, ,, Andik, Vermans...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18771</th>\n",
              "      <td>teknologi</td>\n",
              "      <td>[[False, True, True, False, False], [False], [...</td>\n",
              "      <td>1501214400-kaskus-kini-fokus-ke-pengembangan-p...</td>\n",
              "      <td>[[[Sebagai, seorang, pengguna, Kaskus, yang, p...</td>\n",
              "      <td>dailysocial.id</td>\n",
              "      <td>https://dailysocial.id/post/inovasi-kaskus-kin...</td>\n",
              "      <td>[[Kaskus, saat, ini, sudah, jauh, berbeda, kar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18772</th>\n",
              "      <td>tajuk utama</td>\n",
              "      <td>[[True, True], [True, True], [True], [False], ...</td>\n",
              "      <td>1500930900-kebakaran-hutan-dan-lahan-kabut-asa...</td>\n",
              "      <td>[[[Jakarta, ,, CNN, Indonesia, -, -, Kabut, as...</td>\n",
              "      <td>cnn indonesia</td>\n",
              "      <td>https://www.cnnindonesia.com/nasional/20170724...</td>\n",
              "      <td>[[Kabut, asap, menyelimuti, Kota, Meulaboh, ,,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18773</th>\n",
              "      <td>teknologi</td>\n",
              "      <td>[[False, False], [True], [False], [False], [Tr...</td>\n",
              "      <td>1511229600-facebook-luncurkan-aplikasi-baru-un...</td>\n",
              "      <td>[[[Misi, Facebook, mengkudeta, Snapchat, terbi...</td>\n",
              "      <td>dailysocial.id</td>\n",
              "      <td>https://dailysocial.id/post/facebook-luncurkan...</td>\n",
              "      <td>[[Facebook, Creator, dirancang, untuk, membant...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18774 rows  7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-021f00df-7d6c-4194-82ad-0dd713751732')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-021f00df-7d6c-4194-82ad-0dd713751732 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-021f00df-7d6c-4194-82ad-0dd713751732');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "full_test = pd.concat([test1, test2, test3, test4, test5], ignore_index=True)\n",
        "full_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxcltMMNt202"
      },
      "outputs": [],
      "source": [
        "dev1 = pd.read_json(path_or_buf='/content/drive/MyDrive/Dataset TA/dev.01.jsonl', lines=True)\n",
        "dev2 = pd.read_json(path_or_buf='/content/drive/MyDrive/Dataset TA/dev.02.jsonl', lines=True)\n",
        "dev3 = pd.read_json(path_or_buf='/content/drive/MyDrive/Dataset TA/dev.03.jsonl', lines=True)\n",
        "dev4 = pd.read_json(path_or_buf='/content/drive/MyDrive/Dataset TA/dev.04.jsonl', lines=True)\n",
        "dev5 = pd.read_json(path_or_buf='/content/drive/MyDrive/Dataset TA/dev.05.jsonl', lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0L7Ac0ut5H_",
        "outputId": "1507a2f7-e51a-4e76-e8c1-6e8bf9e6704e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         category                                        gold_labels  \\\n",
              "0     tajuk utama  [[True, True], [True], [False, False, False], ...   \n",
              "1         showbiz  [[True, True], [False], [False, False], [True,...   \n",
              "2     tajuk utama  [[True, False], [True, True], [False, False, F...   \n",
              "3        olahraga  [[True, True], [False, False, False, False], [...   \n",
              "4         hiburan                          [[True], [True], [False]]   \n",
              "...           ...                                                ...   \n",
              "3738  tajuk utama  [[True, True], [False], [False], [True], [Fals...   \n",
              "3739  tajuk utama  [[True], [True], [True], [False], [False, Fals...   \n",
              "3740    teknologi  [[True, False, True], [True, False], [False, F...   \n",
              "3741  tajuk utama  [[True], [False, False], [True], [False, False...   \n",
              "3742     olahraga  [[True], [True], [True], [False, False], [Fals...   \n",
              "\n",
              "                                                     id  \\\n",
              "0     1490674536-mustahil-transportasi-tradisional-d...   \n",
              "1     1504900800-bocor-james-bond-nikah-di-sekuel-te...   \n",
              "2     1489536002-mentan-lepas-ekspor-perdana-daging-...   \n",
              "3             1514112565-hasil-real-madrid-vs-barcelona   \n",
              "4     1508483400-jayawijaya-datangkan-arkeolog-untuk...   \n",
              "...                                                 ...   \n",
              "3738  1498371300-dapat-remisi-382-narapidana-bebas-s...   \n",
              "3739  1509745710-jokowi-tagih-janji-kapolri-tuntaska...   \n",
              "3740  1501649557-microsoft-pensiunkan-aplikasi-word-...   \n",
              "3741  1518152939-luhut-janjikan-pembebasan-lahan-ker...   \n",
              "3742  1506745137-sebastian-vettel-jadi-yang-tercepat...   \n",
              "\n",
              "                                             paragraphs          source  \\\n",
              "0     [[[Ketua, MPR, Zulkifli, Hasan, menyesalkan, k...        kumparan   \n",
              "1     [[[Suara.com, -, Cerita, sekuel, terbaru, Jame...           suara   \n",
              "2     [[[Menteri, Pertanian, Andi, Amran, Sulaiman, ...           suara   \n",
              "3     [[[SPANYOL, , Barcelona, berhasil, memboyong,...     poskotanews   \n",
              "4     [[[Wamena, (, ANTARA, News, ), -, Pemerintah, ...      antaranews   \n",
              "...                                                 ...             ...   \n",
              "3738  [[[Jakarta, ,, CNN, Indonesia, -, -, Total, 38...   cnn indonesia   \n",
              "3739  [[[Jakarta, ,, CNN, Indonesia, -, -, Presiden,...   cnn indonesia   \n",
              "3740  [[[Tahun, lalu, Microsoft, meramaikan, persain...  dailysocial.id   \n",
              "3741  [[[Suara.com, -, Menteri, Koordinator, Bidang,...           suara   \n",
              "3742  [[[JUARA.NET, ,, KUALA, LUMPUR, -, Pebalap, Sc...       juara.net   \n",
              "\n",
              "                                             source_url  \\\n",
              "0     https://kumparan.com/ananda-wardhiati-teresia/...   \n",
              "1     http://www.suara.com/entertainment/2017/09/06/...   \n",
              "2     http://www.suara.com/bisnis/2017/03/13/201620/...   \n",
              "3     http://poskotanews.com/2017/12/23/kalahkan-rea...   \n",
              "4     http://www.antaranews.com/berita/659644/jayawi...   \n",
              "...                                                 ...   \n",
              "3738  http://www.cnnindonesia.com/nasional/201706241...   \n",
              "3739  https://www.cnnindonesia.com/nasional/20171103...   \n",
              "3740    https://dailysocial.id/post/microsoft-word-flow   \n",
              "3741  https://www.suara.com/news/2018/02/08/140348/l...   \n",
              "3742  https://juara.bolasport.com/read/balap/f1/1821...   \n",
              "\n",
              "                                                summary  \n",
              "0     [[Ketua, MPR, Zulkifli, Hasan, menyesalkan, ki...  \n",
              "1     [[Cerita, sekuel, terbaru, James, Bond, bocor,...  \n",
              "2     [[Saat, ini, pemerintah, terus, meningkatkan, ...  \n",
              "3     [[Barcelona, berhasil, memboyong, kemenangan, ...  \n",
              "4     [[Pemerintah, Kabupaten, Jayawijaya, ,, Papua,...  \n",
              "...                                                 ...  \n",
              "3738  [[Total, 382, narapidana, beragama, Islam, beb...  \n",
              "3739  [[Presiden, Joko, Widodo, akan, kembali, mengu...  \n",
              "3740  [[Tahun, lalu, Microsoft, meramaikan, persaing...  \n",
              "3741  [[, Menteri, Koordinator, Bidang, Kemaritiman...  \n",
              "3742  [[Pebalap, Scuderia, Ferrari, ,, Sebastian, Ve...  \n",
              "\n",
              "[3743 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-210c8d91-c860-47b8-bfa0-9b6db8cb904e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>gold_labels</th>\n",
              "      <th>id</th>\n",
              "      <th>paragraphs</th>\n",
              "      <th>source</th>\n",
              "      <th>source_url</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tajuk utama</td>\n",
              "      <td>[[True, True], [True], [False, False, False], ...</td>\n",
              "      <td>1490674536-mustahil-transportasi-tradisional-d...</td>\n",
              "      <td>[[[Ketua, MPR, Zulkifli, Hasan, menyesalkan, k...</td>\n",
              "      <td>kumparan</td>\n",
              "      <td>https://kumparan.com/ananda-wardhiati-teresia/...</td>\n",
              "      <td>[[Ketua, MPR, Zulkifli, Hasan, menyesalkan, ki...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>showbiz</td>\n",
              "      <td>[[True, True], [False], [False, False], [True,...</td>\n",
              "      <td>1504900800-bocor-james-bond-nikah-di-sekuel-te...</td>\n",
              "      <td>[[[Suara.com, -, Cerita, sekuel, terbaru, Jame...</td>\n",
              "      <td>suara</td>\n",
              "      <td>http://www.suara.com/entertainment/2017/09/06/...</td>\n",
              "      <td>[[Cerita, sekuel, terbaru, James, Bond, bocor,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tajuk utama</td>\n",
              "      <td>[[True, False], [True, True], [False, False, F...</td>\n",
              "      <td>1489536002-mentan-lepas-ekspor-perdana-daging-...</td>\n",
              "      <td>[[[Menteri, Pertanian, Andi, Amran, Sulaiman, ...</td>\n",
              "      <td>suara</td>\n",
              "      <td>http://www.suara.com/bisnis/2017/03/13/201620/...</td>\n",
              "      <td>[[Saat, ini, pemerintah, terus, meningkatkan, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>olahraga</td>\n",
              "      <td>[[True, True], [False, False, False, False], [...</td>\n",
              "      <td>1514112565-hasil-real-madrid-vs-barcelona</td>\n",
              "      <td>[[[SPANYOL, , Barcelona, berhasil, memboyong,...</td>\n",
              "      <td>poskotanews</td>\n",
              "      <td>http://poskotanews.com/2017/12/23/kalahkan-rea...</td>\n",
              "      <td>[[Barcelona, berhasil, memboyong, kemenangan, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hiburan</td>\n",
              "      <td>[[True], [True], [False]]</td>\n",
              "      <td>1508483400-jayawijaya-datangkan-arkeolog-untuk...</td>\n",
              "      <td>[[[Wamena, (, ANTARA, News, ), -, Pemerintah, ...</td>\n",
              "      <td>antaranews</td>\n",
              "      <td>http://www.antaranews.com/berita/659644/jayawi...</td>\n",
              "      <td>[[Pemerintah, Kabupaten, Jayawijaya, ,, Papua,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3738</th>\n",
              "      <td>tajuk utama</td>\n",
              "      <td>[[True, True], [False], [False], [True], [Fals...</td>\n",
              "      <td>1498371300-dapat-remisi-382-narapidana-bebas-s...</td>\n",
              "      <td>[[[Jakarta, ,, CNN, Indonesia, -, -, Total, 38...</td>\n",
              "      <td>cnn indonesia</td>\n",
              "      <td>http://www.cnnindonesia.com/nasional/201706241...</td>\n",
              "      <td>[[Total, 382, narapidana, beragama, Islam, beb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3739</th>\n",
              "      <td>tajuk utama</td>\n",
              "      <td>[[True], [True], [True], [False], [False, Fals...</td>\n",
              "      <td>1509745710-jokowi-tagih-janji-kapolri-tuntaska...</td>\n",
              "      <td>[[[Jakarta, ,, CNN, Indonesia, -, -, Presiden,...</td>\n",
              "      <td>cnn indonesia</td>\n",
              "      <td>https://www.cnnindonesia.com/nasional/20171103...</td>\n",
              "      <td>[[Presiden, Joko, Widodo, akan, kembali, mengu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3740</th>\n",
              "      <td>teknologi</td>\n",
              "      <td>[[True, False, True], [True, False], [False, F...</td>\n",
              "      <td>1501649557-microsoft-pensiunkan-aplikasi-word-...</td>\n",
              "      <td>[[[Tahun, lalu, Microsoft, meramaikan, persain...</td>\n",
              "      <td>dailysocial.id</td>\n",
              "      <td>https://dailysocial.id/post/microsoft-word-flow</td>\n",
              "      <td>[[Tahun, lalu, Microsoft, meramaikan, persaing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3741</th>\n",
              "      <td>tajuk utama</td>\n",
              "      <td>[[True], [False, False], [True], [False, False...</td>\n",
              "      <td>1518152939-luhut-janjikan-pembebasan-lahan-ker...</td>\n",
              "      <td>[[[Suara.com, -, Menteri, Koordinator, Bidang,...</td>\n",
              "      <td>suara</td>\n",
              "      <td>https://www.suara.com/news/2018/02/08/140348/l...</td>\n",
              "      <td>[[, Menteri, Koordinator, Bidang, Kemaritiman...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3742</th>\n",
              "      <td>olahraga</td>\n",
              "      <td>[[True], [True], [True], [False, False], [Fals...</td>\n",
              "      <td>1506745137-sebastian-vettel-jadi-yang-tercepat...</td>\n",
              "      <td>[[[JUARA.NET, ,, KUALA, LUMPUR, -, Pebalap, Sc...</td>\n",
              "      <td>juara.net</td>\n",
              "      <td>https://juara.bolasport.com/read/balap/f1/1821...</td>\n",
              "      <td>[[Pebalap, Scuderia, Ferrari, ,, Sebastian, Ve...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3743 rows  7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-210c8d91-c860-47b8-bfa0-9b6db8cb904e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-210c8d91-c860-47b8-bfa0-9b6db8cb904e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-210c8d91-c860-47b8-bfa0-9b6db8cb904e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "full_dev = pd.concat([dev1, dev2, dev3, dev4, dev5], ignore_index=True)\n",
        "full_dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuDqlTwfuCw3"
      },
      "outputs": [],
      "source": [
        "full_dataset = pd.concat([full_dev, full_train, full_test], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHj96DVpuFea"
      },
      "outputs": [],
      "source": [
        "full_dataset = full_dataset[full_dataset.category == 'teknologi']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wAqw3w7uVds"
      },
      "outputs": [],
      "source": [
        "full_dataset = full_dataset.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILPgwGysutpJ"
      },
      "outputs": [],
      "source": [
        "full_dataset_unlist = full_dataset.copy()\n",
        "unlistDatasetParagraphs(full_dataset_unlist, 'paragraphs')\n",
        "unlistDatasetSummary(full_dataset_unlist, 'summary')\n",
        "full_dataset['clean_paragraphs'] = full_dataset_unlist['paragraphs']\n",
        "full_dataset['clean_summary'] = full_dataset_unlist['summary']\n",
        "caseFolding(full_dataset, 'clean_paragraphs')\n",
        "caseFolding(full_dataset, 'clean_summary')\n",
        "removingPunctuation(full_dataset, 'clean_paragraphs')\n",
        "removingPunctuation(full_dataset, 'clean_summary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoMDDGv9u6nE"
      },
      "outputs": [],
      "source": [
        "wordTokenization(full_dataset, 'clean_paragraphs')\n",
        "wordTokenization(full_dataset, 'clean_summary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNWYBaczu-dC",
        "outputId": "bf61cefb-4628-4b05-ce3b-10332077f815"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "showMax(full_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uMX7ge_vAP-",
        "outputId": "e1732e5c-6e3e-4bd3-add9-4999b6489a54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9099435518888407\n"
          ]
        }
      ],
      "source": [
        "# Check how much % of text have 0-500 words\n",
        "cnt = 0\n",
        "for i in full_dataset['clean_paragraphs']:\n",
        "    if len(i) <= 500:\n",
        "        cnt = cnt + 1\n",
        "print(cnt / len(full_dataset['clean_paragraphs']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTHrlvfwvCMz",
        "outputId": "96c04809-9bfa-49a9-9303-8f4f0f38cddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9795918367346939\n"
          ]
        }
      ],
      "source": [
        "# Check how much % of text have 0-70 words\n",
        "cnt = 0\n",
        "for i in full_dataset['clean_summary']:\n",
        "    if len(i) <= 65:\n",
        "        cnt = cnt + 1\n",
        "print(cnt / len(full_dataset['clean_summary']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBpbaSWJvLJR"
      },
      "outputs": [],
      "source": [
        "max_paragraphs_len = 500\n",
        "max_summary_len = 65"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXwuNl0XvNZp"
      },
      "outputs": [],
      "source": [
        "addStartEnd(full_dataset, 'clean_summary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zj2dZWFyvPId"
      },
      "outputs": [],
      "source": [
        "post_full = shortText(full_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FbQaexC5l29"
      },
      "outputs": [],
      "source": [
        "post_full = post_full.head(10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxy2-ewI-R3a",
        "outputId": "b5e97e01-3a5a-42aa-d8c6-8fb6ff752662"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             paragraphs  \\\n",
              "0     [ada, yang, baru, dari, google, calendar, vers...   \n",
              "1     [berdiri, sejak, juli, 2016, platform, direkto...   \n",
              "2     [awalnya, hanya, tersedia, di, platform, windo...   \n",
              "3     [tren, kerja, remote, tidak, ngantor, setiap, ...   \n",
              "4     [pt, suzuki, indomobil, sales, sis, divisi, ro...   \n",
              "...                                                 ...   \n",
              "9832  [ada, yang, baru, dari, google, calendar, vers...   \n",
              "9833  [pebisnis, startup, selalu, melihat, peluang, ...   \n",
              "9834  [lomography, kembali, hadir, dengan, kamera, i...   \n",
              "9835  [sebagai, seorang, pengguna, kaskus, yang, per...   \n",
              "9836  [misi, facebook, mengkudeta, snapchat, terbila...   \n",
              "\n",
              "                                                summary  \n",
              "0     [<s>, tampilan, dari, google, calendar, versi,...  \n",
              "1     [<s>, gotomalls, mengklaim, sudah, menjalin, k...  \n",
              "2     [<s>, anda, kini, dapat, menghubungkan, cortan...  \n",
              "3     [<s>, salah, satu, startup, yang, sedang, meng...  \n",
              "4     [<s>, pt, suzuki, indomobil, sales, sis, divis...  \n",
              "...                                                 ...  \n",
              "9832  [<s>, tampilan, dari, google, calendar, versi,...  \n",
              "9833  [<s>, newsfeeding, bekerja, dengan, menawarkan...  \n",
              "9834  [<s>, lomography, kembali, hadir, dengan, kame...  \n",
              "9835  [<s>, kaskus, saat, ini, sudah, jauh, berbeda,...  \n",
              "9836  [<s>, facebook, creator, dirancang, untuk, mem...  \n",
              "\n",
              "[9837 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8992b956-6a88-4682-aced-ed54586a907d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paragraphs</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[ada, yang, baru, dari, google, calendar, vers...</td>\n",
              "      <td>[&lt;s&gt;, tampilan, dari, google, calendar, versi,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[berdiri, sejak, juli, 2016, platform, direkto...</td>\n",
              "      <td>[&lt;s&gt;, gotomalls, mengklaim, sudah, menjalin, k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[awalnya, hanya, tersedia, di, platform, windo...</td>\n",
              "      <td>[&lt;s&gt;, anda, kini, dapat, menghubungkan, cortan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[tren, kerja, remote, tidak, ngantor, setiap, ...</td>\n",
              "      <td>[&lt;s&gt;, salah, satu, startup, yang, sedang, meng...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[pt, suzuki, indomobil, sales, sis, divisi, ro...</td>\n",
              "      <td>[&lt;s&gt;, pt, suzuki, indomobil, sales, sis, divis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9832</th>\n",
              "      <td>[ada, yang, baru, dari, google, calendar, vers...</td>\n",
              "      <td>[&lt;s&gt;, tampilan, dari, google, calendar, versi,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9833</th>\n",
              "      <td>[pebisnis, startup, selalu, melihat, peluang, ...</td>\n",
              "      <td>[&lt;s&gt;, newsfeeding, bekerja, dengan, menawarkan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9834</th>\n",
              "      <td>[lomography, kembali, hadir, dengan, kamera, i...</td>\n",
              "      <td>[&lt;s&gt;, lomography, kembali, hadir, dengan, kame...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9835</th>\n",
              "      <td>[sebagai, seorang, pengguna, kaskus, yang, per...</td>\n",
              "      <td>[&lt;s&gt;, kaskus, saat, ini, sudah, jauh, berbeda,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9836</th>\n",
              "      <td>[misi, facebook, mengkudeta, snapchat, terbila...</td>\n",
              "      <td>[&lt;s&gt;, facebook, creator, dirancang, untuk, mem...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9837 rows  2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8992b956-6a88-4682-aced-ed54586a907d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8992b956-6a88-4682-aced-ed54586a907d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8992b956-6a88-4682-aced-ed54586a907d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "post_full"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbSPZNyEvSpz"
      },
      "source": [
        "# Fit Sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myMeVL5ovVIm"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, x_test, Y, y_test = train_test_split(\n",
        "  np.array(post_full[\"paragraphs\"]),\n",
        "  np.array(post_full[\"summary\"]),\n",
        "  test_size=0.1,\n",
        "  random_state=0,\n",
        "  shuffle=True,\n",
        ")\n",
        "\n",
        "x_tr, x_val, y_tr, y_val = train_test_split(\n",
        "  X,\n",
        "  Y,\n",
        "  test_size=0.1,\n",
        "  random_state=0,\n",
        "  shuffle=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAj03TFkvcr-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da883f23-3e99-4c78-a9a3-f2b390a6fc94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of rare words in vocabulary:  16.40423288119568\n",
            "Size of vocabulary in X = 27500\n"
          ]
        }
      ],
      "source": [
        "# Tokenize the text to get the vocab count \n",
        "from tensorflow.keras.preprocessing.text import Tokenizer \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Prepare a tokenizer on training data\n",
        "x_tokenizer = Tokenizer()\n",
        "x_tokenizer.fit_on_texts(list(X))\n",
        "\n",
        "thresh = 5\n",
        "\n",
        "cnt = 0\n",
        "tot_cnt = 0\n",
        "\n",
        "for key, value in x_tokenizer.word_counts.items():\n",
        "    tot_cnt = tot_cnt + 1\n",
        "    if value < thresh:\n",
        "        cnt = cnt + 1\n",
        "    \n",
        "print(\"% of rare words in vocabulary: \", (cnt / tot_cnt) * 100)\n",
        "\n",
        "# Prepare a tokenizer, again -- by not considering the rare words\n",
        "x_tokenizer = Tokenizer() \n",
        "x_tokenizer.fit_on_texts(list(X))\n",
        "\n",
        "# Convert text sequences to integer sequences \n",
        "x_tr_seq = x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq = x_tokenizer.texts_to_sequences(x_val)\n",
        "x_test_seq = x_tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "# Pad zero upto maximum length\n",
        "x_tr = pad_sequences(x_tr_seq,  maxlen=max_paragraphs_len, padding='post')\n",
        "x_val = pad_sequences(x_val_seq, maxlen=max_paragraphs_len, padding='post')\n",
        "x_test = pad_sequences(x_test_seq, maxlen=max_paragraphs_len, padding='post')\n",
        "\n",
        "# Size of vocabulary (+1 for padding token)\n",
        "x_voc = len(x_tokenizer.word_index) + 1\n",
        "\n",
        "print(\"Size of vocabulary in X = {}\".format(x_voc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDOCpwSavfX4",
        "outputId": "8d3052e8-1a99-4769-e4ae-4029c6642fc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of rare words in vocabulary: 18.47592194108481\n",
            "Size of vocabulary in Y = 13478\n"
          ]
        }
      ],
      "source": [
        "# Prepare a tokenizer on testing data\n",
        "y_tokenizer = Tokenizer()   \n",
        "y_tokenizer.fit_on_texts(list(Y))\n",
        "\n",
        "thresh = 5\n",
        "\n",
        "cnt = 0\n",
        "tot_cnt = 0\n",
        "\n",
        "for key, value in y_tokenizer.word_counts.items():\n",
        "    tot_cnt = tot_cnt + 1\n",
        "    if value < thresh:\n",
        "        cnt = cnt + 1\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt / tot_cnt) * 100)\n",
        "\n",
        "# Prepare a tokenizer, again -- by not considering the rare words\n",
        "y_tokenizer = Tokenizer() \n",
        "y_tokenizer.fit_on_texts(list(Y))\n",
        "\n",
        "# Convert text sequences to integer sequences \n",
        "y_tr_seq = y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_seq = y_tokenizer.texts_to_sequences(y_val)\n",
        "y_test_seq = y_tokenizer.texts_to_sequences(y_test)\n",
        "\n",
        "# Pad zero upto maximum length\n",
        "y_tr = pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
        "y_val = pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
        "y_test = pad_sequences(y_test_seq, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "# Size of vocabulary (+1 for padding token)\n",
        "y_voc = len(y_tokenizer.word_index) + 1\n",
        "\n",
        "print(\"Size of vocabulary in Y = {}\".format(y_voc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X9Rrn4Bvr1O"
      },
      "source": [
        "# Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fc9ZLDMAvuWI"
      },
      "outputs": [],
      "source": [
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "glove_file = open('/content/drive/MyDrive/Dataset TA/glove_id/glove_50dim_wiki.id.case.text.txt', encoding=\"utf8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRYkcfxNvvxi"
      },
      "outputs": [],
      "source": [
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary [word] = vector_dimensions\n",
        "\n",
        "glove_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCPxEnwuvxQh"
      },
      "outputs": [],
      "source": [
        "x_embedding_matrix = zeros((x_voc, 50))\n",
        "for word, index in x_tokenizer.word_index.items():\n",
        "    x_embedding_vector = embeddings_dictionary.get(word)\n",
        "    if x_embedding_vector is not None:\n",
        "        x_embedding_matrix[index] = x_embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zVlUgSFvzJ1"
      },
      "outputs": [],
      "source": [
        "y_embedding_matrix = zeros((y_voc, 50))\n",
        "for word, index in y_tokenizer.word_index.items():\n",
        "    y_embedding_vector = embeddings_dictionary.get(word)\n",
        "    if y_embedding_vector is not None:\n",
        "        y_embedding_matrix[index] = y_embedding_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh4se3Nwvj7T"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4M9R9AOvjKm"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, \\\n",
        "    Concatenate, TimeDistributed, Bidirectional, GRU, Attention\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoW-189DvojW",
        "outputId": "01cee9f7-679e-44d1-ce14-42f9032616f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 500)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 500, 300)     8250000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " primary_encoder (Bidirectional  (None, 500, 200)    241200      ['embedding[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 300)    4043400     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " secondary_encoder (GRU)        [(None, 100),        90600       ['primary_encoder[0][0]']        \n",
            "                                 (None, 100)]                                                     \n",
            "                                                                                                  \n",
            " decoder (GRU)                  [(None, None, 100),  120600      ['embedding_1[0][0]',            \n",
            "                                 (None, 100)]                     'secondary_encoder[0][1]']      \n",
            "                                                                                                  \n",
            " time_distributed (TimeDistribu  (None, None, 13478)  1361278    ['decoder[0][0]']                \n",
            " ted)                                                                                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 14,107,078\n",
            "Trainable params: 14,107,078\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "latent_dim = 100\n",
        "embedding_dim = 300\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_paragraphs_len, ))\n",
        "\n",
        "# Embedding layer\n",
        "enc_emb = Embedding(x_voc, embedding_dim, trainable=True)(encoder_inputs)\n",
        "encoder_gru_1 = Bidirectional(GRU(latent_dim, return_sequences=True),                                                         \n",
        "                               merge_mode=\"concat\",\n",
        "                               name=\"primary_encoder\")(enc_emb)\n",
        "encoder_gru_2 = GRU(latent_dim, return_state=True, name='secondary_encoder')                               \n",
        "encoder_outputs, state = encoder_gru_2(encoder_gru_1)\n",
        "# Set up the decoder, using encoder_states as the initial state\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "# # Embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder = GRU(latent_dim, return_sequences=True, return_state=True, name='decoder')\n",
        "(decoder_outputs, decoder_state) =  decoder(dec_emb, initial_state=state)\n",
        "\n",
        "# Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diEaJ4aXv2Wm"
      },
      "outputs": [],
      "source": [
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy')\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6kvsWD0v5tT",
        "outputId": "1e6a3075-5af0-4090-ba0b-b345a75cc8b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "498/498 [==============================] - 48s 76ms/step - loss: 7.1649 - val_loss: 6.7367\n",
            "Epoch 2/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 6.3819 - val_loss: 6.1085\n",
            "Epoch 3/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 5.7496 - val_loss: 5.5452\n",
            "Epoch 4/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 5.1688 - val_loss: 5.0475\n",
            "Epoch 5/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 4.6374 - val_loss: 4.6030\n",
            "Epoch 6/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 4.1568 - val_loss: 4.2037\n",
            "Epoch 7/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 3.7290 - val_loss: 3.8539\n",
            "Epoch 8/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 3.3615 - val_loss: 3.5510\n",
            "Epoch 9/100\n",
            "498/498 [==============================] - 37s 73ms/step - loss: 3.0487 - val_loss: 3.2846\n",
            "Epoch 10/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 2.7889 - val_loss: 3.0691\n",
            "Epoch 11/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 2.5719 - val_loss: 2.8832\n",
            "Epoch 12/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 2.3863 - val_loss: 2.7137\n",
            "Epoch 13/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 2.2280 - val_loss: 2.5676\n",
            "Epoch 14/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 2.0891 - val_loss: 2.4396\n",
            "Epoch 15/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 1.9680 - val_loss: 2.3242\n",
            "Epoch 16/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 1.8603 - val_loss: 2.2220\n",
            "Epoch 17/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 1.7664 - val_loss: 2.1382\n",
            "Epoch 18/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 1.6837 - val_loss: 2.0535\n",
            "Epoch 19/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 1.6041 - val_loss: 1.9777\n",
            "Epoch 20/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 1.5323 - val_loss: 1.8950\n",
            "Epoch 21/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 1.4703 - val_loss: 1.8383\n",
            "Epoch 22/100\n",
            "498/498 [==============================] - 37s 73ms/step - loss: 1.4108 - val_loss: 1.7767\n",
            "Epoch 23/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 1.3588 - val_loss: 1.7288\n",
            "Epoch 24/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 1.3132 - val_loss: 1.6744\n",
            "Epoch 25/100\n",
            "498/498 [==============================] - 37s 73ms/step - loss: 1.2599 - val_loss: 1.6190\n",
            "Epoch 26/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 1.2095 - val_loss: 1.5637\n",
            "Epoch 27/100\n",
            "498/498 [==============================] - 37s 73ms/step - loss: 1.1766 - val_loss: 1.5224\n",
            "Epoch 28/100\n",
            "498/498 [==============================] - 37s 75ms/step - loss: 1.1364 - val_loss: 1.4830\n",
            "Epoch 29/100\n",
            "498/498 [==============================] - 38s 76ms/step - loss: 1.0988 - val_loss: 1.4295\n",
            "Epoch 30/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 1.0584 - val_loss: 1.3890\n",
            "Epoch 31/100\n",
            "498/498 [==============================] - 37s 73ms/step - loss: 1.0289 - val_loss: 1.3692\n",
            "Epoch 32/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 1.0076 - val_loss: 1.3329\n",
            "Epoch 33/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 0.9732 - val_loss: 1.2979\n",
            "Epoch 34/100\n",
            "498/498 [==============================] - 37s 73ms/step - loss: 0.9445 - val_loss: 1.2658\n",
            "Epoch 35/100\n",
            "498/498 [==============================] - 37s 73ms/step - loss: 0.9097 - val_loss: 1.2191\n",
            "Epoch 36/100\n",
            "498/498 [==============================] - 37s 73ms/step - loss: 0.8877 - val_loss: 1.2008\n",
            "Epoch 37/100\n",
            "498/498 [==============================] - 37s 73ms/step - loss: 0.8698 - val_loss: 1.2051\n",
            "Epoch 38/100\n",
            "498/498 [==============================] - 37s 73ms/step - loss: 0.8576 - val_loss: 1.1516\n",
            "Epoch 39/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 0.8214 - val_loss: 1.1354\n",
            "Epoch 40/100\n",
            "498/498 [==============================] - 37s 73ms/step - loss: 0.7984 - val_loss: 1.1080\n",
            "Epoch 41/100\n",
            "498/498 [==============================] - 37s 73ms/step - loss: 0.7770 - val_loss: 1.0688\n",
            "Epoch 42/100\n",
            "498/498 [==============================] - 37s 73ms/step - loss: 0.7606 - val_loss: 1.0488\n",
            "Epoch 43/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 0.7409 - val_loss: 1.0371\n",
            "Epoch 44/100\n",
            "498/498 [==============================] - 37s 73ms/step - loss: 0.7287 - val_loss: 1.0123\n",
            "Epoch 45/100\n",
            "498/498 [==============================] - 37s 73ms/step - loss: 0.7040 - val_loss: 0.9755\n",
            "Epoch 46/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 0.6837 - val_loss: 0.9690\n",
            "Epoch 47/100\n",
            "498/498 [==============================] - 37s 73ms/step - loss: 0.6823 - val_loss: 0.9513\n",
            "Epoch 48/100\n",
            "498/498 [==============================] - 38s 75ms/step - loss: 0.6601 - val_loss: 0.9350\n",
            "Epoch 49/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 0.6462 - val_loss: 0.9157\n",
            "Epoch 50/100\n",
            "498/498 [==============================] - 37s 73ms/step - loss: 0.6374 - val_loss: 0.8958\n",
            "Epoch 51/100\n",
            "498/498 [==============================] - 37s 73ms/step - loss: 0.6214 - val_loss: 0.8911\n",
            "Epoch 52/100\n",
            "498/498 [==============================] - 37s 73ms/step - loss: 0.6026 - val_loss: 0.8548\n",
            "Epoch 53/100\n",
            "498/498 [==============================] - 37s 73ms/step - loss: 0.5772 - val_loss: 0.8310\n",
            "Epoch 54/100\n",
            "498/498 [==============================] - 37s 73ms/step - loss: 0.6031 - val_loss: 0.8542\n",
            "Epoch 55/100\n",
            "498/498 [==============================] - 37s 74ms/step - loss: 0.5702 - val_loss: 0.8146\n",
            "Epoch 56/100\n",
            "498/498 [==============================] - 37s 73ms/step - loss: 0.5613 - val_loss: 0.8098\n",
            "Epoch 57/100\n",
            "498/498 [==============================] - 36s 73ms/step - loss: 0.5373 - val_loss: 0.7725\n",
            "Epoch 58/100\n",
            "498/498 [==============================] - 36s 73ms/step - loss: 0.5179 - val_loss: 0.7719\n",
            "Epoch 59/100\n",
            "498/498 [==============================] - 37s 73ms/step - loss: 0.5243 - val_loss: 0.7629\n",
            "Epoch 60/100\n",
            "498/498 [==============================] - 37s 73ms/step - loss: 0.5067 - val_loss: 0.7455\n",
            "Epoch 61/100\n",
            "498/498 [==============================] - 36s 73ms/step - loss: 0.4965 - val_loss: 0.7279\n",
            "Epoch 62/100\n",
            "498/498 [==============================] - 37s 73ms/step - loss: 0.4815 - val_loss: 0.7116\n",
            "Epoch 63/100\n",
            "498/498 [==============================] - 37s 73ms/step - loss: 0.4765 - val_loss: 0.7154\n",
            "Epoch 64/100\n",
            "498/498 [==============================] - 36s 73ms/step - loss: 0.4801 - val_loss: 0.7068\n",
            "Epoch 65/100\n",
            "498/498 [==============================] - 36s 73ms/step - loss: 0.4701 - val_loss: 0.6826\n",
            "Epoch 66/100\n",
            "498/498 [==============================] - 36s 73ms/step - loss: 0.4590 - val_loss: 0.7090\n",
            "Epoch 67/100\n",
            "498/498 [==============================] - 36s 73ms/step - loss: 0.4821 - val_loss: 0.7115\n",
            "Epoch 67: early stopping\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    [x_tr, y_tr[:, :-1]],\n",
        "    y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:, 1:],\n",
        "    epochs=100,\n",
        "    callbacks=[es],\n",
        "    batch_size=16,\n",
        "    validation_data=([x_val, y_val[:, :-1]],\n",
        "                     y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:\n",
        "                     , 1:]),\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b5k-_ZIy5dV"
      },
      "source": [
        "# Inference Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpWqVDpUy4_K"
      },
      "outputs": [],
      "source": [
        "# Inference Models\n",
        "\n",
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state])\n",
        "\n",
        "# Decoder setup\n",
        "\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input = Input(shape=(latent_dim, ))\n",
        "decoder_hidden_state_input = Input(shape=(latent_dim, latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "(decoder_outputs2, state2) = decoder(dec_emb2,\n",
        "        initial_state=decoder_state_input)\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
        "                      decoder_state_input],\n",
        "                      [decoder_outputs2] + [state2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_Xjh-hNy86H"
      },
      "outputs": [],
      "source": [
        "reverse_target_word_index = y_tokenizer.index_word\n",
        "reverse_source_word_index = x_tokenizer.index_word\n",
        "target_word_index = y_tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_MhwY5-y-rt"
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq):\n",
        "\n",
        "  # Encode the input as state vectors.\n",
        "  (e_out, e_state) = encoder_model.predict(input_seq)\n",
        "  \n",
        "\n",
        "  # Generate empty target sequence of length 1\n",
        "  target_seq = np.zeros((1, 1))\n",
        "\n",
        "  # Populate the first word of target sequence with the start word.\n",
        "  target_seq[0, 0] = target_word_index['<s>']\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "\n",
        "  while not stop_condition:\n",
        "    (output_tokens, o_state) = decoder_model.predict([target_seq] + [e_out, e_state])\n",
        "\n",
        "    # Sample a token\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    if sampled_token_index != 0:\n",
        "      sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "\n",
        "    else:\n",
        "      sampled_token = reverse_target_word_index[1]\n",
        "\n",
        "    if sampled_token != '</s>':\n",
        "        decoded_sentence += ' ' + sampled_token\n",
        "\n",
        "    # Exit condition: either hit max length or find the stop word.\n",
        "    if sampled_token == '</s>' or len(decoded_sentence.split()) \\\n",
        "        >= max_summary_len - 1:\n",
        "        stop_condition = True\n",
        "\n",
        "    # Update the target sequence (of length 1)\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "    # Update internal states\n",
        "    e_state = o_state\n",
        "  return decoded_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nX0vYx_OzAwZ"
      },
      "outputs": [],
      "source": [
        "# To convert sequence to summary\n",
        "def seq2summary(input_seq):\n",
        "    newString = ''\n",
        "    for i in input_seq:\n",
        "        if i != 0 and i != target_word_index['<s>'] and i \\\n",
        "            != target_word_index['</s>']:\n",
        "            newString = newString + reverse_target_word_index[i] + ' '\n",
        "\n",
        "    return newString\n",
        "\n",
        "\n",
        "# To convert sequence to text\n",
        "def seq2text(input_seq):\n",
        "    newString = ''\n",
        "    for i in input_seq:\n",
        "        if i != 0:\n",
        "            newString = newString + reverse_source_word_index[i] + ' '\n",
        "\n",
        "    return newString"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riWacQev_8qu"
      },
      "source": [
        "# Epoch 5 Batch 8 LR 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYUH9bTO_nyC",
        "outputId": "376e50ae-34a7-41cd-bdf3-bb29536fc07a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/5\n",
            "886/886 [==============================] - 80s 75ms/step - loss: 6.2033 - val_loss: 4.9055\n",
            "Epoch 2/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 3.8494 - val_loss: 3.6670\n",
            "Epoch 3/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.9599 - val_loss: 3.1878\n",
            "Epoch 4/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.6142 - val_loss: 2.9616\n",
            "Epoch 5/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.4307 - val_loss: 2.8291\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_8'), name='input_8', description=\"created by layer 'input_8'\"), but it was called on an input with incompatible shape (None, 100).\n",
            "Score for fold 1: score: {'ROUGE-1-R': 0.14286, 'ROUGE-1-P': 0.18919, 'ROUGE-1-F': 0.16279, 'ROUGE-2-R': 0.04167, 'ROUGE-2-P': 0.05556, 'ROUGE-2-F': 0.04762, 'ROUGE-L-R': 0.08163, 'ROUGE-L-P': 0.10811, 'ROUGE-L-F': 0.09302}\n",
            "Score for fold 1: score: {'ROUGE-1-R': 0.02, 'ROUGE-1-P': 0.02703, 'ROUGE-1-F': 0.02299, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.02, 'ROUGE-L-P': 0.02703, 'ROUGE-L-F': 0.02299}\n",
            "Score for fold 1: score: {'ROUGE-1-R': 0.06122, 'ROUGE-1-P': 0.08108, 'ROUGE-1-F': 0.06976, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04082, 'ROUGE-L-P': 0.05405, 'ROUGE-L-F': 0.04651}\n",
            "Score for fold 1: score: {'ROUGE-1-R': 0.02222, 'ROUGE-1-P': 0.02703, 'ROUGE-1-F': 0.02439, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.02222, 'ROUGE-L-P': 0.02703, 'ROUGE-L-F': 0.02439}\n",
            "Score for fold 1: score: {'ROUGE-1-R': 0.08, 'ROUGE-1-P': 0.10811, 'ROUGE-1-F': 0.09195, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.06, 'ROUGE-L-P': 0.08108, 'ROUGE-L-F': 0.06897}\n",
            "Score for fold 1: score: {'ROUGE-1-R': 0.04, 'ROUGE-1-P': 0.05405, 'ROUGE-1-F': 0.04598, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04, 'ROUGE-L-P': 0.05405, 'ROUGE-L-F': 0.04598}\n",
            "Score for fold 1: score: {'ROUGE-1-R': 0.04, 'ROUGE-1-P': 0.05405, 'ROUGE-1-F': 0.04598, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04, 'ROUGE-L-P': 0.05405, 'ROUGE-L-F': 0.04598}\n",
            "Score for fold 1: score: {'ROUGE-1-R': 0.04082, 'ROUGE-1-P': 0.05405, 'ROUGE-1-F': 0.04651, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04082, 'ROUGE-L-P': 0.05405, 'ROUGE-L-F': 0.04651}\n",
            "Score for fold 1: score: {'ROUGE-1-R': 0.02041, 'ROUGE-1-P': 0.02703, 'ROUGE-1-F': 0.02326, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.02041, 'ROUGE-L-P': 0.02703, 'ROUGE-L-F': 0.02326}\n",
            "Score for fold 1: score: {'ROUGE-1-R': 0.06, 'ROUGE-1-P': 0.08108, 'ROUGE-1-F': 0.06897, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04, 'ROUGE-L-P': 0.05405, 'ROUGE-L-F': 0.04598}\n",
            "Score for fold 1: score: {'ROUGE-1-R': 0.04, 'ROUGE-1-P': 0.05405, 'ROUGE-1-F': 0.04598, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04, 'ROUGE-L-P': 0.05405, 'ROUGE-L-F': 0.04598}\n",
            "Score for fold 1: score: {'ROUGE-1-R': 0.04, 'ROUGE-1-P': 0.05405, 'ROUGE-1-F': 0.04598, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04, 'ROUGE-L-P': 0.05405, 'ROUGE-L-F': 0.04598}\n",
            "Score for fold 1: score: {'ROUGE-1-R': 0.08696, 'ROUGE-1-P': 0.10811, 'ROUGE-1-F': 0.09639, 'ROUGE-2-R': 0.04444, 'ROUGE-2-P': 0.05556, 'ROUGE-2-F': 0.04938, 'ROUGE-L-R': 0.06522, 'ROUGE-L-P': 0.08108, 'ROUGE-L-F': 0.07229}\n",
            "Score for fold 1: score: {'ROUGE-1-R': 0.0, 'ROUGE-1-P': 0.0, 'ROUGE-1-F': 0.0, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.0, 'ROUGE-L-P': 0.0, 'ROUGE-L-F': 0.0}\n",
            "Score for fold 1: score: {'ROUGE-1-R': 0.02041, 'ROUGE-1-P': 0.02703, 'ROUGE-1-F': 0.02326, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.02041, 'ROUGE-L-P': 0.02703, 'ROUGE-L-F': 0.02326}\n",
            "Score for fold 1: score: {'ROUGE-1-R': 0.06383, 'ROUGE-1-P': 0.08108, 'ROUGE-1-F': 0.07143, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04255, 'ROUGE-L-P': 0.05405, 'ROUGE-L-F': 0.04762}\n",
            "Score for fold 1: score: {'ROUGE-1-R': 0.04082, 'ROUGE-1-P': 0.05405, 'ROUGE-1-F': 0.04651, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04082, 'ROUGE-L-P': 0.05405, 'ROUGE-L-F': 0.04651}\n",
            "Score for fold 1: score: {'ROUGE-1-R': 0.04167, 'ROUGE-1-P': 0.05405, 'ROUGE-1-F': 0.04706, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04167, 'ROUGE-L-P': 0.05405, 'ROUGE-L-F': 0.04706}\n",
            "Score for fold 1: score: {'ROUGE-1-R': 0.02128, 'ROUGE-1-P': 0.02703, 'ROUGE-1-F': 0.02381, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.02128, 'ROUGE-L-P': 0.02703, 'ROUGE-L-F': 0.02381}\n",
            "Score for fold 1: score: {'ROUGE-1-R': 0.1, 'ROUGE-1-P': 0.13514, 'ROUGE-1-F': 0.11494, 'ROUGE-2-R': 0.02041, 'ROUGE-2-P': 0.02778, 'ROUGE-2-F': 0.02353, 'ROUGE-L-R': 0.08, 'ROUGE-L-P': 0.10811, 'ROUGE-L-F': 0.09195}\n",
            "ROUGE 1 : 0.049125, ROUGE 2 : 0.005325999999999999, ROUGE L : 0.039892499999999984\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/5\n",
            "886/886 [==============================] - 73s 75ms/step - loss: 2.4886 - val_loss: 2.3473\n",
            "Epoch 2/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.3454 - val_loss: 2.3558\n",
            "Epoch 3/5\n",
            "886/886 [==============================] - 65s 74ms/step - loss: 2.2748 - val_loss: 2.3653\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_10'), name='input_10', description=\"created by layer 'input_10'\"), but it was called on an input with incompatible shape (None, 100).\n",
            "Score for fold 2: score: {'ROUGE-1-R': 0.02, 'ROUGE-1-P': 0.02128, 'ROUGE-1-F': 0.02062, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.02, 'ROUGE-L-P': 0.02128, 'ROUGE-L-F': 0.02062}\n",
            "Score for fold 2: score: {'ROUGE-1-R': 0.06, 'ROUGE-1-P': 0.06383, 'ROUGE-1-F': 0.06186, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04, 'ROUGE-L-P': 0.04255, 'ROUGE-L-F': 0.04124}\n",
            "Score for fold 2: score: {'ROUGE-1-R': 0.08, 'ROUGE-1-P': 0.08511, 'ROUGE-1-F': 0.08248, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.08, 'ROUGE-L-P': 0.08511, 'ROUGE-L-F': 0.08248}\n",
            "Score for fold 2: score: {'ROUGE-1-R': 0.14894, 'ROUGE-1-P': 0.14894, 'ROUGE-1-F': 0.14894, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.10638, 'ROUGE-L-P': 0.10638, 'ROUGE-L-F': 0.10638}\n",
            "Score for fold 2: score: {'ROUGE-1-R': 0.06, 'ROUGE-1-P': 0.06383, 'ROUGE-1-F': 0.06186, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.06, 'ROUGE-L-P': 0.06383, 'ROUGE-L-F': 0.06186}\n",
            "Score for fold 2: score: {'ROUGE-1-R': 0.12766, 'ROUGE-1-P': 0.12766, 'ROUGE-1-F': 0.12766, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.10638, 'ROUGE-L-P': 0.10638, 'ROUGE-L-F': 0.10638}\n",
            "Score for fold 2: score: {'ROUGE-1-R': 0.06, 'ROUGE-1-P': 0.06383, 'ROUGE-1-F': 0.06186, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04, 'ROUGE-L-P': 0.04255, 'ROUGE-L-F': 0.04124}\n",
            "Score for fold 2: score: {'ROUGE-1-R': 0.08, 'ROUGE-1-P': 0.08511, 'ROUGE-1-F': 0.08248, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.06, 'ROUGE-L-P': 0.06383, 'ROUGE-L-F': 0.06186}\n",
            "Score for fold 2: score: {'ROUGE-1-R': 0.08, 'ROUGE-1-P': 0.08511, 'ROUGE-1-F': 0.08248, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04, 'ROUGE-L-P': 0.04255, 'ROUGE-L-F': 0.04124}\n",
            "Score for fold 2: score: {'ROUGE-1-R': 0.04, 'ROUGE-1-P': 0.04255, 'ROUGE-1-F': 0.04124, 'ROUGE-2-R': 0.02041, 'ROUGE-2-P': 0.02174, 'ROUGE-2-F': 0.02105, 'ROUGE-L-R': 0.04, 'ROUGE-L-P': 0.04255, 'ROUGE-L-F': 0.04124}\n",
            "Score for fold 2: score: {'ROUGE-1-R': 0.02083, 'ROUGE-1-P': 0.02128, 'ROUGE-1-F': 0.02105, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.02083, 'ROUGE-L-P': 0.02128, 'ROUGE-L-F': 0.02105}\n",
            "Score for fold 2: score: {'ROUGE-1-R': 0.06, 'ROUGE-1-P': 0.06383, 'ROUGE-1-F': 0.06186, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04, 'ROUGE-L-P': 0.04255, 'ROUGE-L-F': 0.04124}\n",
            "Score for fold 2: score: {'ROUGE-1-R': 0.06, 'ROUGE-1-P': 0.06383, 'ROUGE-1-F': 0.06186, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.06, 'ROUGE-L-P': 0.06383, 'ROUGE-L-F': 0.06186}\n",
            "Score for fold 2: score: {'ROUGE-1-R': 0.06122, 'ROUGE-1-P': 0.06383, 'ROUGE-1-F': 0.0625, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04082, 'ROUGE-L-P': 0.04255, 'ROUGE-L-F': 0.04167}\n",
            "Score for fold 2: score: {'ROUGE-1-R': 0.12245, 'ROUGE-1-P': 0.12766, 'ROUGE-1-F': 0.125, 'ROUGE-2-R': 0.02083, 'ROUGE-2-P': 0.02174, 'ROUGE-2-F': 0.02128, 'ROUGE-L-R': 0.08163, 'ROUGE-L-P': 0.08511, 'ROUGE-L-F': 0.08333}\n",
            "Score for fold 2: score: {'ROUGE-1-R': 0.04, 'ROUGE-1-P': 0.04255, 'ROUGE-1-F': 0.04124, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04, 'ROUGE-L-P': 0.04255, 'ROUGE-L-F': 0.04124}\n",
            "Score for fold 2: score: {'ROUGE-1-R': 0.08, 'ROUGE-1-P': 0.08511, 'ROUGE-1-F': 0.08248, 'ROUGE-2-R': 0.02041, 'ROUGE-2-P': 0.02174, 'ROUGE-2-F': 0.02105, 'ROUGE-L-R': 0.06, 'ROUGE-L-P': 0.06383, 'ROUGE-L-F': 0.06186}\n",
            "Score for fold 2: score: {'ROUGE-1-R': 0.08163, 'ROUGE-1-P': 0.08511, 'ROUGE-1-F': 0.08333, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.06122, 'ROUGE-L-P': 0.06383, 'ROUGE-L-F': 0.0625}\n",
            "Score for fold 2: score: {'ROUGE-1-R': 0.0625, 'ROUGE-1-P': 0.06383, 'ROUGE-1-F': 0.06316, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04167, 'ROUGE-L-P': 0.04255, 'ROUGE-L-F': 0.04211}\n",
            "Score for fold 2: score: {'ROUGE-1-R': 0.08, 'ROUGE-1-P': 0.08511, 'ROUGE-1-F': 0.08248, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.06, 'ROUGE-L-P': 0.06383, 'ROUGE-L-F': 0.06186}\n",
            "ROUGE 1 : 0.0712615, ROUGE 2 : 0.0030824999999999997, ROUGE L : 0.05494650000000002\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/5\n",
            "886/886 [==============================] - 73s 75ms/step - loss: 2.3093 - val_loss: 2.2185\n",
            "Epoch 2/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.2104 - val_loss: 2.2610\n",
            "Epoch 3/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.1955 - val_loss: 2.2811\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_12'), name='input_12', description=\"created by layer 'input_12'\"), but it was called on an input with incompatible shape (None, 100).\n",
            "Score for fold 3: score: {'ROUGE-1-R': 0.04, 'ROUGE-1-P': 0.06897, 'ROUGE-1-F': 0.05063, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04, 'ROUGE-L-P': 0.06897, 'ROUGE-L-F': 0.05063}\n",
            "Score for fold 3: score: {'ROUGE-1-R': 0.02041, 'ROUGE-1-P': 0.03448, 'ROUGE-1-F': 0.02564, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.02041, 'ROUGE-L-P': 0.03448, 'ROUGE-L-F': 0.02564}\n",
            "Score for fold 3: score: {'ROUGE-1-R': 0.04167, 'ROUGE-1-P': 0.06897, 'ROUGE-1-F': 0.05195, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04167, 'ROUGE-L-P': 0.06897, 'ROUGE-L-F': 0.05195}\n",
            "Score for fold 3: score: {'ROUGE-1-R': 0.02041, 'ROUGE-1-P': 0.03448, 'ROUGE-1-F': 0.02564, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.02041, 'ROUGE-L-P': 0.03448, 'ROUGE-L-F': 0.02564}\n",
            "Score for fold 3: score: {'ROUGE-1-R': 0.08333, 'ROUGE-1-P': 0.13793, 'ROUGE-1-F': 0.10389, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04167, 'ROUGE-L-P': 0.06897, 'ROUGE-L-F': 0.05195}\n",
            "Score for fold 3: score: {'ROUGE-1-R': 0.02, 'ROUGE-1-P': 0.03448, 'ROUGE-1-F': 0.02532, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.02, 'ROUGE-L-P': 0.03448, 'ROUGE-L-F': 0.02532}\n",
            "Score for fold 3: score: {'ROUGE-1-R': 0.0, 'ROUGE-1-P': 0.0, 'ROUGE-1-F': 0.0, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.0, 'ROUGE-L-P': 0.0, 'ROUGE-L-F': 0.0}\n",
            "Score for fold 3: score: {'ROUGE-1-R': 0.04, 'ROUGE-1-P': 0.06897, 'ROUGE-1-F': 0.05063, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04, 'ROUGE-L-P': 0.06897, 'ROUGE-L-F': 0.05063}\n",
            "Score for fold 3: score: {'ROUGE-1-R': 0.04, 'ROUGE-1-P': 0.06897, 'ROUGE-1-F': 0.05063, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04, 'ROUGE-L-P': 0.06897, 'ROUGE-L-F': 0.05063}\n",
            "Score for fold 3: score: {'ROUGE-1-R': 0.02041, 'ROUGE-1-P': 0.03448, 'ROUGE-1-F': 0.02564, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.02041, 'ROUGE-L-P': 0.03448, 'ROUGE-L-F': 0.02564}\n",
            "Score for fold 3: score: {'ROUGE-1-R': 0.04, 'ROUGE-1-P': 0.06897, 'ROUGE-1-F': 0.05063, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04, 'ROUGE-L-P': 0.06897, 'ROUGE-L-F': 0.05063}\n",
            "Score for fold 3: score: {'ROUGE-1-R': 0.04082, 'ROUGE-1-P': 0.06897, 'ROUGE-1-F': 0.05129, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04082, 'ROUGE-L-P': 0.06897, 'ROUGE-L-F': 0.05129}\n",
            "Score for fold 3: score: {'ROUGE-1-R': 0.08163, 'ROUGE-1-P': 0.13793, 'ROUGE-1-F': 0.10256, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.08163, 'ROUGE-L-P': 0.13793, 'ROUGE-L-F': 0.10256}\n",
            "Score for fold 3: score: {'ROUGE-1-R': 0.0625, 'ROUGE-1-P': 0.10345, 'ROUGE-1-F': 0.07792, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.02083, 'ROUGE-L-P': 0.03448, 'ROUGE-L-F': 0.02597}\n",
            "Score for fold 3: score: {'ROUGE-1-R': 0.02, 'ROUGE-1-P': 0.03448, 'ROUGE-1-F': 0.02532, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.02, 'ROUGE-L-P': 0.03448, 'ROUGE-L-F': 0.02532}\n",
            "Score for fold 3: score: {'ROUGE-1-R': 0.08, 'ROUGE-1-P': 0.13793, 'ROUGE-1-F': 0.10127, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.06, 'ROUGE-L-P': 0.10345, 'ROUGE-L-F': 0.07595}\n",
            "Score for fold 3: score: {'ROUGE-1-R': 0.0, 'ROUGE-1-P': 0.0, 'ROUGE-1-F': 0.0, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.0, 'ROUGE-L-P': 0.0, 'ROUGE-L-F': 0.0}\n",
            "Score for fold 3: score: {'ROUGE-1-R': 0.02, 'ROUGE-1-P': 0.03448, 'ROUGE-1-F': 0.02532, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.02, 'ROUGE-L-P': 0.03448, 'ROUGE-L-F': 0.02532}\n",
            "Score for fold 3: score: {'ROUGE-1-R': 0.0, 'ROUGE-1-P': 0.0, 'ROUGE-1-F': 0.0, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.0, 'ROUGE-L-P': 0.0, 'ROUGE-L-F': 0.0}\n",
            "Score for fold 3: score: {'ROUGE-1-R': 0.02, 'ROUGE-1-P': 0.03448, 'ROUGE-1-F': 0.02532, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.02, 'ROUGE-L-P': 0.03448, 'ROUGE-L-F': 0.02532}\n",
            "ROUGE 1 : 0.034559, ROUGE 2 : 0.0, ROUGE L : 0.0293925\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/5\n",
            "886/886 [==============================] - 73s 75ms/step - loss: 2.2459 - val_loss: 2.1832\n",
            "Epoch 2/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.1755 - val_loss: 2.1926\n",
            "Epoch 3/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.1721 - val_loss: 2.2485\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_14'), name='input_14', description=\"created by layer 'input_14'\"), but it was called on an input with incompatible shape (None, 100).\n",
            "Score for fold 4: score: {'ROUGE-1-R': 0.08333, 'ROUGE-1-P': 0.08163, 'ROUGE-1-F': 0.08247, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.08333, 'ROUGE-L-P': 0.08163, 'ROUGE-L-F': 0.08247}\n",
            "Score for fold 4: score: {'ROUGE-1-R': 0.04167, 'ROUGE-1-P': 0.04444, 'ROUGE-1-F': 0.04301, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04167, 'ROUGE-L-P': 0.04444, 'ROUGE-L-F': 0.04301}\n",
            "Score for fold 4: score: {'ROUGE-1-R': 0.125, 'ROUGE-1-P': 0.12245, 'ROUGE-1-F': 0.12371, 'ROUGE-2-R': 0.02128, 'ROUGE-2-P': 0.02083, 'ROUGE-2-F': 0.02105, 'ROUGE-L-R': 0.08333, 'ROUGE-L-P': 0.08163, 'ROUGE-L-F': 0.08247}\n",
            "Score for fold 4: score: {'ROUGE-1-R': 0.06122, 'ROUGE-1-P': 0.06122, 'ROUGE-1-F': 0.06122, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04082, 'ROUGE-L-P': 0.04082, 'ROUGE-L-F': 0.04082}\n",
            "Score for fold 4: score: {'ROUGE-1-R': 0.08, 'ROUGE-1-P': 0.08163, 'ROUGE-1-F': 0.08081, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04, 'ROUGE-L-P': 0.04082, 'ROUGE-L-F': 0.04041}\n",
            "Score for fold 4: score: {'ROUGE-1-R': 0.10417, 'ROUGE-1-P': 0.11111, 'ROUGE-1-F': 0.10753, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.08333, 'ROUGE-L-P': 0.08889, 'ROUGE-L-F': 0.08602}\n",
            "Score for fold 4: score: {'ROUGE-1-R': 0.1, 'ROUGE-1-P': 0.11111, 'ROUGE-1-F': 0.10526, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.08, 'ROUGE-L-P': 0.08889, 'ROUGE-L-F': 0.08421}\n",
            "Score for fold 4: score: {'ROUGE-1-R': 0.14, 'ROUGE-1-P': 0.15556, 'ROUGE-1-F': 0.14737, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.1, 'ROUGE-L-P': 0.11111, 'ROUGE-L-F': 0.10526}\n",
            "Score for fold 4: score: {'ROUGE-1-R': 0.16, 'ROUGE-1-P': 0.17778, 'ROUGE-1-F': 0.16842, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.1, 'ROUGE-L-P': 0.11111, 'ROUGE-L-F': 0.10526}\n",
            "Score for fold 4: score: {'ROUGE-1-R': 0.06122, 'ROUGE-1-P': 0.06667, 'ROUGE-1-F': 0.06383, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04082, 'ROUGE-L-P': 0.04444, 'ROUGE-L-F': 0.04255}\n",
            "Score for fold 4: score: {'ROUGE-1-R': 0.06, 'ROUGE-1-P': 0.06667, 'ROUGE-1-F': 0.06316, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04, 'ROUGE-L-P': 0.04444, 'ROUGE-L-F': 0.0421}\n",
            "Score for fold 4: score: {'ROUGE-1-R': 0.17021, 'ROUGE-1-P': 0.17778, 'ROUGE-1-F': 0.17391, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.10638, 'ROUGE-L-P': 0.11111, 'ROUGE-L-F': 0.10869}\n",
            "Score for fold 4: score: {'ROUGE-1-R': 0.1087, 'ROUGE-1-P': 0.11111, 'ROUGE-1-F': 0.10989, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.06522, 'ROUGE-L-P': 0.06667, 'ROUGE-L-F': 0.06594}\n",
            "Score for fold 4: score: {'ROUGE-1-R': 0.04, 'ROUGE-1-P': 0.04444, 'ROUGE-1-F': 0.0421, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.02, 'ROUGE-L-P': 0.02222, 'ROUGE-L-F': 0.02105}\n",
            "Score for fold 4: score: {'ROUGE-1-R': 0.06122, 'ROUGE-1-P': 0.06122, 'ROUGE-1-F': 0.06122, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04082, 'ROUGE-L-P': 0.04082, 'ROUGE-L-F': 0.04082}\n",
            "Score for fold 4: score: {'ROUGE-1-R': 0.1, 'ROUGE-1-P': 0.11111, 'ROUGE-1-F': 0.10526, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.06, 'ROUGE-L-P': 0.06667, 'ROUGE-L-F': 0.06316}\n",
            "Score for fold 4: score: {'ROUGE-1-R': 0.06, 'ROUGE-1-P': 0.06122, 'ROUGE-1-F': 0.0606, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04, 'ROUGE-L-P': 0.04082, 'ROUGE-L-F': 0.04041}\n",
            "Score for fold 4: score: {'ROUGE-1-R': 0.02, 'ROUGE-1-P': 0.02041, 'ROUGE-1-F': 0.0202, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.02, 'ROUGE-L-P': 0.02041, 'ROUGE-L-F': 0.0202}\n",
            "Score for fold 4: score: {'ROUGE-1-R': 0.08163, 'ROUGE-1-P': 0.08889, 'ROUGE-1-F': 0.08511, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04082, 'ROUGE-L-P': 0.04444, 'ROUGE-L-F': 0.04255}\n",
            "Score for fold 4: score: {'ROUGE-1-R': 0.1, 'ROUGE-1-P': 0.11111, 'ROUGE-1-F': 0.10526, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.08, 'ROUGE-L-P': 0.08889, 'ROUGE-L-F': 0.08421}\n",
            "ROUGE 1 : 0.08791850000000002, ROUGE 2 : 0.001064, ROUGE L : 0.060327000000000006\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/5\n",
            "886/886 [==============================] - 73s 75ms/step - loss: 2.2162 - val_loss: 2.1520\n",
            "Epoch 2/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.1562 - val_loss: 2.2087\n",
            "Epoch 3/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.1369 - val_loss: 2.2136\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_16'), name='input_16', description=\"created by layer 'input_16'\"), but it was called on an input with incompatible shape (None, 100).\n",
            "Score for fold 5: score: {'ROUGE-1-R': 0.10204, 'ROUGE-1-P': 0.13889, 'ROUGE-1-F': 0.11765, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.08163, 'ROUGE-L-P': 0.11111, 'ROUGE-L-F': 0.09412}\n",
            "Score for fold 5: score: {'ROUGE-1-R': 0.02, 'ROUGE-1-P': 0.02778, 'ROUGE-1-F': 0.02326, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.02, 'ROUGE-L-P': 0.02778, 'ROUGE-L-F': 0.02326}\n",
            "Score for fold 5: score: {'ROUGE-1-R': 0.06, 'ROUGE-1-P': 0.08333, 'ROUGE-1-F': 0.06977, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04, 'ROUGE-L-P': 0.05556, 'ROUGE-L-F': 0.04651}\n",
            "Score for fold 5: score: {'ROUGE-1-R': 0.0625, 'ROUGE-1-P': 0.08333, 'ROUGE-1-F': 0.07143, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04167, 'ROUGE-L-P': 0.05556, 'ROUGE-L-F': 0.04762}\n",
            "Score for fold 5: score: {'ROUGE-1-R': 0.08163, 'ROUGE-1-P': 0.11111, 'ROUGE-1-F': 0.09412, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.08163, 'ROUGE-L-P': 0.11111, 'ROUGE-L-F': 0.09412}\n",
            "Score for fold 5: score: {'ROUGE-1-R': 0.05882, 'ROUGE-1-P': 0.06122, 'ROUGE-1-F': 0.06, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.03922, 'ROUGE-L-P': 0.04082, 'ROUGE-L-F': 0.04}\n",
            "Score for fold 5: score: {'ROUGE-1-R': 0.04, 'ROUGE-1-P': 0.05556, 'ROUGE-1-F': 0.04651, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04, 'ROUGE-L-P': 0.05556, 'ROUGE-L-F': 0.04651}\n",
            "Score for fold 5: score: {'ROUGE-1-R': 0.04167, 'ROUGE-1-P': 0.05556, 'ROUGE-1-F': 0.04762, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04167, 'ROUGE-L-P': 0.05556, 'ROUGE-L-F': 0.04762}\n",
            "Score for fold 5: score: {'ROUGE-1-R': 0.1, 'ROUGE-1-P': 0.10204, 'ROUGE-1-F': 0.10101, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.06, 'ROUGE-L-P': 0.06122, 'ROUGE-L-F': 0.0606}\n",
            "Score for fold 5: score: {'ROUGE-1-R': 0.06, 'ROUGE-1-P': 0.08333, 'ROUGE-1-F': 0.06977, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04, 'ROUGE-L-P': 0.05556, 'ROUGE-L-F': 0.04651}\n",
            "Score for fold 5: score: {'ROUGE-1-R': 0.06, 'ROUGE-1-P': 0.06122, 'ROUGE-1-F': 0.0606, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04, 'ROUGE-L-P': 0.04082, 'ROUGE-L-F': 0.04041}\n",
            "Score for fold 5: score: {'ROUGE-1-R': 0.1, 'ROUGE-1-P': 0.10204, 'ROUGE-1-F': 0.10101, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.06, 'ROUGE-L-P': 0.06122, 'ROUGE-L-F': 0.0606}\n",
            "Score for fold 5: score: {'ROUGE-1-R': 0.08, 'ROUGE-1-P': 0.11111, 'ROUGE-1-F': 0.09302, 'ROUGE-2-R': 0.02041, 'ROUGE-2-P': 0.02857, 'ROUGE-2-F': 0.02381, 'ROUGE-L-R': 0.08, 'ROUGE-L-P': 0.11111, 'ROUGE-L-F': 0.09302}\n",
            "Score for fold 5: score: {'ROUGE-1-R': 0.08, 'ROUGE-1-P': 0.08163, 'ROUGE-1-F': 0.08081, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.06, 'ROUGE-L-P': 0.06122, 'ROUGE-L-F': 0.0606}\n",
            "Score for fold 5: score: {'ROUGE-1-R': 0.06, 'ROUGE-1-P': 0.08333, 'ROUGE-1-F': 0.06977, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04, 'ROUGE-L-P': 0.05556, 'ROUGE-L-F': 0.04651}\n",
            "Score for fold 5: score: {'ROUGE-1-R': 0.1, 'ROUGE-1-P': 0.13889, 'ROUGE-1-F': 0.11628, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.04, 'ROUGE-L-P': 0.05556, 'ROUGE-L-F': 0.04651}\n",
            "Score for fold 5: score: {'ROUGE-1-R': 0.04, 'ROUGE-1-P': 0.04082, 'ROUGE-1-F': 0.04041, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.02, 'ROUGE-L-P': 0.02041, 'ROUGE-L-F': 0.0202}\n",
            "Score for fold 5: score: {'ROUGE-1-R': 0.08, 'ROUGE-1-P': 0.11111, 'ROUGE-1-F': 0.09302, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.06, 'ROUGE-L-P': 0.08333, 'ROUGE-L-F': 0.06977}\n",
            "Score for fold 5: score: {'ROUGE-1-R': 0.10204, 'ROUGE-1-P': 0.13889, 'ROUGE-1-F': 0.11765, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.08163, 'ROUGE-L-P': 0.11111, 'ROUGE-L-F': 0.09412}\n",
            "Score for fold 5: score: {'ROUGE-1-R': 0.02, 'ROUGE-1-P': 0.02778, 'ROUGE-1-F': 0.02326, 'ROUGE-2-R': 0.0, 'ROUGE-2-P': 0.0, 'ROUGE-2-F': 0.0, 'ROUGE-L-R': 0.02, 'ROUGE-L-P': 0.02778, 'ROUGE-L-F': 0.02326}\n",
            "ROUGE 1 : 0.067435, ROUGE 2 : 0.0010205000000000001, ROUGE L : 0.0493725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_8_layer_call_fn, gru_cell_8_layer_call_and_return_conditional_losses, gru_cell_9_layer_call_fn, gru_cell_9_layer_call_and_return_conditional_losses, gru_cell_6_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_8_0.01_5/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_8_0.01_5/assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fead65de8d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fead63b9550> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fead65fa5d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fead65ee090> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from pythonrouge.pythonrouge import Pythonrouge\n",
        "\n",
        "# batch_size = [8, 16, 32, 64, 128]\n",
        "# Learning_rate = [0.01, 0.001, 0.0001]\n",
        "# epochs = [5, 10, 20]\n",
        "epoch = 5\n",
        "batch = 8\n",
        "lr = 0.01\n",
        "num_folds = 5\n",
        "inputs = np.concatenate((x_tr, x_val), axis=0)\n",
        "targets = np.concatenate((y_tr, y_val), axis=0)\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_paragraphs_len, ))\n",
        "\n",
        "# Embedding layer\n",
        "enc_emb = Embedding(x_voc, embedding_dim, trainable=True)(encoder_inputs)\n",
        "encoder_gru_1 = Bidirectional(GRU(latent_dim, return_sequences=True),                                                         \n",
        "                              merge_mode=\"concat\",\n",
        "                              name=\"primary_encoder\")(enc_emb)\n",
        "encoder_gru_2 = GRU(latent_dim, return_state=True, name='secondary_encoder')                               \n",
        "encoder_outputs, state = encoder_gru_2(encoder_gru_1)\n",
        "# Set up the decoder, using encoder_states as the initial state\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "# # Embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder = GRU(latent_dim, return_sequences=True, return_state=True, name='decoder')\n",
        "(decoder_outputs, decoder_state) =  decoder(dec_emb, initial_state=state)\n",
        "\n",
        "# Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "fold_no = 1\n",
        "for train, val in kfold.split(inputs, targets):\n",
        "  x_tr = inputs[train]\n",
        "  y_tr = targets[train]\n",
        "  x_val = inputs[val]\n",
        "  y_val = targets[val]\n",
        "\n",
        "  latent_dim = 100\n",
        "  embedding_dim = 300\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Compile Model\n",
        "  opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "  model.compile(optimizer=opt, loss='sparse_categorical_crossentropy')\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit([x_tr, y_tr[:, :-1]], y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:, 1:],\n",
        "              batch_size=batch,\n",
        "              epochs=epoch,\n",
        "              callbacks=[es],\n",
        "              validation_data=([x_val, y_val[:, :-1]], y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:, 1:]))\n",
        "  \n",
        "  # Inference Models\n",
        "  encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state])\n",
        "\n",
        "  # Below tensors will hold the states of the previous time step\n",
        "  decoder_state_input = Input(shape=(latent_dim, ))\n",
        "  decoder_hidden_state_input = Input(shape=(latent_dim, latent_dim))\n",
        "\n",
        "  # Get the embeddings of the decoder sequence\n",
        "  dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  # To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "  (decoder_outputs2, state2) = decoder(dec_emb2,\n",
        "          initial_state=decoder_state_input)\n",
        "\n",
        "  # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "  decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "  # Final decoder model\n",
        "  decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
        "                        decoder_state_input],\n",
        "                        [decoder_outputs2] + [state2])\n",
        "\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  rouge1 = 0\n",
        "  rouge2 = 0\n",
        "  rougel = 0\n",
        "  for i in range(0, 20):\n",
        "    original = seq2summary(y_val[i])\n",
        "    predict = decode_sequence(x_val[i].reshape(1, max_paragraphs_len))\n",
        "\n",
        "    rouge = Pythonrouge(summary_file_exist=False,\n",
        "                        summary=[[predict]], reference=[[[original]]],\n",
        "                        n_gram=2, ROUGE_SU4=False, ROUGE_L=True,\n",
        "                        recall_only=False, stemming=True, stopwords=True,\n",
        "                        word_level=True, length_limit=True, length=50,\n",
        "                        use_cf=False, cf=95, scoring_formula='average',\n",
        "                        resampling=True, samples=1000, favor=True, p=0.5)\n",
        "\n",
        "    score = rouge.calc_score()\n",
        "    rouge1 = rouge1 + score['ROUGE-1-R']\n",
        "    rouge2 = rouge2 + score['ROUGE-2-R']\n",
        "    rougel = rougel + score['ROUGE-L-R']\n",
        "    \n",
        "    print(f'Score for fold {fold_no}: score: {score}')\n",
        "\n",
        "  rogue1 = rouge1/20\n",
        "  rogue2 = rouge2/20\n",
        "  roguel = rougel/20\n",
        "  print(f'ROUGE 1 : {rogue1}, ROUGE 2 : {rogue2}, ROUGE L : {roguel}')\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# save model\n",
        "model.save(f'/content/drive/MyDrive/Dataset TA/my_model_{batch}_{lr}_{epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eFFDdtLAxDO"
      },
      "source": [
        "# Epoch 10 Batch 8 LR 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tI9k0g9uAyZB",
        "outputId": "3a67eb68-d23b-4d47-eee8-8c68ded9830b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/10\n",
            "886/886 [==============================] - 73s 75ms/step - loss: 6.1811 - val_loss: 4.8552\n",
            "Epoch 2/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 3.8431 - val_loss: 3.6249\n",
            "Epoch 3/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.9758 - val_loss: 3.2155\n",
            "Epoch 4/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.6434 - val_loss: 3.0145\n",
            "Epoch 5/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.4609 - val_loss: 2.8769\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.3361 - val_loss: 2.7739\n",
            "Epoch 7/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.2569 - val_loss: 2.7134\n",
            "Epoch 8/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.2116 - val_loss: 2.6688\n",
            "Epoch 9/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.1658 - val_loss: 2.6404\n",
            "Epoch 10/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.1442 - val_loss: 2.6264\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_20'), name='input_20', description=\"created by layer 'input_20'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_20'), name='input_20', description=\"created by layer 'input_20'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.08845350000000003, ROUGE 2 : 0.0, ROUGE L : 0.07218050000000001\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/10\n",
            "886/886 [==============================] - 73s 75ms/step - loss: 2.2656 - val_loss: 2.1729\n",
            "Epoch 2/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.1972 - val_loss: 2.2295\n",
            "Epoch 3/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.1570 - val_loss: 2.2221\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_22'), name='input_22', description=\"created by layer 'input_22'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_22'), name='input_22', description=\"created by layer 'input_22'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.08176000000000001, ROUGE 2 : 0.0, ROUGE L : 0.060192499999999996\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/10\n",
            "886/886 [==============================] - 73s 75ms/step - loss: 2.2161 - val_loss: 2.1616\n",
            "Epoch 2/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.1599 - val_loss: 2.2106\n",
            "Epoch 3/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.1311 - val_loss: 2.2481\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_24'), name='input_24', description=\"created by layer 'input_24'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_24'), name='input_24', description=\"created by layer 'input_24'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.07843150000000002, ROUGE 2 : 0.0011365, ROUGE L : 0.055946499999999996\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/10\n",
            "886/886 [==============================] - 79s 75ms/step - loss: 2.1838 - val_loss: 2.1588\n",
            "Epoch 2/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.1292 - val_loss: 2.2171\n",
            "Epoch 3/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.1279 - val_loss: 2.2472\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_26'), name='input_26', description=\"created by layer 'input_26'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_26'), name='input_26', description=\"created by layer 'input_26'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.11087850000000002, ROUGE 2 : 0.0, ROUGE L : 0.07125350000000001\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/10\n",
            "886/886 [==============================] - 73s 75ms/step - loss: 2.2013 - val_loss: 2.1370\n",
            "Epoch 2/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.1508 - val_loss: 2.1792\n",
            "Epoch 3/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.1454 - val_loss: 2.2012\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_28'), name='input_28', description=\"created by layer 'input_28'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_28'), name='input_28', description=\"created by layer 'input_28'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.07029800000000001, ROUGE 2 : 0.0010415, ROUGE L : 0.04679299999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_11_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_8_0.01_10/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_8_0.01_10/assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feaabd99710> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feca5aea5d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fec9dd15c50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fec9da56090> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "# batch_size = [8, 16, 32, 64, 128]\n",
        "# Learning_rate = [0.01, 0.001, 0.0001]\n",
        "# epochs = [5, 10, 20]\n",
        "epoch = 10\n",
        "batch = 8\n",
        "lr = 0.01\n",
        "num_folds = 5\n",
        "inputs = np.concatenate((x_tr, x_val), axis=0)\n",
        "targets = np.concatenate((y_tr, y_val), axis=0)\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_paragraphs_len, ))\n",
        "\n",
        "# Embedding layer\n",
        "enc_emb = Embedding(x_voc, embedding_dim, trainable=True)(encoder_inputs)\n",
        "encoder_gru_1 = Bidirectional(GRU(latent_dim, return_sequences=True),                                                         \n",
        "                              merge_mode=\"concat\",\n",
        "                              name=\"primary_encoder\")(enc_emb)\n",
        "encoder_gru_2 = GRU(latent_dim, return_state=True, name='secondary_encoder')                               \n",
        "encoder_outputs, state = encoder_gru_2(encoder_gru_1)\n",
        "# Set up the decoder, using encoder_states as the initial state\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "# # Embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder = GRU(latent_dim, return_sequences=True, return_state=True, name='decoder')\n",
        "(decoder_outputs, decoder_state) =  decoder(dec_emb, initial_state=state)\n",
        "\n",
        "# Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "fold_no = 1\n",
        "for train, val in kfold.split(inputs, targets):\n",
        "  x_tr = inputs[train]\n",
        "  y_tr = targets[train]\n",
        "  x_val = inputs[val]\n",
        "  y_val = targets[val]\n",
        "\n",
        "  latent_dim = 100\n",
        "  embedding_dim = 300\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Compile Model\n",
        "  opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "  model.compile(optimizer=opt, loss='sparse_categorical_crossentropy')\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit([x_tr, y_tr[:, :-1]], y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:, 1:],\n",
        "              batch_size=batch,\n",
        "              epochs=epoch,\n",
        "              callbacks=[es],\n",
        "              validation_data=([x_val, y_val[:, :-1]], y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:, 1:]))\n",
        "  \n",
        "  # Inference Models\n",
        "  encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state])\n",
        "\n",
        "  # Below tensors will hold the states of the previous time step\n",
        "  decoder_state_input = Input(shape=(latent_dim, ))\n",
        "  decoder_hidden_state_input = Input(shape=(latent_dim, latent_dim))\n",
        "\n",
        "  # Get the embeddings of the decoder sequence\n",
        "  dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  # To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "  (decoder_outputs2, state2) = decoder(dec_emb2,\n",
        "          initial_state=decoder_state_input)\n",
        "\n",
        "  # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "  decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "  # Final decoder model\n",
        "  decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
        "                        decoder_state_input],\n",
        "                        [decoder_outputs2] + [state2])\n",
        "\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  rouge1 = 0\n",
        "  rouge2 = 0\n",
        "  rougel = 0\n",
        "  for i in range(0, 20):\n",
        "    original = seq2summary(y_val[i])\n",
        "    predict = decode_sequence(x_val[i].reshape(1, max_paragraphs_len))\n",
        "\n",
        "    rouge = Pythonrouge(summary_file_exist=False,\n",
        "                        summary=[[predict]], reference=[[[original]]],\n",
        "                        n_gram=2, ROUGE_SU4=False, ROUGE_L=True,\n",
        "                        recall_only=False, stemming=True, stopwords=True,\n",
        "                        word_level=True, length_limit=True, length=50,\n",
        "                        use_cf=False, cf=95, scoring_formula='average',\n",
        "                        resampling=True, samples=1000, favor=True, p=0.5)\n",
        "\n",
        "    score = rouge.calc_score()\n",
        "    rouge1 = rouge1 + score['ROUGE-1-R']\n",
        "    rouge2 = rouge2 + score['ROUGE-2-R']\n",
        "    rougel = rougel + score['ROUGE-L-R']\n",
        "\n",
        "  rogue1 = rouge1/20\n",
        "  rogue2 = rouge2/20\n",
        "  roguel = rougel/20\n",
        "  print(f'ROUGE 1 : {rogue1}, ROUGE 2 : {rogue2}, ROUGE L : {roguel}')\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# save model\n",
        "model.save(f'/content/drive/MyDrive/Dataset TA/my_model_{batch}_{lr}_{epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3ANLQ2wFid7"
      },
      "source": [
        "# Epoch 20 Batch 8 Lr 0.01\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdZ15c-OFnEg",
        "outputId": "353d0239-304c-4a6f-bdea-d63ec2d9b438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/20\n",
            "886/886 [==============================] - 73s 75ms/step - loss: 6.5830 - val_loss: 5.3452\n",
            "Epoch 2/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 4.4062 - val_loss: 4.0756\n",
            "Epoch 3/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 3.4032 - val_loss: 3.5243\n",
            "Epoch 4/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.9929 - val_loss: 3.2703\n",
            "Epoch 5/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.7823 - val_loss: 3.1312\n",
            "Epoch 6/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.6410 - val_loss: 3.0281\n",
            "Epoch 7/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.5520 - val_loss: 2.9771\n",
            "Epoch 8/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.5007 - val_loss: 2.8720\n",
            "Epoch 9/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.4276 - val_loss: 2.8405\n",
            "Epoch 10/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.3934 - val_loss: 2.8296\n",
            "Epoch 11/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.3735 - val_loss: 2.8154\n",
            "Epoch 12/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.3441 - val_loss: 2.7756\n",
            "Epoch 13/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.3251 - val_loss: 2.7596\n",
            "Epoch 14/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.3116 - val_loss: 2.7167\n",
            "Epoch 15/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.3026 - val_loss: 2.7303\n",
            "Epoch 16/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.2989 - val_loss: 2.7357\n",
            "Epoch 16: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_32'), name='input_32', description=\"created by layer 'input_32'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_32'), name='input_32', description=\"created by layer 'input_32'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.09970750000000002, ROUGE 2 : 0.0021075, ROUGE L : 0.07086850000000003\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/20\n",
            "886/886 [==============================] - 73s 75ms/step - loss: 2.4194 - val_loss: 2.3516\n",
            "Epoch 2/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.3437 - val_loss: 2.3646\n",
            "Epoch 3/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.3498 - val_loss: 2.4236\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_34'), name='input_34', description=\"created by layer 'input_34'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_34'), name='input_34', description=\"created by layer 'input_34'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.05522300000000001, ROUGE 2 : 0.002083, ROUGE L : 0.041884\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/20\n",
            "886/886 [==============================] - 78s 75ms/step - loss: 2.4037 - val_loss: 2.3151\n",
            "Epoch 2/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.3540 - val_loss: 2.3556\n",
            "Epoch 3/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.3518 - val_loss: 2.3925\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_36'), name='input_36', description=\"created by layer 'input_36'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_36'), name='input_36', description=\"created by layer 'input_36'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.10158700000000001, ROUGE 2 : 0.0021075, ROUGE L : 0.0613865\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/20\n",
            "886/886 [==============================] - 73s 75ms/step - loss: 2.3754 - val_loss: 2.3009\n",
            "Epoch 2/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.3281 - val_loss: 2.3407\n",
            "Epoch 3/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.3276 - val_loss: 2.3405\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_38'), name='input_38', description=\"created by layer 'input_38'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_38'), name='input_38', description=\"created by layer 'input_38'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.08139300000000001, ROUGE 2 : 0.0, ROUGE L : 0.06819\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/20\n",
            "886/886 [==============================] - 73s 75ms/step - loss: 2.3641 - val_loss: 2.3367\n",
            "Epoch 2/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.3330 - val_loss: 2.3777\n",
            "Epoch 3/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.3081 - val_loss: 2.3951\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_40'), name='input_40', description=\"created by layer 'input_40'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_40'), name='input_40', description=\"created by layer 'input_40'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.06163900000000002, ROUGE 2 : 0.0030825, ROUGE L : 0.050639000000000024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_18_layer_call_fn, gru_cell_18_layer_call_and_return_conditional_losses, gru_cell_19_layer_call_fn, gru_cell_19_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_8_0.01_20/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_8_0.01_20/assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fea5d4f53d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feaa6001590> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feaabf2d790> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fea5d6d1ed0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "# batch_size = [8, 16, 32, 64, 128]\n",
        "# Learning_rate = [0.01, 0.001, 0.0001]\n",
        "# epochs = [5, 10, 20]\n",
        "epoch = 20\n",
        "batch = 8\n",
        "lr = 0.01\n",
        "num_folds = 5\n",
        "inputs = np.concatenate((x_tr, x_val), axis=0)\n",
        "targets = np.concatenate((y_tr, y_val), axis=0)\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_paragraphs_len, ))\n",
        "\n",
        "# Embedding layer\n",
        "enc_emb = Embedding(x_voc, embedding_dim, trainable=True)(encoder_inputs)\n",
        "encoder_gru_1 = Bidirectional(GRU(latent_dim, return_sequences=True),                                                         \n",
        "                              merge_mode=\"concat\",\n",
        "                              name=\"primary_encoder\")(enc_emb)\n",
        "encoder_gru_2 = GRU(latent_dim, return_state=True, name='secondary_encoder')                               \n",
        "encoder_outputs, state = encoder_gru_2(encoder_gru_1)\n",
        "# Set up the decoder, using encoder_states as the initial state\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "# # Embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder = GRU(latent_dim, return_sequences=True, return_state=True, name='decoder')\n",
        "(decoder_outputs, decoder_state) =  decoder(dec_emb, initial_state=state)\n",
        "\n",
        "# Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "fold_no = 1\n",
        "for train, val in kfold.split(inputs, targets):\n",
        "  x_tr = inputs[train]\n",
        "  y_tr = targets[train]\n",
        "  x_val = inputs[val]\n",
        "  y_val = targets[val]\n",
        "\n",
        "  latent_dim = 100\n",
        "  embedding_dim = 300\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Compile Model\n",
        "  opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "  model.compile(optimizer=opt, loss='sparse_categorical_crossentropy')\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit([x_tr, y_tr[:, :-1]], y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:, 1:],\n",
        "              batch_size=batch,\n",
        "              epochs=epoch,\n",
        "              callbacks=[es],\n",
        "              validation_data=([x_val, y_val[:, :-1]], y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:, 1:]))\n",
        "  \n",
        "  # Inference Models\n",
        "  encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state])\n",
        "\n",
        "  # Below tensors will hold the states of the previous time step\n",
        "  decoder_state_input = Input(shape=(latent_dim, ))\n",
        "  decoder_hidden_state_input = Input(shape=(latent_dim, latent_dim))\n",
        "\n",
        "  # Get the embeddings of the decoder sequence\n",
        "  dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  # To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "  (decoder_outputs2, state2) = decoder(dec_emb2,\n",
        "          initial_state=decoder_state_input)\n",
        "\n",
        "  # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "  decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "  # Final decoder model\n",
        "  decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
        "                        decoder_state_input],\n",
        "                        [decoder_outputs2] + [state2])\n",
        "\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  rouge1 = 0\n",
        "  rouge2 = 0\n",
        "  rougel = 0\n",
        "  for i in range(0, 20):\n",
        "    original = seq2summary(y_val[i])\n",
        "    predict = decode_sequence(x_val[i].reshape(1, max_paragraphs_len))\n",
        "\n",
        "    rouge = Pythonrouge(summary_file_exist=False,\n",
        "                        summary=[[predict]], reference=[[[original]]],\n",
        "                        n_gram=2, ROUGE_SU4=False, ROUGE_L=True,\n",
        "                        recall_only=False, stemming=True, stopwords=True,\n",
        "                        word_level=True, length_limit=True, length=50,\n",
        "                        use_cf=False, cf=95, scoring_formula='average',\n",
        "                        resampling=True, samples=1000, favor=True, p=0.5)\n",
        "\n",
        "    score = rouge.calc_score()\n",
        "    rouge1 = rouge1 + score['ROUGE-1-R']\n",
        "    rouge2 = rouge2 + score['ROUGE-2-R']\n",
        "    rougel = rougel + score['ROUGE-L-R']\n",
        "\n",
        "  rogue1 = rouge1/20\n",
        "  rogue2 = rouge2/20\n",
        "  roguel = rougel/20\n",
        "  print(f'ROUGE 1 : {rogue1}, ROUGE 2 : {rogue2}, ROUGE L : {roguel}')\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# save model\n",
        "model.save(f'/content/drive/MyDrive/Dataset TA/my_model_{batch}_{lr}_{epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8ao_CtLMsx8"
      },
      "source": [
        "# Epoch 5 batch 16 lr 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exAGCEQKMy18",
        "outputId": "69d3b88b-2686-466e-d5ed-17e58ce24e76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/5\n",
            "443/443 [==============================] - 48s 93ms/step - loss: 6.4298 - val_loss: 5.0346\n",
            "Epoch 2/5\n",
            "443/443 [==============================] - 36s 80ms/step - loss: 3.8775 - val_loss: 3.4509\n",
            "Epoch 3/5\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 2.7039 - val_loss: 2.8545\n",
            "Epoch 4/5\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 2.2397 - val_loss: 2.5603\n",
            "Epoch 5/5\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 2.0074 - val_loss: 2.3841\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_44'), name='input_44', description=\"created by layer 'input_44'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_44'), name='input_44', description=\"created by layer 'input_44'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.136965, ROUGE 2 : 0.0040820000000000006, ROUGE L : 0.08441900000000002\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/5\n",
            "443/443 [==============================] - 44s 84ms/step - loss: 2.0029 - val_loss: 1.8621\n",
            "Epoch 2/5\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.7985 - val_loss: 1.8564\n",
            "Epoch 3/5\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.7307 - val_loss: 1.8284\n",
            "Epoch 4/5\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.6830 - val_loss: 1.8140\n",
            "Epoch 5/5\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.6284 - val_loss: 1.7742\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_46'), name='input_46', description=\"created by layer 'input_46'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_46'), name='input_46', description=\"created by layer 'input_46'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.07030700000000002, ROUGE 2 : 0.0031475, ROUGE L : 0.05606600000000002\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/5\n",
            "443/443 [==============================] - 44s 84ms/step - loss: 1.6573 - val_loss: 1.5907\n",
            "Epoch 2/5\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.5799 - val_loss: 1.5997\n",
            "Epoch 3/5\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.5485 - val_loss: 1.6253\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_48'), name='input_48', description=\"created by layer 'input_48'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_48'), name='input_48', description=\"created by layer 'input_48'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.031735, ROUGE 2 : 0.001064, ROUGE L : 0.026546000000000004\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/5\n",
            "443/443 [==============================] - 44s 84ms/step - loss: 1.5945 - val_loss: 1.5183\n",
            "Epoch 2/5\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.5326 - val_loss: 1.5832\n",
            "Epoch 3/5\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.5343 - val_loss: 1.6142\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_50'), name='input_50', description=\"created by layer 'input_50'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_50'), name='input_50', description=\"created by layer 'input_50'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.037367000000000004, ROUGE 2 : 0.0, ROUGE L : 0.030191500000000003\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/5\n",
            "443/443 [==============================] - 44s 85ms/step - loss: 1.5625 - val_loss: 1.5060\n",
            "Epoch 2/5\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.5242 - val_loss: 1.5896\n",
            "Epoch 3/5\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.5221 - val_loss: 1.6044\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_52'), name='input_52', description=\"created by layer 'input_52'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_52'), name='input_52', description=\"created by layer 'input_52'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.08487850000000001, ROUGE 2 : 0.0010415, ROUGE L : 0.06362250000000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_23_layer_call_fn, gru_cell_23_layer_call_and_return_conditional_losses, gru_cell_24_layer_call_fn, gru_cell_24_layer_call_and_return_conditional_losses, gru_cell_21_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_16_0.01_5/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_16_0.01_5/assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feabc26fe90> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feca5cfecd0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feaa8036bd0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feca4a3b450> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "# batch_size = [8, 16, 32, 64, 128]\n",
        "# Learning_rate = [0.01, 0.001, 0.0001]\n",
        "# epochs = [5, 10, 20]\n",
        "epoch = 5\n",
        "batch = 16\n",
        "lr = 0.01\n",
        "num_folds = 5\n",
        "inputs = np.concatenate((x_tr, x_val), axis=0)\n",
        "targets = np.concatenate((y_tr, y_val), axis=0)\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_paragraphs_len, ))\n",
        "\n",
        "# Embedding layer\n",
        "enc_emb = Embedding(x_voc, embedding_dim, trainable=True)(encoder_inputs)\n",
        "encoder_gru_1 = Bidirectional(GRU(latent_dim, return_sequences=True),                                                         \n",
        "                              merge_mode=\"concat\",\n",
        "                              name=\"primary_encoder\")(enc_emb)\n",
        "encoder_gru_2 = GRU(latent_dim, return_state=True, name='secondary_encoder')                               \n",
        "encoder_outputs, state = encoder_gru_2(encoder_gru_1)\n",
        "# Set up the decoder, using encoder_states as the initial state\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "# # Embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder = GRU(latent_dim, return_sequences=True, return_state=True, name='decoder')\n",
        "(decoder_outputs, decoder_state) =  decoder(dec_emb, initial_state=state)\n",
        "\n",
        "# Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "fold_no = 1\n",
        "for train, val in kfold.split(inputs, targets):\n",
        "  x_tr = inputs[train]\n",
        "  y_tr = targets[train]\n",
        "  x_val = inputs[val]\n",
        "  y_val = targets[val]\n",
        "\n",
        "  latent_dim = 100\n",
        "  embedding_dim = 300\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Compile Model\n",
        "  opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "  model.compile(optimizer=opt, loss='sparse_categorical_crossentropy')\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit([x_tr, y_tr[:, :-1]], y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:, 1:],\n",
        "              batch_size=batch,\n",
        "              epochs=epoch,\n",
        "              callbacks=[es],\n",
        "              validation_data=([x_val, y_val[:, :-1]], y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:, 1:]))\n",
        "  \n",
        "  # Inference Models\n",
        "  encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state])\n",
        "\n",
        "  # Below tensors will hold the states of the previous time step\n",
        "  decoder_state_input = Input(shape=(latent_dim, ))\n",
        "  decoder_hidden_state_input = Input(shape=(latent_dim, latent_dim))\n",
        "\n",
        "  # Get the embeddings of the decoder sequence\n",
        "  dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  # To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "  (decoder_outputs2, state2) = decoder(dec_emb2,\n",
        "          initial_state=decoder_state_input)\n",
        "\n",
        "  # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "  decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "  # Final decoder model\n",
        "  decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
        "                        decoder_state_input],\n",
        "                        [decoder_outputs2] + [state2])\n",
        "\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  rouge1 = 0\n",
        "  rouge2 = 0\n",
        "  rougel = 0\n",
        "  for i in range(0, 20):\n",
        "    original = seq2summary(y_val[i])\n",
        "    predict = decode_sequence(x_val[i].reshape(1, max_paragraphs_len))\n",
        "\n",
        "    rouge = Pythonrouge(summary_file_exist=False,\n",
        "                        summary=[[predict]], reference=[[[original]]],\n",
        "                        n_gram=2, ROUGE_SU4=False, ROUGE_L=True,\n",
        "                        recall_only=False, stemming=True, stopwords=True,\n",
        "                        word_level=True, length_limit=True, length=50,\n",
        "                        use_cf=False, cf=95, scoring_formula='average',\n",
        "                        resampling=True, samples=1000, favor=True, p=0.5)\n",
        "\n",
        "    score = rouge.calc_score()\n",
        "    rouge1 = rouge1 + score['ROUGE-1-R']\n",
        "    rouge2 = rouge2 + score['ROUGE-2-R']\n",
        "    rougel = rougel + score['ROUGE-L-R']\n",
        "\n",
        "  rogue1 = rouge1/20\n",
        "  rogue2 = rouge2/20\n",
        "  roguel = rougel/20\n",
        "  print(f'ROUGE 1 : {rogue1}, ROUGE 2 : {rogue2}, ROUGE L : {roguel}')\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# save model\n",
        "model.save(f'/content/drive/MyDrive/Dataset TA/my_model_{batch}_{lr}_{epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCN6f69mYBV-"
      },
      "source": [
        "# Epoch 10 Batch 16 Lr 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkYAPlHHX7va",
        "outputId": "a952da6d-d3ac-405f-d0bd-ca1a67df9e34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/10\n",
            "443/443 [==============================] - 44s 84ms/step - loss: 7.1623 - val_loss: 6.3326\n",
            "Epoch 2/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 5.4034 - val_loss: 4.7642\n",
            "Epoch 3/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 3.8487 - val_loss: 3.7847\n",
            "Epoch 4/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 3.0391 - val_loss: 3.2991\n",
            "Epoch 5/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 2.6442 - val_loss: 3.0060\n",
            "Epoch 6/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 2.4183 - val_loss: 2.8442\n",
            "Epoch 7/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 2.2682 - val_loss: 2.6911\n",
            "Epoch 8/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 2.1610 - val_loss: 2.6020\n",
            "Epoch 9/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 2.0777 - val_loss: 2.5493\n",
            "Epoch 10/10\n",
            "443/443 [==============================] - 36s 82ms/step - loss: 2.0324 - val_loss: 2.5142\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_56'), name='input_56', description=\"created by layer 'input_56'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_56'), name='input_56', description=\"created by layer 'input_56'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.08921150000000003, ROUGE 2 : 0.0030824999999999997, ROUGE L : 0.056981000000000004\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/10\n",
            "443/443 [==============================] - 45s 85ms/step - loss: 2.1392 - val_loss: 2.0571\n",
            "Epoch 2/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 2.0306 - val_loss: 2.0599\n",
            "Epoch 3/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.9918 - val_loss: 2.0630\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_58'), name='input_58', description=\"created by layer 'input_58'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_58'), name='input_58', description=\"created by layer 'input_58'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.10440700000000006, ROUGE 2 : 0.0010205000000000001, ROUGE L : 0.0689675\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/10\n",
            "443/443 [==============================] - 44s 85ms/step - loss: 2.0176 - val_loss: 1.9236\n",
            "Epoch 2/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.9547 - val_loss: 1.9749\n",
            "Epoch 3/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.9374 - val_loss: 1.9855\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_60'), name='input_60', description=\"created by layer 'input_60'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_60'), name='input_60', description=\"created by layer 'input_60'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.07006650000000002, ROUGE 2 : 0.0010415, ROUGE L : 0.05765150000000001\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/10\n",
            "443/443 [==============================] - 44s 84ms/step - loss: 1.9619 - val_loss: 1.8771\n",
            "Epoch 2/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.9105 - val_loss: 1.9326\n",
            "Epoch 3/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.9142 - val_loss: 1.9576\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_62'), name='input_62', description=\"created by layer 'input_62'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_62'), name='input_62', description=\"created by layer 'input_62'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.05210950000000001, ROUGE 2 : 0.0, ROUGE L : 0.041966\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/10\n",
            "443/443 [==============================] - 50s 85ms/step - loss: 1.9484 - val_loss: 1.8439\n",
            "Epoch 2/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.9035 - val_loss: 1.8902\n",
            "Epoch 3/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.8939 - val_loss: 1.9159\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_64'), name='input_64', description=\"created by layer 'input_64'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_64'), name='input_64', description=\"created by layer 'input_64'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.10298800000000001, ROUGE 2 : 0.0010205000000000001, ROUGE L : 0.06600800000000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_28_layer_call_fn, gru_cell_28_layer_call_and_return_conditional_losses, gru_cell_29_layer_call_fn, gru_cell_29_layer_call_and_return_conditional_losses, gru_cell_26_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_16_0.01_10/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_16_0.01_10/assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fea3820a190> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feaaada8910> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feca47a5650> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fead663d450> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "# batch_size = [8, 16, 32, 64, 128]\n",
        "# Learning_rate = [0.01, 0.001, 0.0001]\n",
        "# epochs = [5, 10, 20]\n",
        "epoch = 10\n",
        "batch = 16\n",
        "lr = 0.01\n",
        "num_folds = 5\n",
        "inputs = np.concatenate((x_tr, x_val), axis=0)\n",
        "targets = np.concatenate((y_tr, y_val), axis=0)\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_paragraphs_len, ))\n",
        "\n",
        "# Embedding layer\n",
        "enc_emb = Embedding(x_voc, embedding_dim, trainable=True)(encoder_inputs)\n",
        "encoder_gru_1 = Bidirectional(GRU(latent_dim, return_sequences=True),                                                         \n",
        "                              merge_mode=\"concat\",\n",
        "                              name=\"primary_encoder\")(enc_emb)\n",
        "encoder_gru_2 = GRU(latent_dim, return_state=True, name='secondary_encoder')                               \n",
        "encoder_outputs, state = encoder_gru_2(encoder_gru_1)\n",
        "# Set up the decoder, using encoder_states as the initial state\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "# # Embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder = GRU(latent_dim, return_sequences=True, return_state=True, name='decoder')\n",
        "(decoder_outputs, decoder_state) =  decoder(dec_emb, initial_state=state)\n",
        "\n",
        "# Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "fold_no = 1\n",
        "for train, val in kfold.split(inputs, targets):\n",
        "  x_tr = inputs[train]\n",
        "  y_tr = targets[train]\n",
        "  x_val = inputs[val]\n",
        "  y_val = targets[val]\n",
        "\n",
        "  latent_dim = 100\n",
        "  embedding_dim = 300\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Compile Model\n",
        "  opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "  model.compile(optimizer=opt, loss='sparse_categorical_crossentropy')\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit([x_tr, y_tr[:, :-1]], y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:, 1:],\n",
        "              batch_size=batch,\n",
        "              epochs=epoch,\n",
        "              callbacks=[es],\n",
        "              validation_data=([x_val, y_val[:, :-1]], y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:, 1:]))\n",
        "  \n",
        "  # Inference Models\n",
        "  encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state])\n",
        "\n",
        "  # Below tensors will hold the states of the previous time step\n",
        "  decoder_state_input = Input(shape=(latent_dim, ))\n",
        "  decoder_hidden_state_input = Input(shape=(latent_dim, latent_dim))\n",
        "\n",
        "  # Get the embeddings of the decoder sequence\n",
        "  dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  # To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "  (decoder_outputs2, state2) = decoder(dec_emb2,\n",
        "          initial_state=decoder_state_input)\n",
        "\n",
        "  # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "  decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "  # Final decoder model\n",
        "  decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
        "                        decoder_state_input],\n",
        "                        [decoder_outputs2] + [state2])\n",
        "\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  rouge1 = 0\n",
        "  rouge2 = 0\n",
        "  rougel = 0\n",
        "  for i in range(0, 20):\n",
        "    original = seq2summary(y_val[i])\n",
        "    predict = decode_sequence(x_val[i].reshape(1, max_paragraphs_len))\n",
        "\n",
        "    rouge = Pythonrouge(summary_file_exist=False,\n",
        "                        summary=[[predict]], reference=[[[original]]],\n",
        "                        n_gram=2, ROUGE_SU4=False, ROUGE_L=True,\n",
        "                        recall_only=False, stemming=True, stopwords=True,\n",
        "                        word_level=True, length_limit=True, length=50,\n",
        "                        use_cf=False, cf=95, scoring_formula='average',\n",
        "                        resampling=True, samples=1000, favor=True, p=0.5)\n",
        "\n",
        "    score = rouge.calc_score()\n",
        "    rouge1 = rouge1 + score['ROUGE-1-R']\n",
        "    rouge2 = rouge2 + score['ROUGE-2-R']\n",
        "    rougel = rougel + score['ROUGE-L-R']\n",
        "\n",
        "  rogue1 = rouge1/20\n",
        "  rogue2 = rouge2/20\n",
        "  roguel = rougel/20\n",
        "  print(f'ROUGE 1 : {rogue1}, ROUGE 2 : {rogue2}, ROUGE L : {roguel}')\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# save model\n",
        "model.save(f'/content/drive/MyDrive/Dataset TA/my_model_{batch}_{lr}_{epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZVIDoZIer5m"
      },
      "source": [
        "# Epoch 20 Batch 16 lr 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klWvGMMXeg6S",
        "outputId": "4da81ef6-01e0-4bab-ac41-142acad21a22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/20\n",
            "443/443 [==============================] - 44s 84ms/step - loss: 6.2770 - val_loss: 4.7854\n",
            "Epoch 2/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 3.7048 - val_loss: 3.2848\n",
            "Epoch 3/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 2.5989 - val_loss: 2.7153\n",
            "Epoch 4/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 2.1592 - val_loss: 2.4294\n",
            "Epoch 5/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.9360 - val_loss: 2.2623\n",
            "Epoch 6/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.7906 - val_loss: 2.1591\n",
            "Epoch 7/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.6986 - val_loss: 2.0838\n",
            "Epoch 8/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.6309 - val_loss: 2.0213\n",
            "Epoch 9/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.5753 - val_loss: 1.9682\n",
            "Epoch 10/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.5343 - val_loss: 1.9410\n",
            "Epoch 11/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.5022 - val_loss: 1.9140\n",
            "Epoch 12/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.4844 - val_loss: 1.8968\n",
            "Epoch 13/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.4653 - val_loss: 1.8711\n",
            "Epoch 14/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.4393 - val_loss: 1.8729\n",
            "Epoch 15/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.4354 - val_loss: 1.8536\n",
            "Epoch 16/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.4365 - val_loss: 1.8786\n",
            "Epoch 17/20\n",
            "443/443 [==============================] - 36s 80ms/step - loss: 1.4311 - val_loss: 1.8407\n",
            "Epoch 18/20\n",
            "443/443 [==============================] - 36s 80ms/step - loss: 1.4072 - val_loss: 1.8174\n",
            "Epoch 19/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.4035 - val_loss: 1.8361\n",
            "Epoch 20/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.4079 - val_loss: 1.8308\n",
            "Epoch 20: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_68'), name='input_68', description=\"created by layer 'input_68'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_68'), name='input_68', description=\"created by layer 'input_68'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.088705, ROUGE 2 : 0.0010205000000000001, ROUGE L : 0.07315250000000002\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/20\n",
            "443/443 [==============================] - 44s 84ms/step - loss: 1.5338 - val_loss: 1.4616\n",
            "Epoch 2/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.4798 - val_loss: 1.4976\n",
            "Epoch 3/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.4799 - val_loss: 1.5216\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_70'), name='input_70', description=\"created by layer 'input_70'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_70'), name='input_70', description=\"created by layer 'input_70'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.08755550000000002, ROUGE 2 : 0.007271999999999999, ROUGE L : 0.05616399999999999\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/20\n",
            "443/443 [==============================] - 44s 84ms/step - loss: 1.5194 - val_loss: 1.4651\n",
            "Epoch 2/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.4926 - val_loss: 1.4954\n",
            "Epoch 3/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.4824 - val_loss: 1.5033\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_72'), name='input_72', description=\"created by layer 'input_72'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_72'), name='input_72', description=\"created by layer 'input_72'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.03963600000000002, ROUGE 2 : 0.002062, ROUGE L : 0.032405500000000004\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/20\n",
            "443/443 [==============================] - 44s 84ms/step - loss: 1.5130 - val_loss: 1.4509\n",
            "Epoch 2/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.4827 - val_loss: 1.4960\n",
            "Epoch 3/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.4798 - val_loss: 1.5368\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_74'), name='input_74', description=\"created by layer 'input_74'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_74'), name='input_74', description=\"created by layer 'input_74'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.093558, ROUGE 2 : 0.0040820000000000006, ROUGE L : 0.07137250000000002\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/20\n",
            "443/443 [==============================] - 44s 84ms/step - loss: 1.5282 - val_loss: 1.4869\n",
            "Epoch 2/20\n",
            "443/443 [==============================] - 36s 80ms/step - loss: 1.4875 - val_loss: 1.5173\n",
            "Epoch 3/20\n",
            "443/443 [==============================] - 36s 80ms/step - loss: 1.4796 - val_loss: 1.5384\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_76'), name='input_76', description=\"created by layer 'input_76'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_76'), name='input_76', description=\"created by layer 'input_76'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.09944000000000001, ROUGE 2 : 0.0, ROUGE L : 0.06695850000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_33_layer_call_fn, gru_cell_33_layer_call_and_return_conditional_losses, gru_cell_34_layer_call_fn, gru_cell_34_layer_call_and_return_conditional_losses, gru_cell_31_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_16_0.01_20/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_16_0.01_20/assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fec9d2f5b10> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feca43c5b50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feaa72bf610> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feaa58fc890> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "# batch_size = [8, 16, 32, 64, 128]\n",
        "# Learning_rate = [0.01, 0.001, 0.0001]\n",
        "# epochs = [5, 10, 20]\n",
        "epoch = 20\n",
        "batch = 16\n",
        "lr = 0.01\n",
        "num_folds = 5\n",
        "inputs = np.concatenate((x_tr, x_val), axis=0)\n",
        "targets = np.concatenate((y_tr, y_val), axis=0)\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_paragraphs_len, ))\n",
        "\n",
        "# Embedding layer\n",
        "enc_emb = Embedding(x_voc, embedding_dim, trainable=True)(encoder_inputs)\n",
        "encoder_gru_1 = Bidirectional(GRU(latent_dim, return_sequences=True),                                                         \n",
        "                              merge_mode=\"concat\",\n",
        "                              name=\"primary_encoder\")(enc_emb)\n",
        "encoder_gru_2 = GRU(latent_dim, return_state=True, name='secondary_encoder')                               \n",
        "encoder_outputs, state = encoder_gru_2(encoder_gru_1)\n",
        "# Set up the decoder, using encoder_states as the initial state\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "# # Embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder = GRU(latent_dim, return_sequences=True, return_state=True, name='decoder')\n",
        "(decoder_outputs, decoder_state) =  decoder(dec_emb, initial_state=state)\n",
        "\n",
        "# Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "fold_no = 1\n",
        "for train, val in kfold.split(inputs, targets):\n",
        "  x_tr = inputs[train]\n",
        "  y_tr = targets[train]\n",
        "  x_val = inputs[val]\n",
        "  y_val = targets[val]\n",
        "\n",
        "  latent_dim = 100\n",
        "  embedding_dim = 300\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Compile Model\n",
        "  opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "  model.compile(optimizer=opt, loss='sparse_categorical_crossentropy')\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit([x_tr, y_tr[:, :-1]], y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:, 1:],\n",
        "              batch_size=batch,\n",
        "              epochs=epoch,\n",
        "              callbacks=[es],\n",
        "              validation_data=([x_val, y_val[:, :-1]], y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:, 1:]))\n",
        "  \n",
        "  # Inference Models\n",
        "  encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state])\n",
        "\n",
        "  # Below tensors will hold the states of the previous time step\n",
        "  decoder_state_input = Input(shape=(latent_dim, ))\n",
        "  decoder_hidden_state_input = Input(shape=(latent_dim, latent_dim))\n",
        "\n",
        "  # Get the embeddings of the decoder sequence\n",
        "  dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  # To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "  (decoder_outputs2, state2) = decoder(dec_emb2,\n",
        "          initial_state=decoder_state_input)\n",
        "\n",
        "  # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "  decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "  # Final decoder model\n",
        "  decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
        "                        decoder_state_input],\n",
        "                        [decoder_outputs2] + [state2])\n",
        "\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  rouge1 = 0\n",
        "  rouge2 = 0\n",
        "  rougel = 0\n",
        "  for i in range(0, 20):\n",
        "    original = seq2summary(y_val[i])\n",
        "    predict = decode_sequence(x_val[i].reshape(1, max_paragraphs_len))\n",
        "\n",
        "    rouge = Pythonrouge(summary_file_exist=False,\n",
        "                        summary=[[predict]], reference=[[[original]]],\n",
        "                        n_gram=2, ROUGE_SU4=False, ROUGE_L=True,\n",
        "                        recall_only=False, stemming=True, stopwords=True,\n",
        "                        word_level=True, length_limit=True, length=50,\n",
        "                        use_cf=False, cf=95, scoring_formula='average',\n",
        "                        resampling=True, samples=1000, favor=True, p=0.5)\n",
        "\n",
        "    score = rouge.calc_score()\n",
        "    rouge1 = rouge1 + score['ROUGE-1-R']\n",
        "    rouge2 = rouge2 + score['ROUGE-2-R']\n",
        "    rougel = rougel + score['ROUGE-L-R']\n",
        "\n",
        "  rogue1 = rouge1/20\n",
        "  rogue2 = rouge2/20\n",
        "  roguel = rougel/20\n",
        "  print(f'ROUGE 1 : {rogue1}, ROUGE 2 : {rogue2}, ROUGE L : {roguel}')\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# save model\n",
        "model.save(f'/content/drive/MyDrive/Dataset TA/my_model_{batch}_{lr}_{epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSmcgfuFgYCu"
      },
      "source": [
        "# Epoch 5 Batch 32 Lr 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mF6-09-gYp7",
        "outputId": "fe092a4a-d38c-49c6-c5ce-2afb2e208abe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/5\n",
            "222/222 [==============================] - 30s 103ms/step - loss: 7.0527 - val_loss: 6.0872\n",
            "Epoch 2/5\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 5.0498 - val_loss: 4.1947\n",
            "Epoch 3/5\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 3.3559 - val_loss: 3.2028\n",
            "Epoch 4/5\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 2.5902 - val_loss: 2.7154\n",
            "Epoch 5/5\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 2.2021 - val_loss: 2.4453\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_80'), name='input_80', description=\"created by layer 'input_80'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_80'), name='input_80', description=\"created by layer 'input_80'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.080908, ROUGE 2 : 0.0, ROUGE L : 0.056621\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/5\n",
            "222/222 [==============================] - 35s 103ms/step - loss: 2.1207 - val_loss: 1.9171\n",
            "Epoch 2/5\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.8278 - val_loss: 1.8308\n",
            "Epoch 3/5\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.7032 - val_loss: 1.7731\n",
            "Epoch 4/5\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.6153 - val_loss: 1.7166\n",
            "Epoch 5/5\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.5607 - val_loss: 1.7071\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_82'), name='input_82', description=\"created by layer 'input_82'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_82'), name='input_82', description=\"created by layer 'input_82'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.07695500000000001, ROUGE 2 : 0.002083, ROUGE L : 0.05060100000000001\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/5\n",
            "222/222 [==============================] - 30s 103ms/step - loss: 1.5596 - val_loss: 1.4860\n",
            "Epoch 2/5\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.4448 - val_loss: 1.5822\n",
            "Epoch 3/5\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.4179 - val_loss: 1.5073\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_84'), name='input_84', description=\"created by layer 'input_84'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_84'), name='input_84', description=\"created by layer 'input_84'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.095145, ROUGE 2 : 0.004124, ROUGE L : 0.06684399999999999\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/5\n",
            "222/222 [==============================] - 30s 103ms/step - loss: 1.4256 - val_loss: 1.3374\n",
            "Epoch 2/5\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.3453 - val_loss: 1.3543\n",
            "Epoch 3/5\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.3217 - val_loss: 1.3659\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_86'), name='input_86', description=\"created by layer 'input_86'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_86'), name='input_86', description=\"created by layer 'input_86'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.12000700000000002, ROUGE 2 : 0.004124, ROUGE L : 0.09115\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/5\n",
            "222/222 [==============================] - 30s 103ms/step - loss: 1.3375 - val_loss: 1.2633\n",
            "Epoch 2/5\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.2746 - val_loss: 1.2908\n",
            "Epoch 3/5\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.2650 - val_loss: 1.3201\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_88'), name='input_88', description=\"created by layer 'input_88'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_88'), name='input_88', description=\"created by layer 'input_88'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.080955, ROUGE 2 : 0.0020410000000000003, ROUGE L : 0.058580999999999994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_38_layer_call_fn, gru_cell_38_layer_call_and_return_conditional_losses, gru_cell_39_layer_call_fn, gru_cell_39_layer_call_and_return_conditional_losses, gru_cell_36_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_32_0.01_5/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_32_0.01_5/assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fea5ec3df50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fea5d36ef90> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fea5dcad810> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fea5c243d90> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "# batch_size = [8, 16, 32, 64, 128]\n",
        "# Learning_rate = [0.01, 0.001, 0.0001]\n",
        "# epochs = [5, 10, 20]\n",
        "epoch = 5\n",
        "batch = 32\n",
        "lr = 0.01\n",
        "num_folds = 5\n",
        "inputs = np.concatenate((x_tr, x_val), axis=0)\n",
        "targets = np.concatenate((y_tr, y_val), axis=0)\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_paragraphs_len, ))\n",
        "\n",
        "# Embedding layer\n",
        "enc_emb = Embedding(x_voc, embedding_dim, trainable=True)(encoder_inputs)\n",
        "encoder_gru_1 = Bidirectional(GRU(latent_dim, return_sequences=True),                                                         \n",
        "                              merge_mode=\"concat\",\n",
        "                              name=\"primary_encoder\")(enc_emb)\n",
        "encoder_gru_2 = GRU(latent_dim, return_state=True, name='secondary_encoder')                               \n",
        "encoder_outputs, state = encoder_gru_2(encoder_gru_1)\n",
        "# Set up the decoder, using encoder_states as the initial state\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "# # Embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder = GRU(latent_dim, return_sequences=True, return_state=True, name='decoder')\n",
        "(decoder_outputs, decoder_state) =  decoder(dec_emb, initial_state=state)\n",
        "\n",
        "# Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "fold_no = 1\n",
        "for train, val in kfold.split(inputs, targets):\n",
        "  x_tr = inputs[train]\n",
        "  y_tr = targets[train]\n",
        "  x_val = inputs[val]\n",
        "  y_val = targets[val]\n",
        "\n",
        "  latent_dim = 100\n",
        "  embedding_dim = 300\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Compile Model\n",
        "  opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "  model.compile(optimizer=opt, loss='sparse_categorical_crossentropy')\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit([x_tr, y_tr[:, :-1]], y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:, 1:],\n",
        "              batch_size=batch,\n",
        "              epochs=epoch,\n",
        "              callbacks=[es],\n",
        "              validation_data=([x_val, y_val[:, :-1]], y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:, 1:]))\n",
        "  \n",
        "  # Inference Models\n",
        "  encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state])\n",
        "\n",
        "  # Below tensors will hold the states of the previous time step\n",
        "  decoder_state_input = Input(shape=(latent_dim, ))\n",
        "  decoder_hidden_state_input = Input(shape=(latent_dim, latent_dim))\n",
        "\n",
        "  # Get the embeddings of the decoder sequence\n",
        "  dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  # To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "  (decoder_outputs2, state2) = decoder(dec_emb2,\n",
        "          initial_state=decoder_state_input)\n",
        "\n",
        "  # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "  decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "  # Final decoder model\n",
        "  decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
        "                        decoder_state_input],\n",
        "                        [decoder_outputs2] + [state2])\n",
        "\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  rouge1 = 0\n",
        "  rouge2 = 0\n",
        "  rougel = 0\n",
        "  for i in range(0, 10):\n",
        "    original = seq2summary(y_val[i])\n",
        "    predict = decode_sequence(x_val[i].reshape(1, max_paragraphs_len))\n",
        "\n",
        "    rouge = Pythonrouge(summary_file_exist=False,\n",
        "                        summary=[[predict]], reference=[[[original]]],\n",
        "                        n_gram=2, ROUGE_SU4=False, ROUGE_L=True,\n",
        "                        recall_only=False, stemming=True, stopwords=True,\n",
        "                        word_level=True, length_limit=True, length=50,\n",
        "                        use_cf=False, cf=95, scoring_formula='average',\n",
        "                        resampling=True, samples=1000, favor=True, p=0.5)\n",
        "\n",
        "    score = rouge.calc_score()\n",
        "    rouge1 = rouge1 + score['ROUGE-1-R']\n",
        "    rouge2 = rouge2 + score['ROUGE-2-R']\n",
        "    rougel = rougel + score['ROUGE-L-R']\n",
        "\n",
        "  rogue1 = rouge1/10\n",
        "  rogue2 = rouge2/10\n",
        "  roguel = rougel/10\n",
        "  print(f'ROUGE 1 : {rogue1}, ROUGE 2 : {rogue2}, ROUGE L : {roguel}')\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# save model\n",
        "model.save(f'/content/drive/MyDrive/Dataset TA/my_model_{batch}_{lr}_{epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odlnyyiskEH4"
      },
      "source": [
        "# Epoch 10 Batch 32 Lr 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAJzgI0-kK5S",
        "outputId": "5009f065-eb95-42db-bbf4-15218957748b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/10\n",
            "222/222 [==============================] - 30s 104ms/step - loss: 6.9060 - val_loss: 5.8985\n",
            "Epoch 2/10\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 4.8549 - val_loss: 4.1199\n",
            "Epoch 3/10\n",
            "222/222 [==============================] - 22s 97ms/step - loss: 3.2752 - val_loss: 3.1635\n",
            "Epoch 4/10\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 2.5459 - val_loss: 2.6977\n",
            "Epoch 5/10\n",
            "222/222 [==============================] - 22s 97ms/step - loss: 2.1759 - val_loss: 2.4427\n",
            "Epoch 6/10\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.9424 - val_loss: 2.2505\n",
            "Epoch 7/10\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.7911 - val_loss: 2.1181\n",
            "Epoch 8/10\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.6851 - val_loss: 2.0159\n",
            "Epoch 9/10\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.5959 - val_loss: 1.9390\n",
            "Epoch 10/10\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.5295 - val_loss: 1.9007\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_94'), name='input_94', description=\"created by layer 'input_94'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_94'), name='input_94', description=\"created by layer 'input_94'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.09441400000000001, ROUGE 2 : 0.002083, ROUGE L : 0.051272000000000005\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/10\n",
            "222/222 [==============================] - 30s 103ms/step - loss: 1.6017 - val_loss: 1.4883\n",
            "Epoch 2/10\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.4667 - val_loss: 1.4695\n",
            "Epoch 3/10\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.4220 - val_loss: 1.4705\n",
            "Epoch 4/10\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.3852 - val_loss: 1.4548\n",
            "Epoch 5/10\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.3622 - val_loss: 1.4602\n",
            "Epoch 6/10\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.3407 - val_loss: 1.4612\n",
            "Epoch 6: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_96'), name='input_96', description=\"created by layer 'input_96'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_96'), name='input_96', description=\"created by layer 'input_96'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.12222700000000002, ROUGE 2 : 0.004211, ROUGE L : 0.081402\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/10\n",
            "222/222 [==============================] - 30s 103ms/step - loss: 1.3703 - val_loss: 1.2708\n",
            "Epoch 2/10\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.3035 - val_loss: 1.2920\n",
            "Epoch 3/10\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.2816 - val_loss: 1.3091\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_98'), name='input_98', description=\"created by layer 'input_98'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_98'), name='input_98', description=\"created by layer 'input_98'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.086618, ROUGE 2 : 0.006389000000000001, ROUGE L : 0.065773\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/10\n",
            "222/222 [==============================] - 30s 103ms/step - loss: 1.3045 - val_loss: 1.2515\n",
            "Epoch 2/10\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.2449 - val_loss: 1.2817\n",
            "Epoch 3/10\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.2332 - val_loss: 1.3045\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_100'), name='input_100', description=\"created by layer 'input_100'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_100'), name='input_100', description=\"created by layer 'input_100'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.11258900000000001, ROUGE 2 : 0.0020410000000000003, ROUGE L : 0.085852\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/10\n",
            "222/222 [==============================] - 30s 103ms/step - loss: 1.2631 - val_loss: 1.2143\n",
            "Epoch 2/10\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.2124 - val_loss: 1.2590\n",
            "Epoch 3/10\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.2110 - val_loss: 1.2884\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_102'), name='input_102', description=\"created by layer 'input_102'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_102'), name='input_102', description=\"created by layer 'input_102'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.08627199999999999, ROUGE 2 : 0.001961, ROUGE L : 0.05824700000000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_47_layer_call_fn, gru_cell_47_layer_call_and_return_conditional_losses, gru_cell_48_layer_call_fn, gru_cell_48_layer_call_and_return_conditional_losses, gru_cell_45_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_32_0.01_10/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_32_0.01_10/assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fea5ef71610> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fead650b690> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fea5ef5fb90> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fea5ef55550> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "# batch_size = [8, 16, 32, 64, 128]\n",
        "# Learning_rate = [0.01, 0.001, 0.0001]\n",
        "# epochs = [5, 10, 20]\n",
        "epoch = 10\n",
        "batch = 32\n",
        "lr = 0.01\n",
        "num_folds = 5\n",
        "inputs = np.concatenate((x_tr, x_val), axis=0)\n",
        "targets = np.concatenate((y_tr, y_val), axis=0)\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_paragraphs_len, ))\n",
        "\n",
        "# Embedding layer\n",
        "enc_emb = Embedding(x_voc, embedding_dim, trainable=True)(encoder_inputs)\n",
        "encoder_gru_1 = Bidirectional(GRU(latent_dim, return_sequences=True),                                                         \n",
        "                              merge_mode=\"concat\",\n",
        "                              name=\"primary_encoder\")(enc_emb)\n",
        "encoder_gru_2 = GRU(latent_dim, return_state=True, name='secondary_encoder')                               \n",
        "encoder_outputs, state = encoder_gru_2(encoder_gru_1)\n",
        "# Set up the decoder, using encoder_states as the initial state\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "# # Embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder = GRU(latent_dim, return_sequences=True, return_state=True, name='decoder')\n",
        "(decoder_outputs, decoder_state) =  decoder(dec_emb, initial_state=state)\n",
        "\n",
        "# Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "fold_no = 1\n",
        "for train, val in kfold.split(inputs, targets):\n",
        "  x_tr = inputs[train]\n",
        "  y_tr = targets[train]\n",
        "  x_val = inputs[val]\n",
        "  y_val = targets[val]\n",
        "\n",
        "  latent_dim = 100\n",
        "  embedding_dim = 300\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Compile Model\n",
        "  opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "  model.compile(optimizer=opt, loss='sparse_categorical_crossentropy')\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit([x_tr, y_tr[:, :-1]], y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:, 1:],\n",
        "              batch_size=batch,\n",
        "              epochs=epoch,\n",
        "              callbacks=[es],\n",
        "              validation_data=([x_val, y_val[:, :-1]], y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:, 1:]))\n",
        "  \n",
        "  # Inference Models\n",
        "  encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state])\n",
        "\n",
        "  # Below tensors will hold the states of the previous time step\n",
        "  decoder_state_input = Input(shape=(latent_dim, ))\n",
        "  decoder_hidden_state_input = Input(shape=(latent_dim, latent_dim))\n",
        "\n",
        "  # Get the embeddings of the decoder sequence\n",
        "  dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  # To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "  (decoder_outputs2, state2) = decoder(dec_emb2,\n",
        "          initial_state=decoder_state_input)\n",
        "\n",
        "  # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "  decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "  # Final decoder model\n",
        "  decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
        "                        decoder_state_input],\n",
        "                        [decoder_outputs2] + [state2])\n",
        "\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  rouge1 = 0\n",
        "  rouge2 = 0\n",
        "  rougel = 0\n",
        "  for i in range(0, 10):\n",
        "    original = seq2summary(y_val[i])\n",
        "    predict = decode_sequence(x_val[i].reshape(1, max_paragraphs_len))\n",
        "\n",
        "    rouge = Pythonrouge(summary_file_exist=False,\n",
        "                        summary=[[predict]], reference=[[[original]]],\n",
        "                        n_gram=2, ROUGE_SU4=False, ROUGE_L=True,\n",
        "                        recall_only=False, stemming=True, stopwords=True,\n",
        "                        word_level=True, length_limit=True, length=50,\n",
        "                        use_cf=False, cf=95, scoring_formula='average',\n",
        "                        resampling=True, samples=1000, favor=True, p=0.5)\n",
        "\n",
        "    score = rouge.calc_score()\n",
        "    rouge1 = rouge1 + score['ROUGE-1-R']\n",
        "    rouge2 = rouge2 + score['ROUGE-2-R']\n",
        "    rougel = rougel + score['ROUGE-L-R']\n",
        "\n",
        "  rogue1 = rouge1/10\n",
        "  rogue2 = rouge2/10\n",
        "  roguel = rougel/10\n",
        "  print(f'ROUGE 1 : {rogue1}, ROUGE 2 : {rogue2}, ROUGE L : {roguel}')\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# save model\n",
        "model.save(f'/content/drive/MyDrive/Dataset TA/my_model_{batch}_{lr}_{epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UGp7B0vkcuV"
      },
      "source": [
        "# Epoch 20 Batch 32 Lr 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQgd5P3rkdTS",
        "outputId": "1ffc5b39-7d6f-4353-ebd5-f754da68e6f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/20\n",
            "222/222 [==============================] - 34s 103ms/step - loss: 6.7531 - val_loss: 5.6152\n",
            "Epoch 2/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 4.4665 - val_loss: 3.7626\n",
            "Epoch 3/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 2.8988 - val_loss: 2.9053\n",
            "Epoch 4/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 2.2262 - val_loss: 2.4566\n",
            "Epoch 5/20\n",
            "222/222 [==============================] - 22s 97ms/step - loss: 1.8791 - val_loss: 2.2072\n",
            "Epoch 6/20\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.6589 - val_loss: 2.0303\n",
            "Epoch 7/20\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.5220 - val_loss: 1.9027\n",
            "Epoch 8/20\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.4284 - val_loss: 1.8240\n",
            "Epoch 9/20\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.3650 - val_loss: 1.7743\n",
            "Epoch 10/20\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.2947 - val_loss: 1.7175\n",
            "Epoch 11/20\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.2622 - val_loss: 1.6866\n",
            "Epoch 12/20\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.2328 - val_loss: 1.6439\n",
            "Epoch 13/20\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.1918 - val_loss: 1.5956\n",
            "Epoch 14/20\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.1591 - val_loss: 1.5750\n",
            "Epoch 15/20\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.1515 - val_loss: 1.5984\n",
            "Epoch 16/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.1674 - val_loss: 1.6239\n",
            "Epoch 16: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_106'), name='input_106', description=\"created by layer 'input_106'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_106'), name='input_106', description=\"created by layer 'input_106'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.11257500000000001, ROUGE 2 : 0.004124, ROUGE L : 0.075975\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/20\n",
            "222/222 [==============================] - 30s 103ms/step - loss: 1.2487 - val_loss: 1.1444\n",
            "Epoch 2/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.1469 - val_loss: 1.1645\n",
            "Epoch 3/20\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.1333 - val_loss: 1.1766\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_108'), name='input_108', description=\"created by layer 'input_108'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_108'), name='input_108', description=\"created by layer 'input_108'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.06369, ROUGE 2 : 0.0, ROUGE L : 0.04517\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/20\n",
            "222/222 [==============================] - 30s 103ms/step - loss: 1.1558 - val_loss: 1.0698\n",
            "Epoch 2/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.0979 - val_loss: 1.1008\n",
            "Epoch 3/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.0900 - val_loss: 1.1268\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_110'), name='input_110', description=\"created by layer 'input_110'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_110'), name='input_110', description=\"created by layer 'input_110'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.065221, ROUGE 2 : 0.0020410000000000003, ROUGE L : 0.058965000000000004\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/20\n",
            "222/222 [==============================] - 30s 104ms/step - loss: 1.1271 - val_loss: 1.0435\n",
            "Epoch 2/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.0680 - val_loss: 1.0647\n",
            "Epoch 3/20\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.0786 - val_loss: 1.1018\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_112'), name='input_112', description=\"created by layer 'input_112'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_112'), name='input_112', description=\"created by layer 'input_112'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.072442, ROUGE 2 : 0.0021739999999999997, ROUGE L : 0.047682\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/20\n",
            "222/222 [==============================] - 30s 104ms/step - loss: 1.1084 - val_loss: 1.0498\n",
            "Epoch 2/20\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.0518 - val_loss: 1.0782\n",
            "Epoch 3/20\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.0760 - val_loss: 1.1392\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_114'), name='input_114', description=\"created by layer 'input_114'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_114'), name='input_114', description=\"created by layer 'input_114'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.070872, ROUGE 2 : 0.0020410000000000003, ROUGE L : 0.046582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_52_layer_call_fn, gru_cell_52_layer_call_and_return_conditional_losses, gru_cell_53_layer_call_fn, gru_cell_53_layer_call_and_return_conditional_losses, gru_cell_50_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_32_0.01_20/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_32_0.01_20/assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fea3a4e8a50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feaa6ee5d90> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fea5c937910> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feaa75286d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "# batch_size = [8, 16, 32, 64, 128]\n",
        "# Learning_rate = [0.01, 0.001, 0.0001]\n",
        "# epochs = [5, 10, 20]\n",
        "epoch = 20\n",
        "batch = 32\n",
        "lr = 0.01\n",
        "num_folds = 5\n",
        "inputs = np.concatenate((x_tr, x_val), axis=0)\n",
        "targets = np.concatenate((y_tr, y_val), axis=0)\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_paragraphs_len, ))\n",
        "\n",
        "# Embedding layer\n",
        "enc_emb = Embedding(x_voc, embedding_dim, trainable=True)(encoder_inputs)\n",
        "encoder_gru_1 = Bidirectional(GRU(latent_dim, return_sequences=True),                                                         \n",
        "                              merge_mode=\"concat\",\n",
        "                              name=\"primary_encoder\")(enc_emb)\n",
        "encoder_gru_2 = GRU(latent_dim, return_state=True, name='secondary_encoder')                               \n",
        "encoder_outputs, state = encoder_gru_2(encoder_gru_1)\n",
        "# Set up the decoder, using encoder_states as the initial state\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "# # Embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder = GRU(latent_dim, return_sequences=True, return_state=True, name='decoder')\n",
        "(decoder_outputs, decoder_state) =  decoder(dec_emb, initial_state=state)\n",
        "\n",
        "# Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "fold_no = 1\n",
        "for train, val in kfold.split(inputs, targets):\n",
        "  x_tr = inputs[train]\n",
        "  y_tr = targets[train]\n",
        "  x_val = inputs[val]\n",
        "  y_val = targets[val]\n",
        "\n",
        "  latent_dim = 100\n",
        "  embedding_dim = 300\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Compile Model\n",
        "  opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "  model.compile(optimizer=opt, loss='sparse_categorical_crossentropy')\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit([x_tr, y_tr[:, :-1]], y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:, 1:],\n",
        "              batch_size=batch,\n",
        "              epochs=epoch,\n",
        "              callbacks=[es],\n",
        "              validation_data=([x_val, y_val[:, :-1]], y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:, 1:]))\n",
        "  \n",
        "  # Inference Models\n",
        "  encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state])\n",
        "\n",
        "  # Below tensors will hold the states of the previous time step\n",
        "  decoder_state_input = Input(shape=(latent_dim, ))\n",
        "  decoder_hidden_state_input = Input(shape=(latent_dim, latent_dim))\n",
        "\n",
        "  # Get the embeddings of the decoder sequence\n",
        "  dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  # To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "  (decoder_outputs2, state2) = decoder(dec_emb2,\n",
        "          initial_state=decoder_state_input)\n",
        "\n",
        "  # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "  decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "  # Final decoder model\n",
        "  decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
        "                        decoder_state_input],\n",
        "                        [decoder_outputs2] + [state2])\n",
        "\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  rouge1 = 0\n",
        "  rouge2 = 0\n",
        "  rougel = 0\n",
        "  for i in range(0, 10):\n",
        "    original = seq2summary(y_val[i])\n",
        "    predict = decode_sequence(x_val[i].reshape(1, max_paragraphs_len))\n",
        "\n",
        "    rouge = Pythonrouge(summary_file_exist=False,\n",
        "                        summary=[[predict]], reference=[[[original]]],\n",
        "                        n_gram=2, ROUGE_SU4=False, ROUGE_L=True,\n",
        "                        recall_only=False, stemming=True, stopwords=True,\n",
        "                        word_level=True, length_limit=True, length=50,\n",
        "                        use_cf=False, cf=95, scoring_formula='average',\n",
        "                        resampling=True, samples=1000, favor=True, p=0.5)\n",
        "\n",
        "    score = rouge.calc_score()\n",
        "    rouge1 = rouge1 + score['ROUGE-1-R']\n",
        "    rouge2 = rouge2 + score['ROUGE-2-R']\n",
        "    rougel = rougel + score['ROUGE-L-R']\n",
        "\n",
        "  rogue1 = rouge1/10\n",
        "  rogue2 = rouge2/10\n",
        "  roguel = rougel/10\n",
        "  print(f'ROUGE 1 : {rogue1}, ROUGE 2 : {rogue2}, ROUGE L : {roguel}')\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# save model\n",
        "model.save(f'/content/drive/MyDrive/Dataset TA/my_model_{batch}_{lr}_{epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4sdMRYpkrWv"
      },
      "source": [
        "# Epoch 5 Batch 8 Lr 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MvB3Y9XkxOF",
        "outputId": "e5140bf2-d908-48d2-f97a-2d101f28b369"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/5\n",
            "886/886 [==============================] - 79s 75ms/step - loss: 6.9486 - val_loss: 6.3688\n",
            "Epoch 2/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 5.8935 - val_loss: 5.5409\n",
            "Epoch 3/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 5.0840 - val_loss: 4.8956\n",
            "Epoch 4/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 4.3878 - val_loss: 4.3538\n",
            "Epoch 5/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 3.8020 - val_loss: 3.8890\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_118'), name='input_118', description=\"created by layer 'input_118'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_118'), name='input_118', description=\"created by layer 'input_118'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.11798950000000001, ROUGE 2 : 0.0103105, ROUGE L : 0.08347249999999999\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/5\n",
            "886/886 [==============================] - 73s 75ms/step - loss: 3.6178 - val_loss: 3.3311\n",
            "Epoch 2/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 3.0919 - val_loss: 2.9920\n",
            "Epoch 3/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.7051 - val_loss: 2.7272\n",
            "Epoch 4/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.4048 - val_loss: 2.4999\n",
            "Epoch 5/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.1657 - val_loss: 2.3171\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_120'), name='input_120', description=\"created by layer 'input_120'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_120'), name='input_120', description=\"created by layer 'input_120'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.103837, ROUGE 2 : 0.0051235, ROUGE L : 0.0742175\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/5\n",
            "886/886 [==============================] - 73s 75ms/step - loss: 2.1386 - val_loss: 1.9400\n",
            "Epoch 2/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.8834 - val_loss: 1.8311\n",
            "Epoch 3/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.7171 - val_loss: 1.7229\n",
            "Epoch 4/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.5841 - val_loss: 1.6388\n",
            "Epoch 5/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.4693 - val_loss: 1.5518\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_122'), name='input_122', description=\"created by layer 'input_122'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_122'), name='input_122', description=\"created by layer 'input_122'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.10751250000000001, ROUGE 2 : 0.0094015, ROUGE L : 0.07815550000000002\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/5\n",
            "886/886 [==============================] - 73s 75ms/step - loss: 1.4577 - val_loss: 1.3446\n",
            "Epoch 2/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.3224 - val_loss: 1.2979\n",
            "Epoch 3/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.2346 - val_loss: 1.2506\n",
            "Epoch 4/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.1581 - val_loss: 1.2029\n",
            "Epoch 5/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.0980 - val_loss: 1.1727\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_124'), name='input_124', description=\"created by layer 'input_124'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_124'), name='input_124', description=\"created by layer 'input_124'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.11585050000000004, ROUGE 2 : 0.005144999999999999, ROUGE L : 0.076323\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/5\n",
            "886/886 [==============================] - 73s 75ms/step - loss: 1.0961 - val_loss: 0.9955\n",
            "Epoch 2/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.0070 - val_loss: 0.9759\n",
            "Epoch 3/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.9558 - val_loss: 0.9753\n",
            "Epoch 4/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.9210 - val_loss: 0.9376\n",
            "Epoch 5/5\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.8582 - val_loss: 0.9054\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_126'), name='input_126', description=\"created by layer 'input_126'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_126'), name='input_126', description=\"created by layer 'input_126'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.11133249999999999, ROUGE 2 : 0.023490500000000004, ROUGE L : 0.08495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_57_layer_call_fn, gru_cell_57_layer_call_and_return_conditional_losses, gru_cell_58_layer_call_fn, gru_cell_58_layer_call_and_return_conditional_losses, gru_cell_55_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_8_0.001_5/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_8_0.001_5/assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fea6e739250> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fea3accc250> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fea5ccef250> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fea37d99e50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "# batch_size = [8, 16, 32, 64, 128]\n",
        "# Learning_rate = [0.01, 0.001, 0.0001]\n",
        "# epochs = [5, 10, 20]\n",
        "epoch = 5\n",
        "batch = 8\n",
        "lr = 0.001\n",
        "num_folds = 5\n",
        "inputs = np.concatenate((x_tr, x_val), axis=0)\n",
        "targets = np.concatenate((y_tr, y_val), axis=0)\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_paragraphs_len, ))\n",
        "\n",
        "# Embedding layer\n",
        "enc_emb = Embedding(x_voc, embedding_dim, trainable=True)(encoder_inputs)\n",
        "encoder_gru_1 = Bidirectional(GRU(latent_dim, return_sequences=True),                                                         \n",
        "                              merge_mode=\"concat\",\n",
        "                              name=\"primary_encoder\")(enc_emb)\n",
        "encoder_gru_2 = GRU(latent_dim, return_state=True, name='secondary_encoder')                               \n",
        "encoder_outputs, state = encoder_gru_2(encoder_gru_1)\n",
        "# Set up the decoder, using encoder_states as the initial state\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "# # Embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder = GRU(latent_dim, return_sequences=True, return_state=True, name='decoder')\n",
        "(decoder_outputs, decoder_state) =  decoder(dec_emb, initial_state=state)\n",
        "\n",
        "# Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "fold_no = 1\n",
        "for train, val in kfold.split(inputs, targets):\n",
        "  x_tr = inputs[train]\n",
        "  y_tr = targets[train]\n",
        "  x_val = inputs[val]\n",
        "  y_val = targets[val]\n",
        "\n",
        "  latent_dim = 100\n",
        "  embedding_dim = 300\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Compile Model\n",
        "  opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "  model.compile(optimizer=opt, loss='sparse_categorical_crossentropy')\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit([x_tr, y_tr[:, :-1]], y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:, 1:],\n",
        "              batch_size=batch,\n",
        "              epochs=epoch,\n",
        "              callbacks=[es],\n",
        "              validation_data=([x_val, y_val[:, :-1]], y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:, 1:]))\n",
        "  \n",
        "  # Inference Models\n",
        "  encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state])\n",
        "\n",
        "  # Below tensors will hold the states of the previous time step\n",
        "  decoder_state_input = Input(shape=(latent_dim, ))\n",
        "  decoder_hidden_state_input = Input(shape=(latent_dim, latent_dim))\n",
        "\n",
        "  # Get the embeddings of the decoder sequence\n",
        "  dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  # To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "  (decoder_outputs2, state2) = decoder(dec_emb2,\n",
        "          initial_state=decoder_state_input)\n",
        "\n",
        "  # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "  decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "  # Final decoder model\n",
        "  decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
        "                        decoder_state_input],\n",
        "                        [decoder_outputs2] + [state2])\n",
        "\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  rouge1 = 0\n",
        "  rouge2 = 0\n",
        "  rougel = 0\n",
        "  for i in range(0, 20):\n",
        "    original = seq2summary(y_val[i])\n",
        "    predict = decode_sequence(x_val[i].reshape(1, max_paragraphs_len))\n",
        "\n",
        "    rouge = Pythonrouge(summary_file_exist=False,\n",
        "                        summary=[[predict]], reference=[[[original]]],\n",
        "                        n_gram=2, ROUGE_SU4=False, ROUGE_L=True,\n",
        "                        recall_only=False, stemming=True, stopwords=True,\n",
        "                        word_level=True, length_limit=True, length=50,\n",
        "                        use_cf=False, cf=95, scoring_formula='average',\n",
        "                        resampling=True, samples=1000, favor=True, p=0.5)\n",
        "\n",
        "    score = rouge.calc_score()\n",
        "    rouge1 = rouge1 + score['ROUGE-1-R']\n",
        "    rouge2 = rouge2 + score['ROUGE-2-R']\n",
        "    rougel = rougel + score['ROUGE-L-R']\n",
        "\n",
        "  rogue1 = rouge1/20\n",
        "  rogue2 = rouge2/20\n",
        "  roguel = rougel/20\n",
        "  print(f'ROUGE 1 : {rogue1}, ROUGE 2 : {rogue2}, ROUGE L : {roguel}')\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# save model\n",
        "model.save(f'/content/drive/MyDrive/Dataset TA/my_model_{batch}_{lr}_{epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdcxADMPlGAu"
      },
      "source": [
        "# Epoch 10 Batch 8 Lr 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJuX2WNHlKpD",
        "outputId": "e733d55d-0ac3-437e-8928-40c3796985f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/10\n",
            "886/886 [==============================] - 73s 75ms/step - loss: 6.9421 - val_loss: 6.3754\n",
            "Epoch 2/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 5.8912 - val_loss: 5.5494\n",
            "Epoch 3/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 5.0479 - val_loss: 4.8530\n",
            "Epoch 4/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 4.3210 - val_loss: 4.2948\n",
            "Epoch 5/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 3.7070 - val_loss: 3.8128\n",
            "Epoch 6/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 3.2033 - val_loss: 3.4099\n",
            "Epoch 7/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.8018 - val_loss: 3.0978\n",
            "Epoch 8/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.4824 - val_loss: 2.8364\n",
            "Epoch 9/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.2267 - val_loss: 2.6147\n",
            "Epoch 10/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.0142 - val_loss: 2.4266\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_130'), name='input_130', description=\"created by layer 'input_130'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_130'), name='input_130', description=\"created by layer 'input_130'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.1238785, ROUGE 2 : 0.0082305, ROUGE L : 0.08607700000000003\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/10\n",
            "886/886 [==============================] - 73s 75ms/step - loss: 2.0398 - val_loss: 1.8448\n",
            "Epoch 2/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.7988 - val_loss: 1.7488\n",
            "Epoch 3/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.6474 - val_loss: 1.6603\n",
            "Epoch 4/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.5227 - val_loss: 1.5775\n",
            "Epoch 5/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.4103 - val_loss: 1.4996\n",
            "Epoch 6/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.3153 - val_loss: 1.4384\n",
            "Epoch 7/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.2365 - val_loss: 1.3786\n",
            "Epoch 8/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.1618 - val_loss: 1.3233\n",
            "Epoch 9/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.0973 - val_loss: 1.2735\n",
            "Epoch 10/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.0327 - val_loss: 1.2258\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_132'), name='input_132', description=\"created by layer 'input_132'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_132'), name='input_132', description=\"created by layer 'input_132'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.1753725, ROUGE 2 : 0.0847635, ROUGE L : 0.157124\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/10\n",
            "886/886 [==============================] - 73s 75ms/step - loss: 1.0538 - val_loss: 0.9520\n",
            "Epoch 2/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.9720 - val_loss: 0.9430\n",
            "Epoch 3/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.9197 - val_loss: 0.9273\n",
            "Epoch 4/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.8770 - val_loss: 0.9147\n",
            "Epoch 5/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.8313 - val_loss: 0.8783\n",
            "Epoch 6/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.7944 - val_loss: 0.8673\n",
            "Epoch 7/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.7576 - val_loss: 0.8428\n",
            "Epoch 8/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.7219 - val_loss: 0.8188\n",
            "Epoch 9/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.6969 - val_loss: 0.8227\n",
            "Epoch 10/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.6730 - val_loss: 0.7864\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_134'), name='input_134', description=\"created by layer 'input_134'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_134'), name='input_134', description=\"created by layer 'input_134'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.145869, ROUGE 2 : 0.05270850000000001, ROUGE L : 0.12361600000000002\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/10\n",
            "886/886 [==============================] - 73s 75ms/step - loss: 0.6818 - val_loss: 0.6220\n",
            "Epoch 2/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.6457 - val_loss: 0.6367\n",
            "Epoch 3/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.6125 - val_loss: 0.6247\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_136'), name='input_136', description=\"created by layer 'input_136'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_136'), name='input_136', description=\"created by layer 'input_136'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.349001, ROUGE 2 : 0.26298900000000003, ROUGE L : 0.31730400000000003\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/10\n",
            "886/886 [==============================] - 73s 75ms/step - loss: 0.6108 - val_loss: 0.5502\n",
            "Epoch 2/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.5742 - val_loss: 0.5619\n",
            "Epoch 3/10\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.5502 - val_loss: 0.5606\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_138'), name='input_138', description=\"created by layer 'input_138'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_138'), name='input_138', description=\"created by layer 'input_138'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.2903055, ROUGE 2 : 0.1781285, ROUGE L : 0.2557645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_62_layer_call_fn, gru_cell_62_layer_call_and_return_conditional_losses, gru_cell_63_layer_call_fn, gru_cell_63_layer_call_and_return_conditional_losses, gru_cell_60_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_8_0.001_10/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_8_0.001_10/assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fea5e5a3dd0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feaaadb1090> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feca5dce990> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fead65a7590> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "# batch_size = [8, 16, 32, 64, 128]\n",
        "# Learning_rate = [0.01, 0.001, 0.0001]\n",
        "# epochs = [5, 10, 20]\n",
        "epoch = 10\n",
        "batch = 8\n",
        "lr = 0.001\n",
        "num_folds = 5\n",
        "inputs = np.concatenate((x_tr, x_val), axis=0)\n",
        "targets = np.concatenate((y_tr, y_val), axis=0)\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_paragraphs_len, ))\n",
        "\n",
        "# Embedding layer\n",
        "enc_emb = Embedding(x_voc, embedding_dim, trainable=True)(encoder_inputs)\n",
        "encoder_gru_1 = Bidirectional(GRU(latent_dim, return_sequences=True),                                                         \n",
        "                              merge_mode=\"concat\",\n",
        "                              name=\"primary_encoder\")(enc_emb)\n",
        "encoder_gru_2 = GRU(latent_dim, return_state=True, name='secondary_encoder')                               \n",
        "encoder_outputs, state = encoder_gru_2(encoder_gru_1)\n",
        "# Set up the decoder, using encoder_states as the initial state\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "# # Embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder = GRU(latent_dim, return_sequences=True, return_state=True, name='decoder')\n",
        "(decoder_outputs, decoder_state) =  decoder(dec_emb, initial_state=state)\n",
        "\n",
        "# Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "fold_no = 1\n",
        "for train, val in kfold.split(inputs, targets):\n",
        "  x_tr = inputs[train]\n",
        "  y_tr = targets[train]\n",
        "  x_val = inputs[val]\n",
        "  y_val = targets[val]\n",
        "\n",
        "  latent_dim = 100\n",
        "  embedding_dim = 300\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Compile Model\n",
        "  opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "  model.compile(optimizer=opt, loss='sparse_categorical_crossentropy')\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit([x_tr, y_tr[:, :-1]], y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:, 1:],\n",
        "              batch_size=batch,\n",
        "              epochs=epoch,\n",
        "              callbacks=[es],\n",
        "              validation_data=([x_val, y_val[:, :-1]], y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:, 1:]))\n",
        "  \n",
        "  # Inference Models\n",
        "  encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state])\n",
        "\n",
        "  # Below tensors will hold the states of the previous time step\n",
        "  decoder_state_input = Input(shape=(latent_dim, ))\n",
        "  decoder_hidden_state_input = Input(shape=(latent_dim, latent_dim))\n",
        "\n",
        "  # Get the embeddings of the decoder sequence\n",
        "  dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  # To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "  (decoder_outputs2, state2) = decoder(dec_emb2,\n",
        "          initial_state=decoder_state_input)\n",
        "\n",
        "  # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "  decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "  # Final decoder model\n",
        "  decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
        "                        decoder_state_input],\n",
        "                        [decoder_outputs2] + [state2])\n",
        "\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  rouge1 = 0\n",
        "  rouge2 = 0\n",
        "  rougel = 0\n",
        "  for i in range(0, 20):\n",
        "    original = seq2summary(y_val[i])\n",
        "    predict = decode_sequence(x_val[i].reshape(1, max_paragraphs_len))\n",
        "\n",
        "    rouge = Pythonrouge(summary_file_exist=False,\n",
        "                        summary=[[predict]], reference=[[[original]]],\n",
        "                        n_gram=2, ROUGE_SU4=False, ROUGE_L=True,\n",
        "                        recall_only=False, stemming=True, stopwords=True,\n",
        "                        word_level=True, length_limit=True, length=50,\n",
        "                        use_cf=False, cf=95, scoring_formula='average',\n",
        "                        resampling=True, samples=1000, favor=True, p=0.5)\n",
        "\n",
        "    score = rouge.calc_score()\n",
        "    rouge1 = rouge1 + score['ROUGE-1-R']\n",
        "    rouge2 = rouge2 + score['ROUGE-2-R']\n",
        "    rougel = rougel + score['ROUGE-L-R']\n",
        "\n",
        "  rogue1 = rouge1/20\n",
        "  rogue2 = rouge2/20\n",
        "  roguel = rougel/20\n",
        "  print(f'ROUGE 1 : {rogue1}, ROUGE 2 : {rogue2}, ROUGE L : {roguel}')\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# save model\n",
        "model.save(f'/content/drive/MyDrive/Dataset TA/my_model_{batch}_{lr}_{epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ-93FA0lR-I"
      },
      "source": [
        "# Epoch 20 Batch 8 Lr 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46ZP0FYSlWpk",
        "outputId": "5d68c5b3-5c20-4576-e10a-fbebc914d236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/20\n",
            "886/886 [==============================] - 73s 75ms/step - loss: 6.9437 - val_loss: 6.3579\n",
            "Epoch 2/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 5.9145 - val_loss: 5.5577\n",
            "Epoch 3/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 5.0894 - val_loss: 4.8810\n",
            "Epoch 4/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 4.3758 - val_loss: 4.3196\n",
            "Epoch 5/20\n",
            "886/886 [==============================] - 64s 73ms/step - loss: 3.7731 - val_loss: 3.8431\n",
            "Epoch 6/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 3.2730 - val_loss: 3.4540\n",
            "Epoch 7/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.8725 - val_loss: 3.1345\n",
            "Epoch 8/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.5568 - val_loss: 2.8591\n",
            "Epoch 9/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.3009 - val_loss: 2.6444\n",
            "Epoch 10/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 2.0920 - val_loss: 2.4648\n",
            "Epoch 11/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.9153 - val_loss: 2.2962\n",
            "Epoch 12/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.7667 - val_loss: 2.1565\n",
            "Epoch 13/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.6423 - val_loss: 2.0395\n",
            "Epoch 14/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.5352 - val_loss: 1.9319\n",
            "Epoch 15/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.4427 - val_loss: 1.8443\n",
            "Epoch 16/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.3529 - val_loss: 1.7563\n",
            "Epoch 17/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.2821 - val_loss: 1.6922\n",
            "Epoch 18/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.2174 - val_loss: 1.6156\n",
            "Epoch 19/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.1525 - val_loss: 1.5555\n",
            "Epoch 20/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.0977 - val_loss: 1.4865\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_142'), name='input_142', description=\"created by layer 'input_142'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_142'), name='input_142', description=\"created by layer 'input_142'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.08356500000000001, ROUGE 2 : 0.0020410000000000003, ROUGE L : 0.06220650000000001\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/20\n",
            "886/886 [==============================] - 73s 75ms/step - loss: 1.1624 - val_loss: 1.0601\n",
            "Epoch 2/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.0817 - val_loss: 1.0575\n",
            "Epoch 3/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 1.0251 - val_loss: 1.0337\n",
            "Epoch 4/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.9901 - val_loss: 1.0240\n",
            "Epoch 5/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.9329 - val_loss: 0.9922\n",
            "Epoch 6/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.8972 - val_loss: 0.9662\n",
            "Epoch 7/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.8672 - val_loss: 0.9655\n",
            "Epoch 8/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.8322 - val_loss: 0.9307\n",
            "Epoch 9/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.7955 - val_loss: 0.9217\n",
            "Epoch 10/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.7798 - val_loss: 0.9029\n",
            "Epoch 11/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.7505 - val_loss: 0.8782\n",
            "Epoch 12/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.7308 - val_loss: 0.8643\n",
            "Epoch 13/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.6927 - val_loss: 0.8397\n",
            "Epoch 14/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.6697 - val_loss: 0.8167\n",
            "Epoch 15/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.6566 - val_loss: 0.8225\n",
            "Epoch 16/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.6404 - val_loss: 0.8119\n",
            "Epoch 17/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.6178 - val_loss: 0.7924\n",
            "Epoch 18/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.6007 - val_loss: 0.7725\n",
            "Epoch 19/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.5819 - val_loss: 0.7566\n",
            "Epoch 20/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.5587 - val_loss: 0.7416\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_144'), name='input_144', description=\"created by layer 'input_144'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_144'), name='input_144', description=\"created by layer 'input_144'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.232761, ROUGE 2 : 0.1470255, ROUGE L : 0.208292\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/20\n",
            "886/886 [==============================] - 79s 75ms/step - loss: 0.5936 - val_loss: 0.5242\n",
            "Epoch 2/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.5605 - val_loss: 0.5446\n",
            "Epoch 3/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.5393 - val_loss: 0.5415\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_146'), name='input_146', description=\"created by layer 'input_146'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_146'), name='input_146', description=\"created by layer 'input_146'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.224457, ROUGE 2 : 0.11961549999999996, ROUGE L : 0.19474450000000004\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/20\n",
            "886/886 [==============================] - 74s 75ms/step - loss: 0.5474 - val_loss: 0.4981\n",
            "Epoch 2/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.5383 - val_loss: 0.5135\n",
            "Epoch 3/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.4928 - val_loss: 0.4722\n",
            "Epoch 4/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.4723 - val_loss: 0.4996\n",
            "Epoch 5/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.4819 - val_loss: 0.5422\n",
            "Epoch 5: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_148'), name='input_148', description=\"created by layer 'input_148'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_148'), name='input_148', description=\"created by layer 'input_148'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.2837835000000001, ROUGE 2 : 0.18590050000000002, ROUGE L : 0.25731600000000004\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/20\n",
            "886/886 [==============================] - 73s 75ms/step - loss: 0.4809 - val_loss: 0.4295\n",
            "Epoch 2/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.4468 - val_loss: 0.4389\n",
            "Epoch 3/20\n",
            "886/886 [==============================] - 65s 73ms/step - loss: 0.4452 - val_loss: 0.4568\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_150'), name='input_150', description=\"created by layer 'input_150'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_150'), name='input_150', description=\"created by layer 'input_150'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.23930800000000002, ROUGE 2 : 0.14469300000000002, ROUGE L : 0.2177385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_67_layer_call_fn, gru_cell_67_layer_call_and_return_conditional_losses, gru_cell_68_layer_call_fn, gru_cell_68_layer_call_and_return_conditional_losses, gru_cell_65_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_8_0.001_20/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_8_0.001_20/assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fea5df9bd90> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feca5190950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feca51284d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feaa9360a50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "# batch_size = [8, 16, 32, 64, 128]\n",
        "# Learning_rate = [0.01, 0.001, 0.0001]\n",
        "# epochs = [5, 10, 20]\n",
        "epoch = 20\n",
        "batch = 8\n",
        "lr = 0.001\n",
        "num_folds = 5\n",
        "inputs = np.concatenate((x_tr, x_val), axis=0)\n",
        "targets = np.concatenate((y_tr, y_val), axis=0)\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_paragraphs_len, ))\n",
        "\n",
        "# Embedding layer\n",
        "enc_emb = Embedding(x_voc, embedding_dim, trainable=True)(encoder_inputs)\n",
        "encoder_gru_1 = Bidirectional(GRU(latent_dim, return_sequences=True),                                                         \n",
        "                              merge_mode=\"concat\",\n",
        "                              name=\"primary_encoder\")(enc_emb)\n",
        "encoder_gru_2 = GRU(latent_dim, return_state=True, name='secondary_encoder')                               \n",
        "encoder_outputs, state = encoder_gru_2(encoder_gru_1)\n",
        "# Set up the decoder, using encoder_states as the initial state\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "# # Embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder = GRU(latent_dim, return_sequences=True, return_state=True, name='decoder')\n",
        "(decoder_outputs, decoder_state) =  decoder(dec_emb, initial_state=state)\n",
        "\n",
        "# Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "fold_no = 1\n",
        "for train, val in kfold.split(inputs, targets):\n",
        "  x_tr = inputs[train]\n",
        "  y_tr = targets[train]\n",
        "  x_val = inputs[val]\n",
        "  y_val = targets[val]\n",
        "\n",
        "  latent_dim = 100\n",
        "  embedding_dim = 300\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Compile Model\n",
        "  opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "  model.compile(optimizer=opt, loss='sparse_categorical_crossentropy')\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit([x_tr, y_tr[:, :-1]], y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:, 1:],\n",
        "              batch_size=batch,\n",
        "              epochs=epoch,\n",
        "              callbacks=[es],\n",
        "              validation_data=([x_val, y_val[:, :-1]], y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:, 1:]))\n",
        "  \n",
        "  # Inference Models\n",
        "  encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state])\n",
        "\n",
        "  # Below tensors will hold the states of the previous time step\n",
        "  decoder_state_input = Input(shape=(latent_dim, ))\n",
        "  decoder_hidden_state_input = Input(shape=(latent_dim, latent_dim))\n",
        "\n",
        "  # Get the embeddings of the decoder sequence\n",
        "  dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  # To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "  (decoder_outputs2, state2) = decoder(dec_emb2,\n",
        "          initial_state=decoder_state_input)\n",
        "\n",
        "  # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "  decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "  # Final decoder model\n",
        "  decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
        "                        decoder_state_input],\n",
        "                        [decoder_outputs2] + [state2])\n",
        "\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  rouge1 = 0\n",
        "  rouge2 = 0\n",
        "  rougel = 0\n",
        "  for i in range(0, 20):\n",
        "    original = seq2summary(y_val[i])\n",
        "    predict = decode_sequence(x_val[i].reshape(1, max_paragraphs_len))\n",
        "\n",
        "    rouge = Pythonrouge(summary_file_exist=False,\n",
        "                        summary=[[predict]], reference=[[[original]]],\n",
        "                        n_gram=2, ROUGE_SU4=False, ROUGE_L=True,\n",
        "                        recall_only=False, stemming=True, stopwords=True,\n",
        "                        word_level=True, length_limit=True, length=50,\n",
        "                        use_cf=False, cf=95, scoring_formula='average',\n",
        "                        resampling=True, samples=1000, favor=True, p=0.5)\n",
        "\n",
        "    score = rouge.calc_score()\n",
        "    rouge1 = rouge1 + score['ROUGE-1-R']\n",
        "    rouge2 = rouge2 + score['ROUGE-2-R']\n",
        "    rougel = rougel + score['ROUGE-L-R']\n",
        "\n",
        "  rogue1 = rouge1/20\n",
        "  rogue2 = rouge2/20\n",
        "  roguel = rougel/20\n",
        "  print(f'ROUGE 1 : {rogue1}, ROUGE 2 : {rogue2}, ROUGE L : {roguel}')\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# save model\n",
        "model.save(f'/content/drive/MyDrive/Dataset TA/my_model_{batch}_{lr}_{epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2qgiDDllgTi"
      },
      "source": [
        "# Epoch 20 Batch 16 Lr 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcpwKPLIl79J",
        "outputId": "fc3c8e71-15e5-48b3-afe6-5d5b63592f40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/20\n",
            "443/443 [==============================] - 48s 84ms/step - loss: 7.1786 - val_loss: 6.6919\n",
            "Epoch 2/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 6.3196 - val_loss: 6.0513\n",
            "Epoch 3/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 5.6981 - val_loss: 5.5450\n",
            "Epoch 4/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 5.1548 - val_loss: 5.0840\n",
            "Epoch 5/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 4.6588 - val_loss: 4.6701\n",
            "Epoch 6/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 4.2056 - val_loss: 4.3099\n",
            "Epoch 7/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 3.8007 - val_loss: 3.9746\n",
            "Epoch 8/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 3.4431 - val_loss: 3.6835\n",
            "Epoch 9/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 3.1369 - val_loss: 3.4346\n",
            "Epoch 10/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 2.8749 - val_loss: 3.2113\n",
            "Epoch 11/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 2.6482 - val_loss: 3.0180\n",
            "Epoch 12/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 2.4576 - val_loss: 2.8573\n",
            "Epoch 13/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 2.2923 - val_loss: 2.7106\n",
            "Epoch 14/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 2.1475 - val_loss: 2.5766\n",
            "Epoch 15/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 2.0194 - val_loss: 2.4619\n",
            "Epoch 16/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.9063 - val_loss: 2.3548\n",
            "Epoch 17/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.8040 - val_loss: 2.2601\n",
            "Epoch 18/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.7155 - val_loss: 2.1736\n",
            "Epoch 19/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.6395 - val_loss: 2.0991\n",
            "Epoch 20/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.5629 - val_loss: 2.0206\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_154'), name='input_154', description=\"created by layer 'input_154'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_154'), name='input_154', description=\"created by layer 'input_154'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.104568, ROUGE 2 : 0.005393500000000001, ROUGE L : 0.0708105\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/20\n",
            "443/443 [==============================] - 44s 84ms/step - loss: 1.6311 - val_loss: 1.5032\n",
            "Epoch 2/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.5274 - val_loss: 1.4743\n",
            "Epoch 3/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.4555 - val_loss: 1.4380\n",
            "Epoch 4/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.3891 - val_loss: 1.4117\n",
            "Epoch 5/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.3402 - val_loss: 1.3803\n",
            "Epoch 6/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.2879 - val_loss: 1.3473\n",
            "Epoch 7/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.2390 - val_loss: 1.3105\n",
            "Epoch 8/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.1963 - val_loss: 1.2821\n",
            "Epoch 9/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.1616 - val_loss: 1.2550\n",
            "Epoch 10/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.1171 - val_loss: 1.2254\n",
            "Epoch 11/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.0796 - val_loss: 1.1969\n",
            "Epoch 12/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.0472 - val_loss: 1.1737\n",
            "Epoch 13/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.0384 - val_loss: 1.1649\n",
            "Epoch 14/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 0.9916 - val_loss: 1.1197\n",
            "Epoch 15/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 0.9607 - val_loss: 1.1199\n",
            "Epoch 16/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 0.9407 - val_loss: 1.0785\n",
            "Epoch 17/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 0.9091 - val_loss: 1.0518\n",
            "Epoch 18/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 0.8828 - val_loss: 1.0360\n",
            "Epoch 19/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 0.8647 - val_loss: 1.0230\n",
            "Epoch 20/20\n",
            "443/443 [==============================] - 36s 80ms/step - loss: 0.8416 - val_loss: 1.0047\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_156'), name='input_156', description=\"created by layer 'input_156'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_156'), name='input_156', description=\"created by layer 'input_156'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.22668850000000001, ROUGE 2 : 0.1345905, ROUGE L : 0.20235550000000005\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/20\n",
            "443/443 [==============================] - 44s 84ms/step - loss: 0.8747 - val_loss: 0.7895\n",
            "Epoch 2/20\n",
            "443/443 [==============================] - 35s 80ms/step - loss: 0.8329 - val_loss: 0.7830\n",
            "Epoch 3/20\n",
            "443/443 [==============================] - 35s 80ms/step - loss: 0.8055 - val_loss: 0.7801\n",
            "Epoch 4/20\n",
            "443/443 [==============================] - 35s 80ms/step - loss: 0.7892 - val_loss: 0.7856\n",
            "Epoch 5/20\n",
            "443/443 [==============================] - 35s 80ms/step - loss: 0.7702 - val_loss: 0.7680\n",
            "Epoch 6/20\n",
            "443/443 [==============================] - 35s 80ms/step - loss: 0.7414 - val_loss: 0.7707\n",
            "Epoch 7/20\n",
            "443/443 [==============================] - 35s 80ms/step - loss: 0.7401 - val_loss: 0.7595\n",
            "Epoch 8/20\n",
            "443/443 [==============================] - 36s 80ms/step - loss: 0.7098 - val_loss: 0.7477\n",
            "Epoch 9/20\n",
            "443/443 [==============================] - 36s 80ms/step - loss: 0.6952 - val_loss: 0.7335\n",
            "Epoch 10/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 0.6798 - val_loss: 0.7365\n",
            "Epoch 11/20\n",
            "443/443 [==============================] - 36s 80ms/step - loss: 0.6681 - val_loss: 0.7271\n",
            "Epoch 12/20\n",
            "443/443 [==============================] - 36s 80ms/step - loss: 0.6554 - val_loss: 0.7208\n",
            "Epoch 13/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 0.6422 - val_loss: 0.7067\n",
            "Epoch 14/20\n",
            "443/443 [==============================] - 36s 80ms/step - loss: 0.6279 - val_loss: 0.6925\n",
            "Epoch 15/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 0.6024 - val_loss: 0.6661\n",
            "Epoch 16/20\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 0.5907 - val_loss: 0.6829\n",
            "Epoch 17/20\n",
            "443/443 [==============================] - 36s 80ms/step - loss: 0.6131 - val_loss: 0.7187\n",
            "Epoch 17: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_158'), name='input_158', description=\"created by layer 'input_158'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_158'), name='input_158', description=\"created by layer 'input_158'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.21232100000000004, ROUGE 2 : 0.11280850000000002, ROUGE L : 0.18106750000000002\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/20\n",
            "443/443 [==============================] - 44s 83ms/step - loss: 0.6122 - val_loss: 0.5599\n",
            "Epoch 2/20\n",
            "443/443 [==============================] - 35s 80ms/step - loss: 0.5824 - val_loss: 0.5728\n",
            "Epoch 3/20\n",
            "443/443 [==============================] - 35s 80ms/step - loss: 0.5713 - val_loss: 0.5748\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_160'), name='input_160', description=\"created by layer 'input_160'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_160'), name='input_160', description=\"created by layer 'input_160'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.187174, ROUGE 2 : 0.08099399999999998, ROUGE L : 0.15861600000000003\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/20\n",
            "443/443 [==============================] - 44s 84ms/step - loss: 0.5676 - val_loss: 0.5102\n",
            "Epoch 2/20\n",
            "443/443 [==============================] - 35s 80ms/step - loss: 0.5475 - val_loss: 0.5139\n",
            "Epoch 3/20\n",
            "443/443 [==============================] - 35s 79ms/step - loss: 0.5256 - val_loss: 0.5143\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_162'), name='input_162', description=\"created by layer 'input_162'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_162'), name='input_162', description=\"created by layer 'input_162'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.20729050000000004, ROUGE 2 : 0.08901800000000001, ROUGE L : 0.17542250000000004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_72_layer_call_fn, gru_cell_72_layer_call_and_return_conditional_losses, gru_cell_73_layer_call_fn, gru_cell_73_layer_call_and_return_conditional_losses, gru_cell_70_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_16_0.001_20/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_16_0.001_20/assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feaa4814e50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feaa8a9c110> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fea5f66dbd0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fea5f66d7d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from pythonrouge.pythonrouge import Pythonrouge\n",
        "# batch_size = [8, 16, 32, 64, 128]\n",
        "# Learning_rate = [0.01, 0.001, 0.0001]\n",
        "# epochs = [5, 10, 20]\n",
        "epoch = 20\n",
        "batch = 16\n",
        "lr = 0.001\n",
        "num_folds = 5\n",
        "inputs = np.concatenate((x_tr, x_val), axis=0)\n",
        "targets = np.concatenate((y_tr, y_val), axis=0)\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_paragraphs_len, ))\n",
        "\n",
        "# Embedding layer\n",
        "enc_emb = Embedding(x_voc, embedding_dim, trainable=True)(encoder_inputs)\n",
        "encoder_gru_1 = Bidirectional(GRU(latent_dim, return_sequences=True),                                                         \n",
        "                              merge_mode=\"concat\",\n",
        "                              name=\"primary_encoder\")(enc_emb)\n",
        "encoder_gru_2 = GRU(latent_dim, return_state=True, name='secondary_encoder')                               \n",
        "encoder_outputs, state = encoder_gru_2(encoder_gru_1)\n",
        "# Set up the decoder, using encoder_states as the initial state\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "# # Embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder = GRU(latent_dim, return_sequences=True, return_state=True, name='decoder')\n",
        "(decoder_outputs, decoder_state) =  decoder(dec_emb, initial_state=state)\n",
        "\n",
        "# Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "fold_no = 1\n",
        "for train, val in kfold.split(inputs, targets):\n",
        "  x_tr = inputs[train]\n",
        "  y_tr = targets[train]\n",
        "  x_val = inputs[val]\n",
        "  y_val = targets[val]\n",
        "\n",
        "  latent_dim = 100\n",
        "  embedding_dim = 300\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Compile Model\n",
        "  opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "  model.compile(optimizer=opt, loss='sparse_categorical_crossentropy')\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit([x_tr, y_tr[:, :-1]], y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:, 1:],\n",
        "              batch_size=batch,\n",
        "              epochs=epoch,\n",
        "              callbacks=[es],\n",
        "              validation_data=([x_val, y_val[:, :-1]], y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:, 1:]))\n",
        "  \n",
        "  # Inference Models\n",
        "  encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state])\n",
        "\n",
        "  # Below tensors will hold the states of the previous time step\n",
        "  decoder_state_input = Input(shape=(latent_dim, ))\n",
        "  decoder_hidden_state_input = Input(shape=(latent_dim, latent_dim))\n",
        "\n",
        "  # Get the embeddings of the decoder sequence\n",
        "  dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  # To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "  (decoder_outputs2, state2) = decoder(dec_emb2,\n",
        "          initial_state=decoder_state_input)\n",
        "\n",
        "  # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "  decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "  # Final decoder model\n",
        "  decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
        "                        decoder_state_input],\n",
        "                        [decoder_outputs2] + [state2])\n",
        "\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  rouge1 = 0\n",
        "  rouge2 = 0\n",
        "  rougel = 0\n",
        "  for i in range(0, 20):\n",
        "    original = seq2summary(y_val[i])\n",
        "    predict = decode_sequence(x_val[i].reshape(1, max_paragraphs_len))\n",
        "\n",
        "    rouge = Pythonrouge(summary_file_exist=False,\n",
        "                        summary=[[predict]], reference=[[[original]]],\n",
        "                        n_gram=2, ROUGE_SU4=False, ROUGE_L=True,\n",
        "                        recall_only=False, stemming=True, stopwords=True,\n",
        "                        word_level=True, length_limit=True, length=50,\n",
        "                        use_cf=False, cf=95, scoring_formula='average',\n",
        "                        resampling=True, samples=1000, favor=True, p=0.5)\n",
        "\n",
        "    score = rouge.calc_score()\n",
        "    rouge1 = rouge1 + score['ROUGE-1-R']\n",
        "    rouge2 = rouge2 + score['ROUGE-2-R']\n",
        "    rougel = rougel + score['ROUGE-L-R']\n",
        "\n",
        "  rogue1 = rouge1/20\n",
        "  rogue2 = rouge2/20\n",
        "  roguel = rougel/20\n",
        "  print(f'ROUGE 1 : {rogue1}, ROUGE 2 : {rogue2}, ROUGE L : {roguel}')\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# save model\n",
        "model.save(f'/content/drive/MyDrive/Dataset TA/my_model_{batch}_{lr}_{epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaZY0Dv8mL2v"
      },
      "source": [
        "# Epoch 10 Batch 16 Lr 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABqCql4smTML",
        "outputId": "7f05a9cf-7ddb-4dc8-fcc4-7aa658146f05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/10\n",
            "443/443 [==============================] - 44s 84ms/step - loss: 7.2221 - val_loss: 6.7445\n",
            "Epoch 2/10\n",
            "443/443 [==============================] - 35s 79ms/step - loss: 6.3919 - val_loss: 6.1225\n",
            "Epoch 3/10\n",
            "443/443 [==============================] - 35s 79ms/step - loss: 5.8028 - val_loss: 5.6204\n",
            "Epoch 4/10\n",
            "443/443 [==============================] - 35s 79ms/step - loss: 5.2591 - val_loss: 5.1461\n",
            "Epoch 5/10\n",
            "443/443 [==============================] - 35s 79ms/step - loss: 4.7439 - val_loss: 4.7163\n",
            "Epoch 6/10\n",
            "443/443 [==============================] - 35s 79ms/step - loss: 4.2738 - val_loss: 4.3302\n",
            "Epoch 7/10\n",
            "443/443 [==============================] - 35s 79ms/step - loss: 3.8539 - val_loss: 3.9871\n",
            "Epoch 8/10\n",
            "443/443 [==============================] - 35s 79ms/step - loss: 3.4863 - val_loss: 3.6891\n",
            "Epoch 9/10\n",
            "443/443 [==============================] - 35s 79ms/step - loss: 3.1697 - val_loss: 3.4167\n",
            "Epoch 10/10\n",
            "443/443 [==============================] - 35s 80ms/step - loss: 2.9006 - val_loss: 3.1923\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_166'), name='input_166', description=\"created by layer 'input_166'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_166'), name='input_166', description=\"created by layer 'input_166'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.1069805, ROUGE 2 : 0.0071860000000000005, ROUGE L : 0.07353950000000002\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/10\n",
            "443/443 [==============================] - 44s 83ms/step - loss: 2.8702 - val_loss: 2.6781\n",
            "Epoch 2/10\n",
            "443/443 [==============================] - 35s 80ms/step - loss: 2.5899 - val_loss: 2.5283\n",
            "Epoch 3/10\n",
            "443/443 [==============================] - 35s 79ms/step - loss: 2.3880 - val_loss: 2.4040\n",
            "Epoch 4/10\n",
            "443/443 [==============================] - 35s 79ms/step - loss: 2.2231 - val_loss: 2.2926\n",
            "Epoch 5/10\n",
            "443/443 [==============================] - 35s 80ms/step - loss: 2.0818 - val_loss: 2.1937\n",
            "Epoch 6/10\n",
            "443/443 [==============================] - 35s 80ms/step - loss: 1.9585 - val_loss: 2.1006\n",
            "Epoch 7/10\n",
            "443/443 [==============================] - 35s 80ms/step - loss: 1.8492 - val_loss: 2.0128\n",
            "Epoch 8/10\n",
            "443/443 [==============================] - 35s 80ms/step - loss: 1.7509 - val_loss: 1.9383\n",
            "Epoch 9/10\n",
            "443/443 [==============================] - 35s 80ms/step - loss: 1.6644 - val_loss: 1.8692\n",
            "Epoch 10/10\n",
            "443/443 [==============================] - 35s 80ms/step - loss: 1.5857 - val_loss: 1.8086\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_168'), name='input_168', description=\"created by layer 'input_168'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_168'), name='input_168', description=\"created by layer 'input_168'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.11149000000000002, ROUGE 2 : 0.010377, ROUGE L : 0.076185\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/10\n",
            "443/443 [==============================] - 44s 84ms/step - loss: 1.6035 - val_loss: 1.5001\n",
            "Epoch 2/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.4996 - val_loss: 1.4696\n",
            "Epoch 3/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.4291 - val_loss: 1.4332\n",
            "Epoch 4/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.3706 - val_loss: 1.4083\n",
            "Epoch 5/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.3165 - val_loss: 1.3746\n",
            "Epoch 6/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.2631 - val_loss: 1.3457\n",
            "Epoch 7/10\n",
            "443/443 [==============================] - 36s 80ms/step - loss: 1.2154 - val_loss: 1.3115\n",
            "Epoch 8/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.1743 - val_loss: 1.2836\n",
            "Epoch 9/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.1357 - val_loss: 1.2551\n",
            "Epoch 10/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.0936 - val_loss: 1.2250\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_170'), name='input_170', description=\"created by layer 'input_170'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_170'), name='input_170', description=\"created by layer 'input_170'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.11301350000000003, ROUGE 2 : 0.010270999999999999, ROUGE L : 0.08631800000000002\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/10\n",
            "443/443 [==============================] - 44s 84ms/step - loss: 1.1131 - val_loss: 1.0217\n",
            "Epoch 2/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.0578 - val_loss: 1.0298\n",
            "Epoch 3/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.0191 - val_loss: 1.0208\n",
            "Epoch 4/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 0.9908 - val_loss: 1.0150\n",
            "Epoch 5/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 0.9551 - val_loss: 0.9914\n",
            "Epoch 6/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 0.9160 - val_loss: 0.9709\n",
            "Epoch 7/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 0.8984 - val_loss: 0.9850\n",
            "Epoch 8/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 0.8778 - val_loss: 0.9564\n",
            "Epoch 9/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 0.8441 - val_loss: 0.9407\n",
            "Epoch 10/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 0.8251 - val_loss: 0.9205\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_172'), name='input_172', description=\"created by layer 'input_172'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_172'), name='input_172', description=\"created by layer 'input_172'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.1780875, ROUGE 2 : 0.068408, ROUGE L : 0.14052800000000004\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/10\n",
            "443/443 [==============================] - 44s 85ms/step - loss: 0.8399 - val_loss: 0.7684\n",
            "Epoch 2/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 0.8074 - val_loss: 0.8177\n",
            "Epoch 3/10\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 0.7885 - val_loss: 0.7715\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_174'), name='input_174', description=\"created by layer 'input_174'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_174'), name='input_174', description=\"created by layer 'input_174'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.227305, ROUGE 2 : 0.126999, ROUGE L : 0.19901050000000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_77_layer_call_fn, gru_cell_77_layer_call_and_return_conditional_losses, gru_cell_78_layer_call_fn, gru_cell_78_layer_call_and_return_conditional_losses, gru_cell_75_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_16_0.001_10/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_16_0.001_10/assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fea38270ed0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feaa9386a50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fea37ad4d10> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feca4c95890> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "# batch_size = [8, 16, 32, 64, 128]\n",
        "# Learning_rate = [0.01, 0.001, 0.0001]\n",
        "# epochs = [5, 10, 20]\n",
        "epoch = 10\n",
        "batch = 16\n",
        "lr = 0.001\n",
        "num_folds = 5\n",
        "inputs = np.concatenate((x_tr, x_val), axis=0)\n",
        "targets = np.concatenate((y_tr, y_val), axis=0)\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_paragraphs_len, ))\n",
        "\n",
        "# Embedding layer\n",
        "enc_emb = Embedding(x_voc, embedding_dim, trainable=True)(encoder_inputs)\n",
        "encoder_gru_1 = Bidirectional(GRU(latent_dim, return_sequences=True),                                                         \n",
        "                              merge_mode=\"concat\",\n",
        "                              name=\"primary_encoder\")(enc_emb)\n",
        "encoder_gru_2 = GRU(latent_dim, return_state=True, name='secondary_encoder')                               \n",
        "encoder_outputs, state = encoder_gru_2(encoder_gru_1)\n",
        "# Set up the decoder, using encoder_states as the initial state\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "# # Embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder = GRU(latent_dim, return_sequences=True, return_state=True, name='decoder')\n",
        "(decoder_outputs, decoder_state) =  decoder(dec_emb, initial_state=state)\n",
        "\n",
        "# Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "fold_no = 1\n",
        "for train, val in kfold.split(inputs, targets):\n",
        "  x_tr = inputs[train]\n",
        "  y_tr = targets[train]\n",
        "  x_val = inputs[val]\n",
        "  y_val = targets[val]\n",
        "\n",
        "  latent_dim = 100\n",
        "  embedding_dim = 300\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Compile Model\n",
        "  opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "  model.compile(optimizer=opt, loss='sparse_categorical_crossentropy')\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit([x_tr, y_tr[:, :-1]], y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:, 1:],\n",
        "              batch_size=batch,\n",
        "              epochs=epoch,\n",
        "              callbacks=[es],\n",
        "              validation_data=([x_val, y_val[:, :-1]], y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:, 1:]))\n",
        "  \n",
        "  # Inference Models\n",
        "  encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state])\n",
        "\n",
        "  # Below tensors will hold the states of the previous time step\n",
        "  decoder_state_input = Input(shape=(latent_dim, ))\n",
        "  decoder_hidden_state_input = Input(shape=(latent_dim, latent_dim))\n",
        "\n",
        "  # Get the embeddings of the decoder sequence\n",
        "  dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  # To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "  (decoder_outputs2, state2) = decoder(dec_emb2,\n",
        "          initial_state=decoder_state_input)\n",
        "\n",
        "  # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "  decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "  # Final decoder model\n",
        "  decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
        "                        decoder_state_input],\n",
        "                        [decoder_outputs2] + [state2])\n",
        "\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  rouge1 = 0\n",
        "  rouge2 = 0\n",
        "  rougel = 0\n",
        "  for i in range(0, 20):\n",
        "    original = seq2summary(y_val[i])\n",
        "    predict = decode_sequence(x_val[i].reshape(1, max_paragraphs_len))\n",
        "\n",
        "    rouge = Pythonrouge(summary_file_exist=False,\n",
        "                        summary=[[predict]], reference=[[[original]]],\n",
        "                        n_gram=2, ROUGE_SU4=False, ROUGE_L=True,\n",
        "                        recall_only=False, stemming=True, stopwords=True,\n",
        "                        word_level=True, length_limit=True, length=50,\n",
        "                        use_cf=False, cf=95, scoring_formula='average',\n",
        "                        resampling=True, samples=1000, favor=True, p=0.5)\n",
        "\n",
        "    score = rouge.calc_score()\n",
        "    rouge1 = rouge1 + score['ROUGE-1-R']\n",
        "    rouge2 = rouge2 + score['ROUGE-2-R']\n",
        "    rougel = rougel + score['ROUGE-L-R']\n",
        "\n",
        "  rogue1 = rouge1/20\n",
        "  rogue2 = rouge2/20\n",
        "  roguel = rougel/20\n",
        "  print(f'ROUGE 1 : {rogue1}, ROUGE 2 : {rogue2}, ROUGE L : {roguel}')\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# save model\n",
        "model.save(f'/content/drive/MyDrive/Dataset TA/my_model_{batch}_{lr}_{epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asstIjnPmgO9"
      },
      "source": [
        "# Epoch 5 Batch 16 Lr 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMoVkJoUml7h",
        "outputId": "3f741018-872b-4467-f6bc-612bce7a5c95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/5\n",
            "443/443 [==============================] - 44s 84ms/step - loss: 7.2008 - val_loss: 6.7025\n",
            "Epoch 2/5\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 6.3961 - val_loss: 6.1196\n",
            "Epoch 3/5\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 5.7965 - val_loss: 5.6118\n",
            "Epoch 4/5\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 5.2632 - val_loss: 5.1572\n",
            "Epoch 5/5\n",
            "443/443 [==============================] - 36s 80ms/step - loss: 4.7654 - val_loss: 4.7468\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_178'), name='input_178', description=\"created by layer 'input_178'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_178'), name='input_178', description=\"created by layer 'input_178'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.11088500000000001, ROUGE 2 : 0.0073455000000000005, ROUGE L : 0.09159049999999999\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/5\n",
            "443/443 [==============================] - 44s 84ms/step - loss: 4.5146 - val_loss: 4.3281\n",
            "Epoch 2/5\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 4.0536 - val_loss: 3.9995\n",
            "Epoch 3/5\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 3.6552 - val_loss: 3.7024\n",
            "Epoch 4/5\n",
            "443/443 [==============================] - 35s 80ms/step - loss: 3.3101 - val_loss: 3.4324\n",
            "Epoch 5/5\n",
            "443/443 [==============================] - 35s 80ms/step - loss: 3.0161 - val_loss: 3.2002\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_180'), name='input_180', description=\"created by layer 'input_180'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_180'), name='input_180', description=\"created by layer 'input_180'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.10194, ROUGE 2 : 0.0044295, ROUGE L : 0.07149900000000001\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/5\n",
            "443/443 [==============================] - 50s 84ms/step - loss: 2.9559 - val_loss: 2.7374\n",
            "Epoch 2/5\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 2.6615 - val_loss: 2.5727\n",
            "Epoch 3/5\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 2.4449 - val_loss: 2.4302\n",
            "Epoch 4/5\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 2.2688 - val_loss: 2.3014\n",
            "Epoch 5/5\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 2.1136 - val_loss: 2.1893\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_182'), name='input_182', description=\"created by layer 'input_182'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_182'), name='input_182', description=\"created by layer 'input_182'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.10791100000000002, ROUGE 2 : 0.0041245, ROUGE L : 0.075062\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/5\n",
            "443/443 [==============================] - 44s 84ms/step - loss: 2.0780 - val_loss: 1.9318\n",
            "Epoch 2/5\n",
            "443/443 [==============================] - 36s 80ms/step - loss: 1.9049 - val_loss: 1.8621\n",
            "Epoch 3/5\n",
            "443/443 [==============================] - 35s 80ms/step - loss: 1.7817 - val_loss: 1.7965\n",
            "Epoch 4/5\n",
            "443/443 [==============================] - 36s 80ms/step - loss: 1.6780 - val_loss: 1.7263\n",
            "Epoch 5/5\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.5839 - val_loss: 1.6658\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_184'), name='input_184', description=\"created by layer 'input_184'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_184'), name='input_184', description=\"created by layer 'input_184'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.093672, ROUGE 2 : 0.0041695, ROUGE L : 0.062208500000000014\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/5\n",
            "443/443 [==============================] - 45s 83ms/step - loss: 1.5717 - val_loss: 1.4596\n",
            "Epoch 2/5\n",
            "443/443 [==============================] - 35s 80ms/step - loss: 1.4598 - val_loss: 1.4298\n",
            "Epoch 3/5\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.3838 - val_loss: 1.3955\n",
            "Epoch 4/5\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.3171 - val_loss: 1.3541\n",
            "Epoch 5/5\n",
            "443/443 [==============================] - 36s 81ms/step - loss: 1.2596 - val_loss: 1.3260\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_186'), name='input_186', description=\"created by layer 'input_186'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_186'), name='input_186', description=\"created by layer 'input_186'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.1311595, ROUGE 2 : 0.012501500000000002, ROUGE L : 0.0907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_82_layer_call_fn, gru_cell_82_layer_call_and_return_conditional_losses, gru_cell_83_layer_call_fn, gru_cell_83_layer_call_and_return_conditional_losses, gru_cell_80_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_16_0.001_5/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_16_0.001_5/assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feaa48c9290> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feca5244b50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feca49bfc90> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feca4219a90> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "# batch_size = [8, 16, 32, 64, 128]\n",
        "# Learning_rate = [0.01, 0.001, 0.0001]\n",
        "# epochs = [5, 10, 20]\n",
        "epoch = 5\n",
        "batch = 16\n",
        "lr = 0.001\n",
        "num_folds = 5\n",
        "inputs = np.concatenate((x_tr, x_val), axis=0)\n",
        "targets = np.concatenate((y_tr, y_val), axis=0)\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_paragraphs_len, ))\n",
        "\n",
        "# Embedding layer\n",
        "enc_emb = Embedding(x_voc, embedding_dim, trainable=True)(encoder_inputs)\n",
        "encoder_gru_1 = Bidirectional(GRU(latent_dim, return_sequences=True),                                                         \n",
        "                              merge_mode=\"concat\",\n",
        "                              name=\"primary_encoder\")(enc_emb)\n",
        "encoder_gru_2 = GRU(latent_dim, return_state=True, name='secondary_encoder')                               \n",
        "encoder_outputs, state = encoder_gru_2(encoder_gru_1)\n",
        "# Set up the decoder, using encoder_states as the initial state\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "# # Embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder = GRU(latent_dim, return_sequences=True, return_state=True, name='decoder')\n",
        "(decoder_outputs, decoder_state) =  decoder(dec_emb, initial_state=state)\n",
        "\n",
        "# Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "fold_no = 1\n",
        "for train, val in kfold.split(inputs, targets):\n",
        "  x_tr = inputs[train]\n",
        "  y_tr = targets[train]\n",
        "  x_val = inputs[val]\n",
        "  y_val = targets[val]\n",
        "\n",
        "  latent_dim = 100\n",
        "  embedding_dim = 300\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Compile Model\n",
        "  opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "  model.compile(optimizer=opt, loss='sparse_categorical_crossentropy')\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit([x_tr, y_tr[:, :-1]], y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:, 1:],\n",
        "              batch_size=batch,\n",
        "              epochs=epoch,\n",
        "              callbacks=[es],\n",
        "              validation_data=([x_val, y_val[:, :-1]], y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:, 1:]))\n",
        "  \n",
        "  # Inference Models\n",
        "  encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state])\n",
        "\n",
        "  # Below tensors will hold the states of the previous time step\n",
        "  decoder_state_input = Input(shape=(latent_dim, ))\n",
        "  decoder_hidden_state_input = Input(shape=(latent_dim, latent_dim))\n",
        "\n",
        "  # Get the embeddings of the decoder sequence\n",
        "  dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  # To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "  (decoder_outputs2, state2) = decoder(dec_emb2,\n",
        "          initial_state=decoder_state_input)\n",
        "\n",
        "  # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "  decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "  # Final decoder model\n",
        "  decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
        "                        decoder_state_input],\n",
        "                        [decoder_outputs2] + [state2])\n",
        "\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  rouge1 = 0\n",
        "  rouge2 = 0\n",
        "  rougel = 0\n",
        "  for i in range(0, 20):\n",
        "    original = seq2summary(y_val[i])\n",
        "    predict = decode_sequence(x_val[i].reshape(1, max_paragraphs_len))\n",
        "\n",
        "    rouge = Pythonrouge(summary_file_exist=False,\n",
        "                        summary=[[predict]], reference=[[[original]]],\n",
        "                        n_gram=2, ROUGE_SU4=False, ROUGE_L=True,\n",
        "                        recall_only=False, stemming=True, stopwords=True,\n",
        "                        word_level=True, length_limit=True, length=50,\n",
        "                        use_cf=False, cf=95, scoring_formula='average',\n",
        "                        resampling=True, samples=1000, favor=True, p=0.5)\n",
        "\n",
        "    score = rouge.calc_score()\n",
        "    rouge1 = rouge1 + score['ROUGE-1-R']\n",
        "    rouge2 = rouge2 + score['ROUGE-2-R']\n",
        "    rougel = rougel + score['ROUGE-L-R']\n",
        "\n",
        "  rogue1 = rouge1/20\n",
        "  rogue2 = rouge2/20\n",
        "  roguel = rougel/20\n",
        "  print(f'ROUGE 1 : {rogue1}, ROUGE 2 : {rogue2}, ROUGE L : {roguel}')\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# save model\n",
        "model.save(f'/content/drive/MyDrive/Dataset TA/my_model_{batch}_{lr}_{epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlhnBmpenHfP"
      },
      "source": [
        "# Epoch 5 Batch 32 Lr 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8gRPL8CnNn4",
        "outputId": "b5522ab1-3075-4c3b-dda9-4400ba601f09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/5\n",
            "222/222 [==============================] - 30s 103ms/step - loss: 7.5267 - val_loss: 7.0127\n",
            "Epoch 2/5\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 6.8092 - val_loss: 6.6584\n",
            "Epoch 3/5\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 6.4587 - val_loss: 6.3167\n",
            "Epoch 4/5\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 6.0956 - val_loss: 5.9817\n",
            "Epoch 5/5\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 5.7374 - val_loss: 5.6516\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_190'), name='input_190', description=\"created by layer 'input_190'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_190'), name='input_190', description=\"created by layer 'input_190'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.07643600000000003, ROUGE 2 : 0.005301999999999999, ROUGE L : 0.06615950000000001\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/5\n",
            "222/222 [==============================] - 30s 103ms/step - loss: 5.4774 - val_loss: 5.2950\n",
            "Epoch 2/5\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 5.0829 - val_loss: 4.9952\n",
            "Epoch 3/5\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 4.7187 - val_loss: 4.6929\n",
            "Epoch 4/5\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 4.3740 - val_loss: 4.4187\n",
            "Epoch 5/5\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 4.0526 - val_loss: 4.1606\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_192'), name='input_192', description=\"created by layer 'input_192'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_192'), name='input_192', description=\"created by layer 'input_192'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.11498250000000002, ROUGE 2 : 0.0052115, ROUGE L : 0.0840425\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/5\n",
            "222/222 [==============================] - 30s 101ms/step - loss: 3.9147 - val_loss: 3.7595\n",
            "Epoch 2/5\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 3.6090 - val_loss: 3.5640\n",
            "Epoch 3/5\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 3.3492 - val_loss: 3.3800\n",
            "Epoch 4/5\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 3.1204 - val_loss: 3.2145\n",
            "Epoch 5/5\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 2.9159 - val_loss: 3.0601\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_194'), name='input_194', description=\"created by layer 'input_194'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_194'), name='input_194', description=\"created by layer 'input_194'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.090502, ROUGE 2 : 0.0020410000000000003, ROUGE L : 0.06816549999999999\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/5\n",
            "222/222 [==============================] - 30s 102ms/step - loss: 2.8637 - val_loss: 2.6966\n",
            "Epoch 2/5\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 2.6528 - val_loss: 2.5857\n",
            "Epoch 3/5\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 2.4898 - val_loss: 2.4865\n",
            "Epoch 4/5\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 2.3493 - val_loss: 2.3852\n",
            "Epoch 5/5\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 2.2228 - val_loss: 2.3004\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_196'), name='input_196', description=\"created by layer 'input_196'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_196'), name='input_196', description=\"created by layer 'input_196'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.0821625, ROUGE 2 : 0.0032185, ROUGE L : 0.0626595\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/5\n",
            "222/222 [==============================] - 30s 104ms/step - loss: 2.1894 - val_loss: 2.0613\n",
            "Epoch 2/5\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 2.0482 - val_loss: 2.0047\n",
            "Epoch 3/5\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.9409 - val_loss: 1.9567\n",
            "Epoch 4/5\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.8503 - val_loss: 1.9077\n",
            "Epoch 5/5\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.7686 - val_loss: 1.8524\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_198'), name='input_198', description=\"created by layer 'input_198'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_198'), name='input_198', description=\"created by layer 'input_198'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.1047645, ROUGE 2 : 0.0086835, ROUGE L : 0.0750135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_87_layer_call_fn, gru_cell_87_layer_call_and_return_conditional_losses, gru_cell_88_layer_call_fn, gru_cell_88_layer_call_and_return_conditional_losses, gru_cell_85_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_32_0.001_5/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_32_0.001_5/assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fea36603b10> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feaa83e5190> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feaa47b2690> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feaa911f6d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "# batch_size = [8, 16, 32, 64, 128]\n",
        "# Learning_rate = [0.01, 0.001, 0.0001]\n",
        "# epochs = [5, 10, 20]\n",
        "epoch = 5\n",
        "batch = 32\n",
        "lr = 0.001\n",
        "num_folds = 5\n",
        "inputs = np.concatenate((x_tr, x_val), axis=0)\n",
        "targets = np.concatenate((y_tr, y_val), axis=0)\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_paragraphs_len, ))\n",
        "\n",
        "# Embedding layer\n",
        "enc_emb = Embedding(x_voc, embedding_dim, trainable=True)(encoder_inputs)\n",
        "encoder_gru_1 = Bidirectional(GRU(latent_dim, return_sequences=True),                                                         \n",
        "                              merge_mode=\"concat\",\n",
        "                              name=\"primary_encoder\")(enc_emb)\n",
        "encoder_gru_2 = GRU(latent_dim, return_state=True, name='secondary_encoder')                               \n",
        "encoder_outputs, state = encoder_gru_2(encoder_gru_1)\n",
        "# Set up the decoder, using encoder_states as the initial state\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "# # Embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder = GRU(latent_dim, return_sequences=True, return_state=True, name='decoder')\n",
        "(decoder_outputs, decoder_state) =  decoder(dec_emb, initial_state=state)\n",
        "\n",
        "# Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "fold_no = 1\n",
        "for train, val in kfold.split(inputs, targets):\n",
        "  x_tr = inputs[train]\n",
        "  y_tr = targets[train]\n",
        "  x_val = inputs[val]\n",
        "  y_val = targets[val]\n",
        "\n",
        "  latent_dim = 100\n",
        "  embedding_dim = 300\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Compile Model\n",
        "  opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "  model.compile(optimizer=opt, loss='sparse_categorical_crossentropy')\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit([x_tr, y_tr[:, :-1]], y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:, 1:],\n",
        "              batch_size=batch,\n",
        "              epochs=epoch,\n",
        "              callbacks=[es],\n",
        "              validation_data=([x_val, y_val[:, :-1]], y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:, 1:]))\n",
        "  \n",
        "  # Inference Models\n",
        "  encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state])\n",
        "\n",
        "  # Below tensors will hold the states of the previous time step\n",
        "  decoder_state_input = Input(shape=(latent_dim, ))\n",
        "  decoder_hidden_state_input = Input(shape=(latent_dim, latent_dim))\n",
        "\n",
        "  # Get the embeddings of the decoder sequence\n",
        "  dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  # To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "  (decoder_outputs2, state2) = decoder(dec_emb2,\n",
        "          initial_state=decoder_state_input)\n",
        "\n",
        "  # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "  decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "  # Final decoder model\n",
        "  decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
        "                        decoder_state_input],\n",
        "                        [decoder_outputs2] + [state2])\n",
        "\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  rouge1 = 0\n",
        "  rouge2 = 0\n",
        "  rougel = 0\n",
        "  for i in range(0, 20):\n",
        "    original = seq2summary(y_val[i])\n",
        "    predict = decode_sequence(x_val[i].reshape(1, max_paragraphs_len))\n",
        "\n",
        "    rouge = Pythonrouge(summary_file_exist=False,\n",
        "                        summary=[[predict]], reference=[[[original]]],\n",
        "                        n_gram=2, ROUGE_SU4=False, ROUGE_L=True,\n",
        "                        recall_only=False, stemming=True, stopwords=True,\n",
        "                        word_level=True, length_limit=True, length=50,\n",
        "                        use_cf=False, cf=95, scoring_formula='average',\n",
        "                        resampling=True, samples=1000, favor=True, p=0.5)\n",
        "\n",
        "    score = rouge.calc_score()\n",
        "    rouge1 = rouge1 + score['ROUGE-1-R']\n",
        "    rouge2 = rouge2 + score['ROUGE-2-R']\n",
        "    rougel = rougel + score['ROUGE-L-R']\n",
        "\n",
        "  rogue1 = rouge1/20\n",
        "  rogue2 = rouge2/20\n",
        "  roguel = rougel/20\n",
        "  print(f'ROUGE 1 : {rogue1}, ROUGE 2 : {rogue2}, ROUGE L : {roguel}')\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# save model\n",
        "model.save(f'/content/drive/MyDrive/Dataset TA/my_model_{batch}_{lr}_{epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj1rfjECnZse"
      },
      "source": [
        "# Epoch 10 Batch 32 Lr 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12Gj7BoSnd4Z",
        "outputId": "fddbf1ff-4cff-4928-b32e-6cd595fff17b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/10\n",
            "222/222 [==============================] - 30s 104ms/step - loss: 7.5369 - val_loss: 7.0218\n",
            "Epoch 2/10\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 6.8437 - val_loss: 6.6763\n",
            "Epoch 3/10\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 6.4847 - val_loss: 6.3184\n",
            "Epoch 4/10\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 6.0956 - val_loss: 5.9594\n",
            "Epoch 5/10\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 5.7111 - val_loss: 5.6207\n",
            "Epoch 6/10\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 5.3380 - val_loss: 5.3015\n",
            "Epoch 7/10\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 4.9838 - val_loss: 5.0016\n",
            "Epoch 8/10\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 4.6409 - val_loss: 4.7117\n",
            "Epoch 9/10\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 4.3163 - val_loss: 4.4438\n",
            "Epoch 10/10\n",
            "222/222 [==============================] - 21s 94ms/step - loss: 4.0208 - val_loss: 4.2059\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_202'), name='input_202', description=\"created by layer 'input_202'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_202'), name='input_202', description=\"created by layer 'input_202'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.107212, ROUGE 2 : 0.005355, ROUGE L : 0.08027400000000001\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/10\n",
            "222/222 [==============================] - 30s 103ms/step - loss: 3.9218 - val_loss: 3.7332\n",
            "Epoch 2/10\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 3.6351 - val_loss: 3.5522\n",
            "Epoch 3/10\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 3.3949 - val_loss: 3.3857\n",
            "Epoch 4/10\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 3.1861 - val_loss: 3.2289\n",
            "Epoch 5/10\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 2.9992 - val_loss: 3.0897\n",
            "Epoch 6/10\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 2.8378 - val_loss: 2.9707\n",
            "Epoch 7/10\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 2.6905 - val_loss: 2.8506\n",
            "Epoch 8/10\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 2.5652 - val_loss: 2.7496\n",
            "Epoch 9/10\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 2.4459 - val_loss: 2.6522\n",
            "Epoch 10/10\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 2.3374 - val_loss: 2.5727\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_204'), name='input_204', description=\"created by layer 'input_204'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_204'), name='input_204', description=\"created by layer 'input_204'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.1233945, ROUGE 2 : 0.0084755, ROUGE L : 0.08431999999999999\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/10\n",
            "222/222 [==============================] - 30s 103ms/step - loss: 2.3447 - val_loss: 2.2094\n",
            "Epoch 2/10\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 2.2086 - val_loss: 2.1600\n",
            "Epoch 3/10\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 2.1106 - val_loss: 2.1052\n",
            "Epoch 4/10\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 2.0295 - val_loss: 2.0555\n",
            "Epoch 5/10\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.9554 - val_loss: 2.0048\n",
            "Epoch 6/10\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.8864 - val_loss: 1.9655\n",
            "Epoch 7/10\n",
            "222/222 [==============================] - 22s 97ms/step - loss: 1.8254 - val_loss: 1.9228\n",
            "Epoch 8/10\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.7675 - val_loss: 1.8792\n",
            "Epoch 9/10\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.7105 - val_loss: 1.8434\n",
            "Epoch 10/10\n",
            "222/222 [==============================] - 22s 97ms/step - loss: 1.6609 - val_loss: 1.8040\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_206'), name='input_206', description=\"created by layer 'input_206'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_206'), name='input_206', description=\"created by layer 'input_206'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.096815, ROUGE 2 : 0.0020410000000000003, ROUGE L : 0.069317\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/10\n",
            "222/222 [==============================] - 30s 104ms/step - loss: 1.6740 - val_loss: 1.5678\n",
            "Epoch 2/10\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.6032 - val_loss: 1.5494\n",
            "Epoch 3/10\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.5560 - val_loss: 1.5306\n",
            "Epoch 4/10\n",
            "222/222 [==============================] - 22s 97ms/step - loss: 1.5129 - val_loss: 1.5159\n",
            "Epoch 5/10\n",
            "222/222 [==============================] - 22s 97ms/step - loss: 1.4922 - val_loss: 1.5081\n",
            "Epoch 6/10\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.4393 - val_loss: 1.4684\n",
            "Epoch 7/10\n",
            "222/222 [==============================] - 22s 97ms/step - loss: 1.3911 - val_loss: 1.4420\n",
            "Epoch 8/10\n",
            "222/222 [==============================] - 22s 97ms/step - loss: 1.3595 - val_loss: 1.4258\n",
            "Epoch 9/10\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.3347 - val_loss: 1.4031\n",
            "Epoch 10/10\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.3028 - val_loss: 1.3852\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_208'), name='input_208', description=\"created by layer 'input_208'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_208'), name='input_208', description=\"created by layer 'input_208'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.12200600000000002, ROUGE 2 : 0.0082695, ROUGE L : 0.08029550000000002\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/10\n",
            "222/222 [==============================] - 30s 104ms/step - loss: 1.3204 - val_loss: 1.2154\n",
            "Epoch 2/10\n",
            "222/222 [==============================] - 22s 97ms/step - loss: 1.2686 - val_loss: 1.2131\n",
            "Epoch 3/10\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.2447 - val_loss: 1.2130\n",
            "Epoch 4/10\n",
            "222/222 [==============================] - 22s 97ms/step - loss: 1.2229 - val_loss: 1.2070\n",
            "Epoch 5/10\n",
            "222/222 [==============================] - 22s 97ms/step - loss: 1.1836 - val_loss: 1.1901\n",
            "Epoch 6/10\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.1549 - val_loss: 1.1820\n",
            "Epoch 7/10\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 1.1346 - val_loss: 1.1709\n",
            "Epoch 8/10\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.1226 - val_loss: 1.1898\n",
            "Epoch 9/10\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.1158 - val_loss: 1.1598\n",
            "Epoch 10/10\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.0790 - val_loss: 1.1415\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_210'), name='input_210', description=\"created by layer 'input_210'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_210'), name='input_210', description=\"created by layer 'input_210'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.10071850000000002, ROUGE 2 : 0.0042585, ROUGE L : 0.07234300000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_92_layer_call_fn, gru_cell_92_layer_call_and_return_conditional_losses, gru_cell_93_layer_call_fn, gru_cell_93_layer_call_and_return_conditional_losses, gru_cell_90_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_32_0.001_10/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_32_0.001_10/assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fea5eaf6c50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fea3a1bead0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feaaa570c90> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feaa7d7d890> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "# batch_size = [8, 16, 32, 64, 128]\n",
        "# Learning_rate = [0.01, 0.001, 0.0001]\n",
        "# epochs = [5, 10, 20]\n",
        "epoch = 10\n",
        "batch = 32\n",
        "lr = 0.001\n",
        "num_folds = 5\n",
        "inputs = np.concatenate((x_tr, x_val), axis=0)\n",
        "targets = np.concatenate((y_tr, y_val), axis=0)\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_paragraphs_len, ))\n",
        "\n",
        "# Embedding layer\n",
        "enc_emb = Embedding(x_voc, embedding_dim, trainable=True)(encoder_inputs)\n",
        "encoder_gru_1 = Bidirectional(GRU(latent_dim, return_sequences=True),                                                         \n",
        "                              merge_mode=\"concat\",\n",
        "                              name=\"primary_encoder\")(enc_emb)\n",
        "encoder_gru_2 = GRU(latent_dim, return_state=True, name='secondary_encoder')                               \n",
        "encoder_outputs, state = encoder_gru_2(encoder_gru_1)\n",
        "# Set up the decoder, using encoder_states as the initial state\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "# # Embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder = GRU(latent_dim, return_sequences=True, return_state=True, name='decoder')\n",
        "(decoder_outputs, decoder_state) =  decoder(dec_emb, initial_state=state)\n",
        "\n",
        "# Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "fold_no = 1\n",
        "for train, val in kfold.split(inputs, targets):\n",
        "  x_tr = inputs[train]\n",
        "  y_tr = targets[train]\n",
        "  x_val = inputs[val]\n",
        "  y_val = targets[val]\n",
        "\n",
        "  latent_dim = 100\n",
        "  embedding_dim = 300\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Compile Model\n",
        "  opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "  model.compile(optimizer=opt, loss='sparse_categorical_crossentropy')\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit([x_tr, y_tr[:, :-1]], y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:, 1:],\n",
        "              batch_size=batch,\n",
        "              epochs=epoch,\n",
        "              callbacks=[es],\n",
        "              validation_data=([x_val, y_val[:, :-1]], y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:, 1:]))\n",
        "  \n",
        "  # Inference Models\n",
        "  encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state])\n",
        "\n",
        "  # Below tensors will hold the states of the previous time step\n",
        "  decoder_state_input = Input(shape=(latent_dim, ))\n",
        "  decoder_hidden_state_input = Input(shape=(latent_dim, latent_dim))\n",
        "\n",
        "  # Get the embeddings of the decoder sequence\n",
        "  dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  # To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "  (decoder_outputs2, state2) = decoder(dec_emb2,\n",
        "          initial_state=decoder_state_input)\n",
        "\n",
        "  # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "  decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "  # Final decoder model\n",
        "  decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
        "                        decoder_state_input],\n",
        "                        [decoder_outputs2] + [state2])\n",
        "\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  rouge1 = 0\n",
        "  rouge2 = 0\n",
        "  rougel = 0\n",
        "  for i in range(0, 20):\n",
        "    original = seq2summary(y_val[i])\n",
        "    predict = decode_sequence(x_val[i].reshape(1, max_paragraphs_len))\n",
        "\n",
        "    rouge = Pythonrouge(summary_file_exist=False,\n",
        "                        summary=[[predict]], reference=[[[original]]],\n",
        "                        n_gram=2, ROUGE_SU4=False, ROUGE_L=True,\n",
        "                        recall_only=False, stemming=True, stopwords=True,\n",
        "                        word_level=True, length_limit=True, length=50,\n",
        "                        use_cf=False, cf=95, scoring_formula='average',\n",
        "                        resampling=True, samples=1000, favor=True, p=0.5)\n",
        "\n",
        "    score = rouge.calc_score()\n",
        "    rouge1 = rouge1 + score['ROUGE-1-R']\n",
        "    rouge2 = rouge2 + score['ROUGE-2-R']\n",
        "    rougel = rougel + score['ROUGE-L-R']\n",
        "\n",
        "  rogue1 = rouge1/20\n",
        "  rogue2 = rouge2/20\n",
        "  roguel = rougel/20\n",
        "  print(f'ROUGE 1 : {rogue1}, ROUGE 2 : {rogue2}, ROUGE L : {roguel}')\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# save model\n",
        "model.save(f'/content/drive/MyDrive/Dataset TA/my_model_{batch}_{lr}_{epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9UiHQg3nmyA"
      },
      "source": [
        "# Epoch 20 Batch 32 Lr 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SY2DJwM4nsCn",
        "outputId": "2fcf94da-23fa-462e-ec1b-c0d23a34e1c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/20\n",
            "222/222 [==============================] - 30s 105ms/step - loss: 7.4816 - val_loss: 6.9843\n",
            "Epoch 2/20\n",
            "222/222 [==============================] - 22s 98ms/step - loss: 6.7646 - val_loss: 6.5916\n",
            "Epoch 3/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 6.3287 - val_loss: 6.1731\n",
            "Epoch 4/20\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 5.8917 - val_loss: 5.7841\n",
            "Epoch 5/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 5.4824 - val_loss: 5.4306\n",
            "Epoch 6/20\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 5.1028 - val_loss: 5.1069\n",
            "Epoch 7/20\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 4.7464 - val_loss: 4.8104\n",
            "Epoch 8/20\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 4.4122 - val_loss: 4.5321\n",
            "Epoch 9/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 4.1035 - val_loss: 4.2780\n",
            "Epoch 10/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 3.8202 - val_loss: 4.0414\n",
            "Epoch 11/20\n",
            "222/222 [==============================] - 22s 97ms/step - loss: 3.5612 - val_loss: 3.8254\n",
            "Epoch 12/20\n",
            "222/222 [==============================] - 22s 98ms/step - loss: 3.3340 - val_loss: 3.6387\n",
            "Epoch 13/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 3.1349 - val_loss: 3.4634\n",
            "Epoch 14/20\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 2.9576 - val_loss: 3.3149\n",
            "Epoch 15/20\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 2.8017 - val_loss: 3.1765\n",
            "Epoch 16/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 2.6607 - val_loss: 3.0494\n",
            "Epoch 17/20\n",
            "222/222 [==============================] - 21s 97ms/step - loss: 2.5359 - val_loss: 2.9422\n",
            "Epoch 18/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 2.4275 - val_loss: 2.8374\n",
            "Epoch 19/20\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 2.3293 - val_loss: 2.7444\n",
            "Epoch 20/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 2.2370 - val_loss: 2.6668\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_214'), name='input_214', description=\"created by layer 'input_214'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_214'), name='input_214', description=\"created by layer 'input_214'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.10205299999999999, ROUGE 2 : 0.0031035, ROUGE L : 0.069078\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/20\n",
            "222/222 [==============================] - 30s 102ms/step - loss: 2.2906 - val_loss: 2.1517\n",
            "Epoch 2/20\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 2.1625 - val_loss: 2.1023\n",
            "Epoch 3/20\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 2.0758 - val_loss: 2.0630\n",
            "Epoch 4/20\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 2.0018 - val_loss: 2.0246\n",
            "Epoch 5/20\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 1.9362 - val_loss: 1.9874\n",
            "Epoch 6/20\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 1.8730 - val_loss: 1.9460\n",
            "Epoch 7/20\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 1.8152 - val_loss: 1.9128\n",
            "Epoch 8/20\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 1.7683 - val_loss: 1.8836\n",
            "Epoch 9/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.7245 - val_loss: 1.8436\n",
            "Epoch 10/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.6741 - val_loss: 1.8187\n",
            "Epoch 11/20\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 1.6315 - val_loss: 1.7823\n",
            "Epoch 12/20\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 1.5933 - val_loss: 1.7566\n",
            "Epoch 13/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.5544 - val_loss: 1.7300\n",
            "Epoch 14/20\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 1.5198 - val_loss: 1.6969\n",
            "Epoch 15/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.4808 - val_loss: 1.6724\n",
            "Epoch 16/20\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 1.4566 - val_loss: 1.6612\n",
            "Epoch 17/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.4325 - val_loss: 1.6376\n",
            "Epoch 18/20\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 1.4036 - val_loss: 1.6094\n",
            "Epoch 19/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.3740 - val_loss: 1.5933\n",
            "Epoch 20/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.3480 - val_loss: 1.5718\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_216'), name='input_216', description=\"created by layer 'input_216'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_216'), name='input_216', description=\"created by layer 'input_216'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.098069, ROUGE 2 : 0.0041675, ROUGE L : 0.07639399999999999\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/20\n",
            "222/222 [==============================] - 30s 103ms/step - loss: 1.3895 - val_loss: 1.2893\n",
            "Epoch 2/20\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 1.3289 - val_loss: 1.2915\n",
            "Epoch 3/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.2975 - val_loss: 1.2861\n",
            "Epoch 4/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.2818 - val_loss: 1.2858\n",
            "Epoch 5/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.2450 - val_loss: 1.2716\n",
            "Epoch 6/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.2393 - val_loss: 1.2795\n",
            "Epoch 7/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.2076 - val_loss: 1.2580\n",
            "Epoch 8/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.1837 - val_loss: 1.2412\n",
            "Epoch 9/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.1534 - val_loss: 1.2278\n",
            "Epoch 10/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.1383 - val_loss: 1.2291\n",
            "Epoch 11/20\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 1.1306 - val_loss: 1.2164\n",
            "Epoch 12/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.0986 - val_loss: 1.2017\n",
            "Epoch 13/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.0813 - val_loss: 1.2071\n",
            "Epoch 14/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.0820 - val_loss: 1.1954\n",
            "Epoch 15/20\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 1.0637 - val_loss: 1.1916\n",
            "Epoch 16/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.0398 - val_loss: 1.1588\n",
            "Epoch 17/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 1.0133 - val_loss: 1.1572\n",
            "Epoch 18/20\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 1.0206 - val_loss: 1.1718\n",
            "Epoch 19/20\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 1.0091 - val_loss: 1.1488\n",
            "Epoch 20/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 0.9804 - val_loss: 1.1325\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_218'), name='input_218', description=\"created by layer 'input_218'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_218'), name='input_218', description=\"created by layer 'input_218'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.1159595, ROUGE 2 : 0.022534500000000002, ROUGE L : 0.09273400000000001\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/20\n",
            "222/222 [==============================] - 30s 103ms/step - loss: 1.0145 - val_loss: 0.9441\n",
            "Epoch 2/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 0.9819 - val_loss: 0.9604\n",
            "Epoch 3/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 0.9643 - val_loss: 0.9427\n",
            "Epoch 4/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 0.9529 - val_loss: 0.9567\n",
            "Epoch 5/20\n",
            "222/222 [==============================] - 21s 96ms/step - loss: 0.9382 - val_loss: 0.9509\n",
            "Epoch 5: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_220'), name='input_220', description=\"created by layer 'input_220'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_220'), name='input_220', description=\"created by layer 'input_220'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.15613450000000004, ROUGE 2 : 0.060578, ROUGE L : 0.13370450000000003\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/20\n",
            "222/222 [==============================] - 30s 103ms/step - loss: 0.9440 - val_loss: 0.8594\n",
            "Epoch 2/20\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 0.9168 - val_loss: 0.8706\n",
            "Epoch 3/20\n",
            "222/222 [==============================] - 21s 95ms/step - loss: 0.9054 - val_loss: 0.8797\n",
            "Epoch 3: early stopping\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_222'), name='input_222', description=\"created by layer 'input_222'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_222'), name='input_222', description=\"created by layer 'input_222'\"), but it was called on an input with incompatible shape (None, 100).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1 : 0.13247000000000003, ROUGE 2 : 0.040291, ROUGE L : 0.11134500000000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_97_layer_call_fn, gru_cell_97_layer_call_and_return_conditional_losses, gru_cell_98_layer_call_fn, gru_cell_98_layer_call_and_return_conditional_losses, gru_cell_95_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_32_0.001_20/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_32_0.001_20/assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fea3719b850> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feaa5bbeb50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7feaa90b0e10> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fec9cea8510> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "# batch_size = [8, 16, 32, 64, 128]\n",
        "# Learning_rate = [0.01, 0.001, 0.0001]\n",
        "# epochs = [5, 10, 20]\n",
        "epoch = 20\n",
        "batch = 32\n",
        "lr = 0.001\n",
        "num_folds = 5\n",
        "inputs = np.concatenate((x_tr, x_val), axis=0)\n",
        "targets = np.concatenate((y_tr, y_val), axis=0)\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_paragraphs_len, ))\n",
        "\n",
        "# Embedding layer\n",
        "enc_emb = Embedding(x_voc, embedding_dim, trainable=True)(encoder_inputs)\n",
        "encoder_gru_1 = Bidirectional(GRU(latent_dim, return_sequences=True),                                                         \n",
        "                              merge_mode=\"concat\",\n",
        "                              name=\"primary_encoder\")(enc_emb)\n",
        "encoder_gru_2 = GRU(latent_dim, return_state=True, name='secondary_encoder')                               \n",
        "encoder_outputs, state = encoder_gru_2(encoder_gru_1)\n",
        "# Set up the decoder, using encoder_states as the initial state\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "# # Embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder = GRU(latent_dim, return_sequences=True, return_state=True, name='decoder')\n",
        "(decoder_outputs, decoder_state) =  decoder(dec_emb, initial_state=state)\n",
        "\n",
        "# Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "fold_no = 1\n",
        "for train, val in kfold.split(inputs, targets):\n",
        "  x_tr = inputs[train]\n",
        "  y_tr = targets[train]\n",
        "  x_val = inputs[val]\n",
        "  y_val = targets[val]\n",
        "\n",
        "  latent_dim = 100\n",
        "  embedding_dim = 300\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Compile Model\n",
        "  opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "  model.compile(optimizer=opt, loss='sparse_categorical_crossentropy')\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit([x_tr, y_tr[:, :-1]], y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:, 1:],\n",
        "              batch_size=batch,\n",
        "              epochs=epoch,\n",
        "              callbacks=[es],\n",
        "              validation_data=([x_val, y_val[:, :-1]], y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:, 1:]))\n",
        "  \n",
        "  # Inference Models\n",
        "  encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state])\n",
        "\n",
        "  # Below tensors will hold the states of the previous time step\n",
        "  decoder_state_input = Input(shape=(latent_dim, ))\n",
        "  decoder_hidden_state_input = Input(shape=(latent_dim, latent_dim))\n",
        "\n",
        "  # Get the embeddings of the decoder sequence\n",
        "  dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  # To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "  (decoder_outputs2, state2) = decoder(dec_emb2,\n",
        "          initial_state=decoder_state_input)\n",
        "\n",
        "  # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "  decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "  # Final decoder model\n",
        "  decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
        "                        decoder_state_input],\n",
        "                        [decoder_outputs2] + [state2])\n",
        "\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  rouge1 = 0\n",
        "  rouge2 = 0\n",
        "  rougel = 0\n",
        "  for i in range(0, 20):\n",
        "    original = seq2summary(y_val[i])\n",
        "    predict = decode_sequence(x_val[i].reshape(1, max_paragraphs_len))\n",
        "\n",
        "    rouge = Pythonrouge(summary_file_exist=False,\n",
        "                        summary=[[predict]], reference=[[[original]]],\n",
        "                        n_gram=2, ROUGE_SU4=False, ROUGE_L=True,\n",
        "                        recall_only=False, stemming=True, stopwords=True,\n",
        "                        word_level=True, length_limit=True, length=50,\n",
        "                        use_cf=False, cf=95, scoring_formula='average',\n",
        "                        resampling=True, samples=1000, favor=True, p=0.5)\n",
        "\n",
        "    score = rouge.calc_score()\n",
        "    rouge1 = rouge1 + score['ROUGE-1-R']\n",
        "    rouge2 = rouge2 + score['ROUGE-2-R']\n",
        "    rougel = rougel + score['ROUGE-L-R']\n",
        "\n",
        "  rogue1 = rouge1/20\n",
        "  rogue2 = rouge2/20\n",
        "  roguel = rougel/20\n",
        "  print(f'ROUGE 1 : {rogue1}, ROUGE 2 : {rogue2}, ROUGE L : {roguel}')\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# save model\n",
        "model.save(f'/content/drive/MyDrive/Dataset TA/my_model_{batch}_{lr}_{epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBf-EoZBzq4C"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FeKECgAmlnG"
      },
      "outputs": [],
      "source": [
        "# from tensorflow import keras\n",
        "# model = keras.models.load_model('/content/drive/MyDrive/Dataset TA/my_model_16_0.001_20')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k91E5QAs-HxK"
      },
      "outputs": [],
      "source": [
        "from pythonrouge.pythonrouge import Pythonrouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9889
        },
        "id": "BX4GPEqGzFNO",
        "outputId": "b73c0b8d-38ed-4dd6-fa23-f60da9b22f77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (None, 100).\n",
            "ROUGE 1 : 0.3387776666666667, ROUGE 2 : 0.23951766666666666, ROUGE L : 0.30773766666666663\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c777b62f-3f11-4f3f-bfe0-340c64eac9d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paragraphs</th>\n",
              "      <th>summary</th>\n",
              "      <th>predict_summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>harus diakui smartphone dengan bezel tipis dan...</td>\n",
              "      <td>gionee pabrikan ponsel asal tiongkok telah men...</td>\n",
              "      <td>gionee pabrikan ponsel asal tiongkok telah me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jakarta antara news perkembangan cara menikmat...</td>\n",
              "      <td>pada peluncuran paket internet music unlimited...</td>\n",
              "      <td>pada senin 11 12 grab dan garuda indonesia re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>misi facebook mengkudeta snapchat terbilang be...</td>\n",
              "      <td>facebook creator dirancang untuk membantu para...</td>\n",
              "      <td>facebook creator dirancang untuk membantu pen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jakarta cnn indonesia selain memperkenalkan sk...</td>\n",
              "      <td>pihak suzuki indonesia memboyong generasi terb...</td>\n",
              "      <td>oculus belum lama ini memperkenalkan perangka...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>samsung meluncurkan galaxy note fan edition al...</td>\n",
              "      <td>daya tarik samsung galaxy note fan edition tam...</td>\n",
              "      <td>daya tarik samsung galaxy note fan edition di...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ada banyak kamera pengawas yang bisa kita guna...</td>\n",
              "      <td>sebuah solusi inovatif ditawarkan oleh tim aev...</td>\n",
              "      <td>sebuah solusi inovatif ditawarkan oleh tim ae...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>dalam gelaran advertising week di new york cit...</td>\n",
              "      <td>youtube meluncurkan fitur iklan baru yang pert...</td>\n",
              "      <td>youtube meluncurkan fitur iklan baru yang per...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>paypro adalah pengusung layanan dompet virtual...</td>\n",
              "      <td>paypro adalah pengusung layanan dompet virtual...</td>\n",
              "      <td>paypro adalah pengusung layanan dompet virtua...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>kedua kaki kita adalah pilar penting penunjang...</td>\n",
              "      <td>footbeat merupakan perangkat yang memadukan te...</td>\n",
              "      <td>footbeat merupakan perangkat yang memadukan t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>jojonomic secara resmi telah mengumumkan kehad...</td>\n",
              "      <td>jojonomic secara resmi telah mengumumkan kehad...</td>\n",
              "      <td>jojonomic secara resmi telah mengumumkan keha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>popularitas snapchat jelas berada dalam ancama...</td>\n",
              "      <td>untuk mengembalikan penggunanya yang berpaling...</td>\n",
              "      <td>untuk mengembalikan penggunanya yang berpalin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>jaybird boleh memelopori kategori sport earpho...</td>\n",
              "      <td>jaybird run mengadopsi premis desain yang sama...</td>\n",
              "      <td>jaybird run mengadopsi premis desain yang leb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>bukan rahasai lagi bahwa selain menjual smartp...</td>\n",
              "      <td>xiaomi rupanya baru saja meluncurkan penjernih...</td>\n",
              "      <td>xiaomi baru saja meluncurkan penjernih udara ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>di era 90 an ketika compact disc menjadi mediu...</td>\n",
              "      <td>lima orang developer independen legendaris men...</td>\n",
              "      <td>lima orang developer independen legendaris me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>setelah menggelar proses bookbuilding lebih da...</td>\n",
              "      <td>setelah menggelar proses bookbuilding lebih da...</td>\n",
              "      <td>setelah menggelar proses bookbuilding lebih d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>ada banyak game yang seharusnya tidak kita mai...</td>\n",
              "      <td>indie pixel dash studios punya jawaban atas ri...</td>\n",
              "      <td>indie pixel dash studios punya jawaban atas r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>facebook messenger dan paypal sebelumnya sudah...</td>\n",
              "      <td>facebook messenger dan paypal sebelumnya sudah...</td>\n",
              "      <td>facebook messenger dan tablet yang sangat pra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>grup bisnis telkom berencana mencabut blokir k...</td>\n",
              "      <td>grup bisnis telkom berencana mencabut blokir k...</td>\n",
              "      <td>grup bisnis telkom berencana mencabut blokir ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>mei tahun lalu google mulai memasarkan jamboar...</td>\n",
              "      <td>mei tahun lalu google mulai memasarkan jamboar...</td>\n",
              "      <td>mei tahun lalu browser edge pada tanggal 10 s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>mesin hybrid elektrik teknologi selfdriving se...</td>\n",
              "      <td>audi ag membuktikan bahwa mobil driverless seb...</td>\n",
              "      <td>audi ag membuktikan bahwa mobil driverless se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>tahun lalu hp meluncurkan sebuah printer porta...</td>\n",
              "      <td>tahun lalu hp meluncurkan sebuah printer porta...</td>\n",
              "      <td>setelah menjadi tiga produk baru bernama  so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>indonesia saat ini tercatat sebagai negara den...</td>\n",
              "      <td>indonesia saat ini tercatat sebagai negara den...</td>\n",
              "      <td>samsung secara resmi memperkenalkan versi bar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>google bakal mengungkap generasi kedua lini sm...</td>\n",
              "      <td>google rupanya ingin mencuri perhatian terlebi...</td>\n",
              "      <td>google menguji sebuah aplikasi baru bernama b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>industri startup di tanah air mulai berkembang...</td>\n",
              "      <td>petarumah menyebut diri sebagai agensi modern ...</td>\n",
              "      <td>petarumah menyebut diri sebagai agensi modern...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>kementerian energi dan sumber daya mineral esd...</td>\n",
              "      <td>menurut presdir pt astra prijono sugiarto mobi...</td>\n",
              "      <td>menurut presdir pt astra prijono sugiarto mob...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>cakra cipta kreasi indonesia adalah asosiasi y...</td>\n",
              "      <td>cakra cipta kreasi indonesia adalah asosiasi y...</td>\n",
              "      <td>cakra cipta kreasi indonesia adalah asosiasi ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>instagram kemungkinan besar bakal mempunyai  ...</td>\n",
              "      <td>instagram kemungkinan besar bakal mempunyai  ...</td>\n",
              "      <td>instagram bisa melakukan pembaruan agar pengg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>jaket adalah salah satu jenis pakaian tertua m...</td>\n",
              "      <td>perusahaan afloader memperkenalkan bulletproof...</td>\n",
              "      <td>perusahaan afloader memperkenalkan bulletproo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>spesifikasi usb yang ada sekarang sudah ibarat...</td>\n",
              "      <td>silicon power baru saja memperkenalkan usb fla...</td>\n",
              "      <td>silicon power baru saja memperkenalkan usb fl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>suaracom salah satu ciri khas twiiter adalah t...</td>\n",
              "      <td>tidak sedikit pengguna twitter yang mengingink...</td>\n",
              "      <td>gboard untuk android atau ios namun terdapat ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c777b62f-3f11-4f3f-bfe0-340c64eac9d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c777b62f-3f11-4f3f-bfe0-340c64eac9d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c777b62f-3f11-4f3f-bfe0-340c64eac9d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                           paragraphs  \\\n",
              "0   harus diakui smartphone dengan bezel tipis dan...   \n",
              "1   jakarta antara news perkembangan cara menikmat...   \n",
              "2   misi facebook mengkudeta snapchat terbilang be...   \n",
              "3   jakarta cnn indonesia selain memperkenalkan sk...   \n",
              "4   samsung meluncurkan galaxy note fan edition al...   \n",
              "5   ada banyak kamera pengawas yang bisa kita guna...   \n",
              "6   dalam gelaran advertising week di new york cit...   \n",
              "7   paypro adalah pengusung layanan dompet virtual...   \n",
              "8   kedua kaki kita adalah pilar penting penunjang...   \n",
              "9   jojonomic secara resmi telah mengumumkan kehad...   \n",
              "10  popularitas snapchat jelas berada dalam ancama...   \n",
              "11  jaybird boleh memelopori kategori sport earpho...   \n",
              "12  bukan rahasai lagi bahwa selain menjual smartp...   \n",
              "13  di era 90 an ketika compact disc menjadi mediu...   \n",
              "14  setelah menggelar proses bookbuilding lebih da...   \n",
              "15  ada banyak game yang seharusnya tidak kita mai...   \n",
              "16  facebook messenger dan paypal sebelumnya sudah...   \n",
              "17  grup bisnis telkom berencana mencabut blokir k...   \n",
              "18  mei tahun lalu google mulai memasarkan jamboar...   \n",
              "19  mesin hybrid elektrik teknologi selfdriving se...   \n",
              "20  tahun lalu hp meluncurkan sebuah printer porta...   \n",
              "21  indonesia saat ini tercatat sebagai negara den...   \n",
              "22  google bakal mengungkap generasi kedua lini sm...   \n",
              "23  industri startup di tanah air mulai berkembang...   \n",
              "24  kementerian energi dan sumber daya mineral esd...   \n",
              "25  cakra cipta kreasi indonesia adalah asosiasi y...   \n",
              "26  instagram kemungkinan besar bakal mempunyai  ...   \n",
              "27  jaket adalah salah satu jenis pakaian tertua m...   \n",
              "28  spesifikasi usb yang ada sekarang sudah ibarat...   \n",
              "29  suaracom salah satu ciri khas twiiter adalah t...   \n",
              "\n",
              "                                              summary  \\\n",
              "0   gionee pabrikan ponsel asal tiongkok telah men...   \n",
              "1   pada peluncuran paket internet music unlimited...   \n",
              "2   facebook creator dirancang untuk membantu para...   \n",
              "3   pihak suzuki indonesia memboyong generasi terb...   \n",
              "4   daya tarik samsung galaxy note fan edition tam...   \n",
              "5   sebuah solusi inovatif ditawarkan oleh tim aev...   \n",
              "6   youtube meluncurkan fitur iklan baru yang pert...   \n",
              "7   paypro adalah pengusung layanan dompet virtual...   \n",
              "8   footbeat merupakan perangkat yang memadukan te...   \n",
              "9   jojonomic secara resmi telah mengumumkan kehad...   \n",
              "10  untuk mengembalikan penggunanya yang berpaling...   \n",
              "11  jaybird run mengadopsi premis desain yang sama...   \n",
              "12  xiaomi rupanya baru saja meluncurkan penjernih...   \n",
              "13  lima orang developer independen legendaris men...   \n",
              "14  setelah menggelar proses bookbuilding lebih da...   \n",
              "15  indie pixel dash studios punya jawaban atas ri...   \n",
              "16  facebook messenger dan paypal sebelumnya sudah...   \n",
              "17  grup bisnis telkom berencana mencabut blokir k...   \n",
              "18  mei tahun lalu google mulai memasarkan jamboar...   \n",
              "19  audi ag membuktikan bahwa mobil driverless seb...   \n",
              "20  tahun lalu hp meluncurkan sebuah printer porta...   \n",
              "21  indonesia saat ini tercatat sebagai negara den...   \n",
              "22  google rupanya ingin mencuri perhatian terlebi...   \n",
              "23  petarumah menyebut diri sebagai agensi modern ...   \n",
              "24  menurut presdir pt astra prijono sugiarto mobi...   \n",
              "25  cakra cipta kreasi indonesia adalah asosiasi y...   \n",
              "26  instagram kemungkinan besar bakal mempunyai  ...   \n",
              "27  perusahaan afloader memperkenalkan bulletproof...   \n",
              "28  silicon power baru saja memperkenalkan usb fla...   \n",
              "29  tidak sedikit pengguna twitter yang mengingink...   \n",
              "\n",
              "                                      predict_summary  \n",
              "0    gionee pabrikan ponsel asal tiongkok telah me...  \n",
              "1    pada senin 11 12 grab dan garuda indonesia re...  \n",
              "2    facebook creator dirancang untuk membantu pen...  \n",
              "3    oculus belum lama ini memperkenalkan perangka...  \n",
              "4    daya tarik samsung galaxy note fan edition di...  \n",
              "5    sebuah solusi inovatif ditawarkan oleh tim ae...  \n",
              "6    youtube meluncurkan fitur iklan baru yang per...  \n",
              "7    paypro adalah pengusung layanan dompet virtua...  \n",
              "8    footbeat merupakan perangkat yang memadukan t...  \n",
              "9    jojonomic secara resmi telah mengumumkan keha...  \n",
              "10   untuk mengembalikan penggunanya yang berpalin...  \n",
              "11   jaybird run mengadopsi premis desain yang leb...  \n",
              "12   xiaomi baru saja meluncurkan penjernih udara ...  \n",
              "13   lima orang developer independen legendaris me...  \n",
              "14   setelah menggelar proses bookbuilding lebih d...  \n",
              "15   indie pixel dash studios punya jawaban atas r...  \n",
              "16   facebook messenger dan tablet yang sangat pra...  \n",
              "17   grup bisnis telkom berencana mencabut blokir ...  \n",
              "18   mei tahun lalu browser edge pada tanggal 10 s...  \n",
              "19   audi ag membuktikan bahwa mobil driverless se...  \n",
              "20   setelah menjadi tiga produk baru bernama  so...  \n",
              "21   samsung secara resmi memperkenalkan versi bar...  \n",
              "22   google menguji sebuah aplikasi baru bernama b...  \n",
              "23   petarumah menyebut diri sebagai agensi modern...  \n",
              "24   menurut presdir pt astra prijono sugiarto mob...  \n",
              "25   cakra cipta kreasi indonesia adalah asosiasi ...  \n",
              "26   instagram bisa melakukan pembaruan agar pengg...  \n",
              "27   perusahaan afloader memperkenalkan bulletproo...  \n",
              "28   silicon power baru saja memperkenalkan usb fl...  \n",
              "29   gboard untuk android atau ios namun terdapat ...  "
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "paragraphs_df = []\n",
        "summary_df = []\n",
        "predict_df = []\n",
        "rouge1 = 0\n",
        "rouge2 = 0\n",
        "rougel = 0\n",
        "for i in range(0, 30):\n",
        "  review = seq2text(x_test[i])\n",
        "  original = seq2summary(y_test[i])\n",
        "  predict = decode_sequence(x_test[i].reshape(1, max_paragraphs_len))\n",
        "  paragraphs_df.append(review)\n",
        "  summary_df.append(original)\n",
        "  predict_df.append(predict)\n",
        "\n",
        "  rouge = Pythonrouge(summary_file_exist=False,\n",
        "                    summary=[[predict]], reference=[[[original]]],\n",
        "                    n_gram=2, ROUGE_SU4=False, ROUGE_L=True,\n",
        "                    recall_only=False, stemming=True, stopwords=True,\n",
        "                    word_level=True, length_limit=True, length=50,\n",
        "                    use_cf=False, cf=95, scoring_formula='average',\n",
        "                    resampling=True, samples=1000, favor=True, p=0.5)\n",
        "\n",
        "  score = rouge.calc_score()\n",
        "  rouge1 = rouge1 + score['ROUGE-1-R']\n",
        "  rouge2 = rouge2 + score['ROUGE-2-R']\n",
        "  rougel = rougel + score['ROUGE-L-R']\n",
        "\n",
        "rogue1 = rouge1/30\n",
        "rogue2 = rouge2/30\n",
        "roguel = rougel/30\n",
        "\n",
        "print(f'ROUGE 1 : {rogue1}, ROUGE 2 : {rogue2}, ROUGE L : {roguel}')\n",
        "        \n",
        "post_df = pd.DataFrame({'paragraphs': paragraphs_df,'summary': summary_df, 'predict_summary': predict_df})\n",
        "post_df.to_csv(path_or_buf='/content/drive/MyDrive/Dataset TA/predict.csv')\n",
        "post_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LcUpIL8-R9uU",
        "outputId": "0a8e1fe4-a3ae-41e1-fdcd-d3bb6360d0aa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-34073c50-3e75-41c5-8821-1679ceb28eac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paragraphs</th>\n",
              "      <th>summary</th>\n",
              "      <th>predict_summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>harus diakui smartphone dengan bezel tipis dan...</td>\n",
              "      <td>gionee pabrikan ponsel asal tiongkok telah men...</td>\n",
              "      <td>gionee pabrikan ponsel asal tiongkok telah me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jakarta antara news perkembangan cara menikmat...</td>\n",
              "      <td>pada peluncuran paket internet music unlimited...</td>\n",
              "      <td>pada senin 11 12 grab dan garuda indonesia re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>misi facebook mengkudeta snapchat terbilang be...</td>\n",
              "      <td>facebook creator dirancang untuk membantu para...</td>\n",
              "      <td>facebook creator dirancang untuk membantu pen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jakarta cnn indonesia selain memperkenalkan sk...</td>\n",
              "      <td>pihak suzuki indonesia memboyong generasi terb...</td>\n",
              "      <td>oculus belum lama ini memperkenalkan perangka...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>samsung meluncurkan galaxy note fan edition al...</td>\n",
              "      <td>daya tarik samsung galaxy note fan edition tam...</td>\n",
              "      <td>daya tarik samsung galaxy note fan edition di...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ada banyak kamera pengawas yang bisa kita guna...</td>\n",
              "      <td>sebuah solusi inovatif ditawarkan oleh tim aev...</td>\n",
              "      <td>sebuah solusi inovatif ditawarkan oleh tim ae...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>dalam gelaran advertising week di new york cit...</td>\n",
              "      <td>youtube meluncurkan fitur iklan baru yang pert...</td>\n",
              "      <td>youtube meluncurkan fitur iklan baru yang per...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>paypro adalah pengusung layanan dompet virtual...</td>\n",
              "      <td>paypro adalah pengusung layanan dompet virtual...</td>\n",
              "      <td>paypro adalah pengusung layanan dompet virtua...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>kedua kaki kita adalah pilar penting penunjang...</td>\n",
              "      <td>footbeat merupakan perangkat yang memadukan te...</td>\n",
              "      <td>footbeat merupakan perangkat yang memadukan t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>jojonomic secara resmi telah mengumumkan kehad...</td>\n",
              "      <td>jojonomic secara resmi telah mengumumkan kehad...</td>\n",
              "      <td>jojonomic secara resmi telah mengumumkan keha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>popularitas snapchat jelas berada dalam ancama...</td>\n",
              "      <td>untuk mengembalikan penggunanya yang berpaling...</td>\n",
              "      <td>untuk mengembalikan penggunanya yang berpalin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>jaybird boleh memelopori kategori sport earpho...</td>\n",
              "      <td>jaybird run mengadopsi premis desain yang sama...</td>\n",
              "      <td>jaybird run mengadopsi premis desain yang leb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>bukan rahasai lagi bahwa selain menjual smartp...</td>\n",
              "      <td>xiaomi rupanya baru saja meluncurkan penjernih...</td>\n",
              "      <td>xiaomi baru saja meluncurkan penjernih udara ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>di era 90 an ketika compact disc menjadi mediu...</td>\n",
              "      <td>lima orang developer independen legendaris men...</td>\n",
              "      <td>lima orang developer independen legendaris me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>setelah menggelar proses bookbuilding lebih da...</td>\n",
              "      <td>setelah menggelar proses bookbuilding lebih da...</td>\n",
              "      <td>setelah menggelar proses bookbuilding lebih d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>ada banyak game yang seharusnya tidak kita mai...</td>\n",
              "      <td>indie pixel dash studios punya jawaban atas ri...</td>\n",
              "      <td>indie pixel dash studios punya jawaban atas r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>facebook messenger dan paypal sebelumnya sudah...</td>\n",
              "      <td>facebook messenger dan paypal sebelumnya sudah...</td>\n",
              "      <td>facebook messenger dan tablet yang sangat pra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>grup bisnis telkom berencana mencabut blokir k...</td>\n",
              "      <td>grup bisnis telkom berencana mencabut blokir k...</td>\n",
              "      <td>grup bisnis telkom berencana mencabut blokir ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>mei tahun lalu google mulai memasarkan jamboar...</td>\n",
              "      <td>mei tahun lalu google mulai memasarkan jamboar...</td>\n",
              "      <td>mei tahun lalu browser edge pada tanggal 10 s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>mesin hybrid elektrik teknologi selfdriving se...</td>\n",
              "      <td>audi ag membuktikan bahwa mobil driverless seb...</td>\n",
              "      <td>audi ag membuktikan bahwa mobil driverless se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>tahun lalu hp meluncurkan sebuah printer porta...</td>\n",
              "      <td>tahun lalu hp meluncurkan sebuah printer porta...</td>\n",
              "      <td>setelah menjadi tiga produk baru bernama  so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>indonesia saat ini tercatat sebagai negara den...</td>\n",
              "      <td>indonesia saat ini tercatat sebagai negara den...</td>\n",
              "      <td>samsung secara resmi memperkenalkan versi bar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>google bakal mengungkap generasi kedua lini sm...</td>\n",
              "      <td>google rupanya ingin mencuri perhatian terlebi...</td>\n",
              "      <td>google menguji sebuah aplikasi baru bernama b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>industri startup di tanah air mulai berkembang...</td>\n",
              "      <td>petarumah menyebut diri sebagai agensi modern ...</td>\n",
              "      <td>petarumah menyebut diri sebagai agensi modern...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>kementerian energi dan sumber daya mineral esd...</td>\n",
              "      <td>menurut presdir pt astra prijono sugiarto mobi...</td>\n",
              "      <td>menurut presdir pt astra prijono sugiarto mob...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>cakra cipta kreasi indonesia adalah asosiasi y...</td>\n",
              "      <td>cakra cipta kreasi indonesia adalah asosiasi y...</td>\n",
              "      <td>cakra cipta kreasi indonesia adalah asosiasi ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>instagram kemungkinan besar bakal mempunyai  ...</td>\n",
              "      <td>instagram kemungkinan besar bakal mempunyai  ...</td>\n",
              "      <td>instagram bisa melakukan pembaruan agar pengg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>jaket adalah salah satu jenis pakaian tertua m...</td>\n",
              "      <td>perusahaan afloader memperkenalkan bulletproof...</td>\n",
              "      <td>perusahaan afloader memperkenalkan bulletproo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>spesifikasi usb yang ada sekarang sudah ibarat...</td>\n",
              "      <td>silicon power baru saja memperkenalkan usb fla...</td>\n",
              "      <td>silicon power baru saja memperkenalkan usb fl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>suaracom salah satu ciri khas twiiter adalah t...</td>\n",
              "      <td>tidak sedikit pengguna twitter yang mengingink...</td>\n",
              "      <td>gboard untuk android atau ios namun terdapat ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>popularitas snapchat jelas berada dalam ancama...</td>\n",
              "      <td>untuk mengembalikan penggunanya yang berpaling...</td>\n",
              "      <td>untuk mengembalikan penggunanya yang berpalin...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34073c50-3e75-41c5-8821-1679ceb28eac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-34073c50-3e75-41c5-8821-1679ceb28eac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-34073c50-3e75-41c5-8821-1679ceb28eac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                           paragraphs  \\\n",
              "0   harus diakui smartphone dengan bezel tipis dan...   \n",
              "1   jakarta antara news perkembangan cara menikmat...   \n",
              "2   misi facebook mengkudeta snapchat terbilang be...   \n",
              "3   jakarta cnn indonesia selain memperkenalkan sk...   \n",
              "4   samsung meluncurkan galaxy note fan edition al...   \n",
              "5   ada banyak kamera pengawas yang bisa kita guna...   \n",
              "6   dalam gelaran advertising week di new york cit...   \n",
              "7   paypro adalah pengusung layanan dompet virtual...   \n",
              "8   kedua kaki kita adalah pilar penting penunjang...   \n",
              "9   jojonomic secara resmi telah mengumumkan kehad...   \n",
              "10  popularitas snapchat jelas berada dalam ancama...   \n",
              "11  jaybird boleh memelopori kategori sport earpho...   \n",
              "12  bukan rahasai lagi bahwa selain menjual smartp...   \n",
              "13  di era 90 an ketika compact disc menjadi mediu...   \n",
              "14  setelah menggelar proses bookbuilding lebih da...   \n",
              "15  ada banyak game yang seharusnya tidak kita mai...   \n",
              "16  facebook messenger dan paypal sebelumnya sudah...   \n",
              "17  grup bisnis telkom berencana mencabut blokir k...   \n",
              "18  mei tahun lalu google mulai memasarkan jamboar...   \n",
              "19  mesin hybrid elektrik teknologi selfdriving se...   \n",
              "20  tahun lalu hp meluncurkan sebuah printer porta...   \n",
              "21  indonesia saat ini tercatat sebagai negara den...   \n",
              "22  google bakal mengungkap generasi kedua lini sm...   \n",
              "23  industri startup di tanah air mulai berkembang...   \n",
              "24  kementerian energi dan sumber daya mineral esd...   \n",
              "25  cakra cipta kreasi indonesia adalah asosiasi y...   \n",
              "26  instagram kemungkinan besar bakal mempunyai  ...   \n",
              "27  jaket adalah salah satu jenis pakaian tertua m...   \n",
              "28  spesifikasi usb yang ada sekarang sudah ibarat...   \n",
              "29  suaracom salah satu ciri khas twiiter adalah t...   \n",
              "30  popularitas snapchat jelas berada dalam ancama...   \n",
              "\n",
              "                                              summary  \\\n",
              "0   gionee pabrikan ponsel asal tiongkok telah men...   \n",
              "1   pada peluncuran paket internet music unlimited...   \n",
              "2   facebook creator dirancang untuk membantu para...   \n",
              "3   pihak suzuki indonesia memboyong generasi terb...   \n",
              "4   daya tarik samsung galaxy note fan edition tam...   \n",
              "5   sebuah solusi inovatif ditawarkan oleh tim aev...   \n",
              "6   youtube meluncurkan fitur iklan baru yang pert...   \n",
              "7   paypro adalah pengusung layanan dompet virtual...   \n",
              "8   footbeat merupakan perangkat yang memadukan te...   \n",
              "9   jojonomic secara resmi telah mengumumkan kehad...   \n",
              "10  untuk mengembalikan penggunanya yang berpaling...   \n",
              "11  jaybird run mengadopsi premis desain yang sama...   \n",
              "12  xiaomi rupanya baru saja meluncurkan penjernih...   \n",
              "13  lima orang developer independen legendaris men...   \n",
              "14  setelah menggelar proses bookbuilding lebih da...   \n",
              "15  indie pixel dash studios punya jawaban atas ri...   \n",
              "16  facebook messenger dan paypal sebelumnya sudah...   \n",
              "17  grup bisnis telkom berencana mencabut blokir k...   \n",
              "18  mei tahun lalu google mulai memasarkan jamboar...   \n",
              "19  audi ag membuktikan bahwa mobil driverless seb...   \n",
              "20  tahun lalu hp meluncurkan sebuah printer porta...   \n",
              "21  indonesia saat ini tercatat sebagai negara den...   \n",
              "22  google rupanya ingin mencuri perhatian terlebi...   \n",
              "23  petarumah menyebut diri sebagai agensi modern ...   \n",
              "24  menurut presdir pt astra prijono sugiarto mobi...   \n",
              "25  cakra cipta kreasi indonesia adalah asosiasi y...   \n",
              "26  instagram kemungkinan besar bakal mempunyai  ...   \n",
              "27  perusahaan afloader memperkenalkan bulletproof...   \n",
              "28  silicon power baru saja memperkenalkan usb fla...   \n",
              "29  tidak sedikit pengguna twitter yang mengingink...   \n",
              "30  untuk mengembalikan penggunanya yang berpaling...   \n",
              "\n",
              "                                      predict_summary  \n",
              "0    gionee pabrikan ponsel asal tiongkok telah me...  \n",
              "1    pada senin 11 12 grab dan garuda indonesia re...  \n",
              "2    facebook creator dirancang untuk membantu pen...  \n",
              "3    oculus belum lama ini memperkenalkan perangka...  \n",
              "4    daya tarik samsung galaxy note fan edition di...  \n",
              "5    sebuah solusi inovatif ditawarkan oleh tim ae...  \n",
              "6    youtube meluncurkan fitur iklan baru yang per...  \n",
              "7    paypro adalah pengusung layanan dompet virtua...  \n",
              "8    footbeat merupakan perangkat yang memadukan t...  \n",
              "9    jojonomic secara resmi telah mengumumkan keha...  \n",
              "10   untuk mengembalikan penggunanya yang berpalin...  \n",
              "11   jaybird run mengadopsi premis desain yang leb...  \n",
              "12   xiaomi baru saja meluncurkan penjernih udara ...  \n",
              "13   lima orang developer independen legendaris me...  \n",
              "14   setelah menggelar proses bookbuilding lebih d...  \n",
              "15   indie pixel dash studios punya jawaban atas r...  \n",
              "16   facebook messenger dan tablet yang sangat pra...  \n",
              "17   grup bisnis telkom berencana mencabut blokir ...  \n",
              "18   mei tahun lalu browser edge pada tanggal 10 s...  \n",
              "19   audi ag membuktikan bahwa mobil driverless se...  \n",
              "20   setelah menjadi tiga produk baru bernama  so...  \n",
              "21   samsung secara resmi memperkenalkan versi bar...  \n",
              "22   google menguji sebuah aplikasi baru bernama b...  \n",
              "23   petarumah menyebut diri sebagai agensi modern...  \n",
              "24   menurut presdir pt astra prijono sugiarto mob...  \n",
              "25   cakra cipta kreasi indonesia adalah asosiasi ...  \n",
              "26   instagram bisa melakukan pembaruan agar pengg...  \n",
              "27   perusahaan afloader memperkenalkan bulletproo...  \n",
              "28   silicon power baru saja memperkenalkan usb fl...  \n",
              "29   gboard untuk android atau ios namun terdapat ...  \n",
              "30   untuk mengembalikan penggunanya yang berpalin...  "
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "review = seq2text(x_test[10])\n",
        "original = seq2summary(y_test[10])\n",
        "predict = decode_sequence(x_test[10].reshape(1, max_paragraphs_len))\n",
        "paragraphs_df.append(review)\n",
        "summary_df.append(original)\n",
        "predict_df.append(predict)\n",
        "post_df = pd.DataFrame({'paragraphs': paragraphs_df,'summary': summary_df, 'predict_summary': predict_df})\n",
        "post_df.to_csv(path_or_buf='/content/drive/MyDrive/Dataset TA/predict2.csv')\n",
        "post_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "j1KSHBRAAlSS",
        "outputId": "e863352b-e82a-41e3-e8fe-cd2d0db846f2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSYiQLe8FrMi",
        "outputId": "1c607021-793f-405d-c716-071de63a4acb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses, gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_best/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dataset TA/my_model_best/assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fa45042e390> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fa4501fd8d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fa45d1e9dd0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fa45041b750> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "model.save(f'/content/drive/MyDrive/Dataset TA/my_model_best')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [
        "ZpVqQpXPsI0D",
        "2X9Rrn4Bvr1O",
        "2b5k-_ZIy5dV",
        "riWacQev_8qu",
        "3eFFDdtLAxDO",
        "r3ANLQ2wFid7",
        "D8ao_CtLMsx8",
        "BCN6f69mYBV-",
        "wZVIDoZIer5m",
        "dSmcgfuFgYCu",
        "odlnyyiskEH4",
        "0UGp7B0vkcuV",
        "k4sdMRYpkrWv",
        "RdcxADMPlGAu",
        "YQ-93FA0lR-I",
        "d2qgiDDllgTi",
        "yaZY0Dv8mL2v",
        "asstIjnPmgO9",
        "TlhnBmpenHfP",
        "Mj1rfjECnZse",
        "C9UiHQg3nmyA"
      ],
      "machine_shape": "hm",
      "name": "TA Dual Encoding.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}